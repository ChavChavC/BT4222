{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI_IQ81m1PrW",
        "outputId": "f26b8d0b-2584-4f86-e469-ceda84b3cb11"
      },
      "outputs": [],
      "source": [
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRa2gDzCmQFr",
        "outputId": "b0658b82-b288-4cd5-8c02-c8fa824b0ba1"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "!pip install datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "K4NRlWdlC83w"
      },
      "outputs": [
        {
          "ename": "ModuleNotFoundError",
          "evalue": "No module named 'datasets'",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[1;32m/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS BZA/y3s1/BT4222/BT4222/testmodels.ipynb Cell 4\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#W2sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdatasets\u001b[39;00m \u001b[39mimport\u001b[39;00m load_dataset\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#W2sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mtorch\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mdata\u001b[39;00m \u001b[39mimport\u001b[39;00m DataLoader\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#W2sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m dataset \u001b[39m=\u001b[39m load_dataset(\u001b[39m\"\u001b[39m\u001b[39mJean-Baptiste/financial_news_sentiment\u001b[39m\u001b[39m\"\u001b[39m)\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'datasets'"
          ]
        }
      ],
      "source": [
        "from datasets import load_dataset\n",
        "from torch.utils.data import DataLoader\n",
        "dataset = load_dataset(\"Jean-Baptiste/financial_news_sentiment\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXGvzpLFfZsG"
      },
      "source": [
        "# Word2Vec\n",
        "Pre trained model does not work well with OOB due to financial jargon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZD6tChvjuiY",
        "outputId": "f7a7ac0e-c981-4c5b-8de9-4c992289b794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 39s  \n",
            "\n",
            "2023-11-05 08:20:08 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUTN2Ni_j1EZ",
        "outputId": "9c81d599-eed5-409c-dd90-3fa9f6412f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QD8UED1hkowN",
        "outputId": "ed8249e6-3cd5-4c6f-c19d-9a78d315c577"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OkjYPn_gl0C",
        "outputId": "3cfaabd4-71c4-443c-a8bd-ebb7e14b0850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eyUOM-4Jh4B-"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9p9gH-8kjpoI"
      },
      "outputs": [],
      "source": [
        "embeddings_dict = {}\n",
        "with open('glove.6B.50d.txt','rb') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZEqmO-Zk7w5",
        "outputId": "0bd2b5d7-8c85-454b-9f55-5e1783364c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.13175 , -0.25517 , -0.067915,  0.26193 , -0.26155 ,  0.23569 ,\n",
              "        0.13077 , -0.011801,  1.7659  ,  0.20781 ,  0.26198 , -0.16428 ,\n",
              "       -0.84642 ,  0.020094,  0.070176,  0.39778 ,  0.15278 , -0.20213 ,\n",
              "       -1.6184  , -0.54327 , -0.17856 ,  0.53894 ,  0.49868 , -0.10171 ,\n",
              "        0.66265 , -1.7051  ,  0.057193, -0.32405 , -0.66835 ,  0.26654 ,\n",
              "        2.842   ,  0.26844 , -0.59537 , -0.5004  ,  1.5199  ,  0.039641,\n",
              "        1.6659  ,  0.99758 , -0.5597  , -0.70493 , -0.0309  , -0.28302 ,\n",
              "       -0.13564 ,  0.6429  ,  0.41491 ,  1.2362  ,  0.76587 ,  0.97798 ,\n",
              "        0.58507 , -0.30176 ], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_dict[b'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "B2LYXKV3h_DW"
      },
      "outputs": [],
      "source": [
        "sents = ['Hi I am Maxim']\n",
        "MAX_NUM_WORDS = 100\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sents)\n",
        "sequences = tokenizer.texts_to_sequences(sents)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "zIIM9VRoSGEO",
        "outputId": "08f7d5eb-ed15-4374-c787-fffe4a5d8182"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5270a4bce7f5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NUM_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "embeddings_dict={}\n",
        "EMBEDDING_DIM = embeddings_dict.get(b'a').shape[0]\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dict.get(word.encode(\"utf-8\"))\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmbntEXl9As"
      },
      "source": [
        "# FastText 2\n",
        "\n",
        "FastText helpss with OOB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcxzvcXEnmSw",
        "outputId": "614047a9-467f-4be4-81b7-3df84fd6eb02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 5,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "49n006npnCbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import FastText\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 132,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_EdV79R9nDk",
        "outputId": "3c643d6f-bfa9-41b9-ab43-8b024be64413"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:gensim.models.word2vec:Each 'sentences' item should be a list of words (usually unicode strings). First item here is instead plain <class 'str'>.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vector of the first training sentence: [ 0.11128892  0.07110703 -0.01832274 -0.03512681 -0.07848565 -0.07651469\n",
            "  0.08572517 -0.01395123 -0.01714981 -0.06193054  0.00910656 -0.00081483\n",
            "  0.07397019 -0.03842697  0.04982022 -0.01583775 -0.00348384 -0.06601973\n",
            "  0.0195169   0.04067872 -0.00692174 -0.01340142  0.03815835 -0.01398507\n",
            "  0.05318914 -0.03291956 -0.02901105  0.03260862 -0.01058913 -0.02635476\n",
            " -0.01129421  0.08665947  0.01121316  0.02365046  0.00781885  0.04035165\n",
            " -0.01518953  0.01826518  0.00239426  0.01019059 -0.07332701 -0.05963234\n",
            " -0.03190676  0.03836203  0.03166715 -0.08553493  0.07815672 -0.0214128\n",
            "  0.01206412 -0.06131215  0.01857485 -0.02381697  0.01508836 -0.01280607\n",
            " -0.06751614  0.00521682 -0.07727255 -0.07575668  0.02930308 -0.07137661\n",
            "  0.02182705  0.03281942  0.06145371  0.0254927  -0.019301   -0.141697\n",
            "  0.14037505  0.02314698 -0.02424587 -0.0333663  -0.00973216  0.02284124\n",
            " -0.01797828 -0.02414297  0.06988305 -0.12591465 -0.12250078 -0.02546415\n",
            "  0.03300989 -0.04149312  0.01124394  0.07563043 -0.07283645  0.06461475\n",
            "  0.01366076  0.02014336  0.02825263 -0.06290364  0.08777177  0.05817781\n",
            " -0.02128029  0.02519332  0.03483546  0.05099227 -0.02107639  0.0775534\n",
            "  0.0492503   0.06019052  0.01346678 -0.06740413 -0.02095684 -0.10326137\n",
            " -0.00228753 -0.03566386 -0.04611883  0.07938968  0.0014645   0.02772444\n",
            "  0.04275662  0.02920291 -0.00479881 -0.00623776 -0.04702722 -0.00927031\n",
            "  0.0356821  -0.00103935  0.0507839   0.04047953 -0.01636394 -0.04141185\n",
            " -0.06045368 -0.06900401 -0.03517543  0.00126031  0.02864436 -0.0214869\n",
            " -0.02331996 -0.02240206]\n"
          ]
        }
      ],
      "source": [
        "model = FastText(sentences=dataset['train']['summary_detail_with_title'], vector_size =128, window=7, min_count=3, epochs = 5, seed =42, sg =1 )\n",
        "wv = model.wv\n",
        "def get_sentence_vectors(sentences):\n",
        "    vectors = []\n",
        "    for sentence in sentences:\n",
        "        sentence_vectors = [wv[word] for word in sentence if word in wv]\n",
        "        vectors.append((np.mean(sentence_vectors, axis=0)))\n",
        "    return vectors\n",
        "\n",
        "train_vectors = get_sentence_vectors(dataset['train']['summary_detail_with_title'])\n",
        "print(\"vector of the first training sentence:\", train_vectors[0])\n",
        "test_vectors = get_sentence_vectors(dataset['test']['summary_detail_with_title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6SoFri6q3uk"
      },
      "source": [
        "# BERT Tokenizer 3\n",
        "BERT Tokenizer to deal with diff in text **size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "52632601b5194259b357010a316a87c3",
            "482368971ad34b2b90d95226231987a7",
            "3c068b96d5544c3e80836ec323f00e4c",
            "7cbb4dda6ecd417ca2a228f9e75a1c9c",
            "925841aa064d47908721220d5c2dc8a0",
            "d44bb132f8774946a4ef51d8905e9406",
            "8fb227ecc4ab4008a5bd4c18eee24b3f",
            "03b363a4be084db2bfdd98c4fe08e133",
            "6331897e562547fba3f62d4b009ea5e9",
            "d1491196238948d398317aaa15adf68c",
            "a4c14f35fb284e37bbea0f0e876957bb",
            "60df71b9a7a04a83a89f7dbeb4003f8a",
            "f91d5ef6106e48c99ca2296c91c3c321",
            "9b54d69d732d4f77817e54fca8eba374",
            "a89e5dae524748a5953c311618c94b08",
            "b1c0e44b9f69418ea8dfeb4b32a000f8",
            "7a874d40f81d48cb845f4d5dd83e7909",
            "9268c5df10f94577ba3f2a1fab5b0595",
            "9c95041aaa17485cb4a09ed0c19d5aa2",
            "83b58655255041338750df563867d4f7",
            "88c2fedef5264a1e94592256bcf36eff",
            "46534bf21d56434bbd640a1f1c0a869b",
            "187358e1308a4581884fc2f4fbde9a94",
            "4287f832e2594b269b8f6ae48b885bd1",
            "7385490df52c44c18044d35bae7c37e1",
            "d0e7378ee17e4d14beb86040e4e91a94",
            "6d9d76219d2644419b1ad08553f6237c",
            "9e031dbb97404ba7a27775a511b69ecd",
            "9670129efee148f78e2c720f5f89a0c5",
            "f28d6656e9af4043aa86cafb8dd5a644",
            "5b2168404943494f91df77dca5bcdc6d",
            "f966b5e0e2a44868b76afe22ee15a51c",
            "88a1037651ca482f9baf03f24f56d34f",
            "8dc20f969e6647cea734eecad6fc5ee7",
            "371e79d8d05e48bd8b59efcfcc010bb2",
            "59c6673701ea425ea0c7fea35767a5be",
            "f1854c5107ef4cd9949e8f54d27a8905",
            "5cfbe3cbffe9483caed053cb35b90939",
            "73c8c385f34447fba4511e04b1d1028a",
            "a3f49eba8c864c3e893c6b1ba6f04768",
            "f2b5e8e49cad4dea9a005c4a9332227c",
            "d9232b398bce42a5b845fc106907a114",
            "22afb4a1f09644778bf4bb10c687644b",
            "39a437e801504f4782f049ff65ea71d2"
          ]
        },
        "id": "MBZWq2hirvMf",
        "outputId": "8c57b602-164a-4d99-955f-dc28b0b403c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52632601b5194259b357010a316a87c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60df71b9a7a04a83a89f7dbeb4003f8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "187358e1308a4581884fc2f4fbde9a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc20f969e6647cea734eecad6fc5ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT5G8Rb8r2P4",
        "outputId": "0658e784-f707-475b-b852-2f3c69fa3ab3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "token_lens = []\n",
        "for txt in dataset['train']['summary_detail_with_title']:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jTaiBp-s7XI"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vyJ9WhLstu6"
      },
      "outputs": [],
      "source": [
        "token_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKe63N4Zr5aV"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "da836073426b4f0382c174f733e6b632",
            "a417965cba7e4256b39a584f60c4f039",
            "5a31b0da8dad42eea5297c17f28c1ea9",
            "98cdd6461b3b46a9aab314fabdc70caf",
            "ab76c2cada82457ba9561bffc84576bc",
            "f1e4f8658078472caeedcff6038e236a",
            "2c162df50a1f4114ae9a108a7d1c30e5",
            "88bb7dd6ad0c48c19d0e9a1ef46a646e",
            "0b5f103144da47e4bf668a2a31c8d6db",
            "4d001b5f443e47ccabffd062d70695b4",
            "02a2dd3734c5481ea6b4c54f33d6121c"
          ]
        },
        "id": "i_MfAlEal96S",
        "outputId": "29459f55-44a9-4716-82e6-dd4a57c79425"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da836073426b4f0382c174f733e6b632",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-7a582dedeaac>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get the embedding vector for the word \"example\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexample_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mexample_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'convert_tokens_to_ids'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# get the embedding vector for the word \"example\"\n",
        "example_token_id = tokenizer.convert_tokens_to_ids([\"example\"])[0]\n",
        "example_embedding = model.embeddings.word_embeddings(torch.tensor([example_token_id]))\n",
        "example_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqRc1C4VmD_O"
      },
      "outputs": [],
      "source": [
        "# Load the BERT tokenizer from the \"bert-base-uncased\" pre-trained model\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "def tokenize_function(examples):\n",
        "# Tokenize the \"text\" column of the examples, adding padding to the maximum length and truncating if necessary\n",
        "        return tokenizer(examples[\"summary_detail_with_title\"], padding=\"max_length\", truncation=True)\n",
        "# Apply the tokenize function to the dataset in batches\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"summary_detail_with_title\"])\n",
        "# Rename the \"label\" column to \"labels\" to match the expected format for training\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# Shuffle the dataset with a fixed seed and select a range of examples\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly4uiJ9jSGB-",
        "outputId": "922acceb-9202-468d-c43d-f14baee8fbde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['train']['token_type_ids']\n",
        "tokenized_datasets['train']['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ9_GlGZSF_t",
        "outputId": "0e843344-dc2a-441e-80e1-2c3dd68cae32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlG6XdApSF9M",
        "outputId": "e287ec0c-643f-44a4-b338-e4315617b953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['token_type_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Gdjve5SF6p",
        "outputId": "bc2e0389-780c-4dd6-c852-d20747825a13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['attention_mask'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt_6x7vu7iWR"
      },
      "source": [
        "# ROBERTA,BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NwGEwgFuSF1Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "train_data = pd.DataFrame(dataset[\"train\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data[\"summary_detail_with_title\"], train_data[\"labels\"], test_size=0.2, shuffle=True, random_state=4222)\n",
        "vectorizer = CountVectorizer().fit(X_train)\n",
        "X_train_count = vectorizer.transform(X_train)\n",
        "X_val_count = vectorizer.transform(X_val)\n",
        "transformer = TfidfTransformer().fit(X_train_count)\n",
        "X_train_feature = transformer.transform(X_train_count)\n",
        "X_val_feature = transformer.transform(X_val_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7fMydHI8pWC",
        "outputId": "28c21856-8b1f-44e0-f058-14c1bdc58ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1209x7640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 51755 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElfQ0ci38xCD"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define the first convolutional layer\n",
        "        self.conv1 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        # Define the batch normalization layer for the first conv layer\n",
        "        self.Bn1 = nn.BatchNorm1d(32)\n",
        "        # Define the max pooling layer for the first conv layer\n",
        "        self.pool1=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        self.Bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool2=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        self.Bn3 = nn.BatchNorm1d(32)\n",
        "        self.pool3=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        # Define LSTM layer with input size of 960 and hidden size of 100\n",
        "        self.bi_lstm1 = nn.LSTM(input_size=960, hidden_size=100, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        # Define the first fully connected layer after LSTM\n",
        "        self.fc1 = nn.Linear(100, 100, bias=True)\n",
        "        # Define self-attention layer\n",
        "        self.self_attn_1 = nn.MultiheadAttention(embed_dim=100, num_heads=4)\n",
        "        # Define the final fully connected layer for classification\n",
        "        self.fc2 = nn.Linear(100, 5, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the first convolutional layer, then through the ReLU activation function, then through max pooling\n",
        "        x_layer1 = self.pool1(F.relu(self.Bn1(self.conv1(x))))\n",
        "        x_layer2 = self.pool1(F.relu(self.Bn2(self.conv2(x))))\n",
        "        x_layer3 = self.pool1(F.relu(self.Bn3(self.conv3(x))))\n",
        "        # Concatenate the outputs of the three layers along the channel dimension\n",
        "        x = torch.cat((x_layer1, x_layer2,x_layer3), 1)\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass input through the LSTM layer\n",
        "        x, _ = self.bi_lstm1(x)\n",
        "        # Pass output of LSTM layer through the first fully connected layer, then through the ReLU activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Reshape the tensor for the self-attention layer\n",
        "        x = x.view(-1, 1, 100)\n",
        "        # Pass tensor through the self-attention layer\n",
        "        x, _ = self.self_attn_1(x.permute(1, 0, 2), x.permute(1, 0, 2), x.permute(1, 0, 2))\n",
        "        # Reshape tensor back to original shape\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.view(-1, 100)\n",
        "        # Pass the output through the final fully connected layer for classification\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMGO6oW6DEOz"
      },
      "source": [
        "Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdwnk0J5ocEx"
      },
      "outputs": [],
      "source": [
        "# # ROBERTA FIN BERT model\n",
        "# #Their own model\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"Jean-Baptiste/roberta-large-financial-news-sentiment-en\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/roberta-large-financial-news-sentiment-en\")\n",
        "\n",
        "# classifier=pipeline(\"text-classification\",model=model, tokenizer=tokenizer)\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3Y9auVVbLH"
      },
      "source": [
        "FinBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IlXTNQRVKSr"
      },
      "outputs": [],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlk18uHBwjql"
      },
      "source": [
        "BERT/ Distilbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI2uC53NwpT1"
      },
      "outputs": [],
      "source": [
        "modelname = \"bert-base-uncased\"\n",
        "modelname = \"distilbert-base-uncased\"\n",
        "modelname = \"distilbert-base-uncased\"\n",
        "\n",
        "\n",
        "# modelname = \"distilbert-base-uncased\"\n",
        "# id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2:\"POSITIVE\"}\n",
        "# label2id = {\"NEGATIVE\": 0, \"NEUTRAL\":1 , \"POSITIVE\": 2}\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2fe15378930b4a97b98ec96f8e584e45",
            "2024bd3b639c48fc8b8815643564717d",
            "af493b1c2c1b40c5ab2db58497fbdd4d",
            "878f2c1cf6b84f9c96be43719570b6e1",
            "961ed0414e5a4c62b78b2f10f1263145",
            "bd63c4f7f92b42b5afd8bc5858b88a74",
            "35f02b3c6dbb4dbb8a6bd04bd181df79",
            "7998ae84e4344bc88cf96162c8c040de",
            "515c0a2698e945d7ac81eaba81432480",
            "3af06ad482b84968966f5bc1f6dde9ac",
            "8d9e2bc1c9e14a71b1860acf10a72025"
          ]
        },
        "id": "p1ZmUZ-5d3gz",
        "outputId": "1e92ea13-4f7f-4a52-8d41-3fc644b3212f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fe15378930b4a97b98ec96f8e584e45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/267 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the BERT tokenizer from the \"bert-base-uncased\" pre-trained model\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "def tokenize_function(examples):\n",
        "# Tokenize the \"text\" column of the examples, adding padding to the maximum length and truncating if necessary\n",
        "        return tokenizer(examples[\"summary_detail_with_title\"], padding=\"max_length\", truncation=True)\n",
        "# Apply the tokenize function to the dataset in batches\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"summary_detail_with_title\"])\n",
        "# Rename the \"label\" column to \"labels\" to match the expected format for training\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# Shuffle the dataset with a fixed seed and select a range of examples\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxno9E1ogst2"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.remove_columns(['summary_detail', 'title', 'topic',  '__index_level_0__',])\n",
        "eval_dataset = eval_dataset.remove_columns(['summary_detail', 'title', 'topic',  '__index_level_0__',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqxFJ-FteZwS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
        "batchsize=4\n",
        "# Create Dataloader\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batchsize)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCkeM5JFejCj",
        "outputId": "3f5da12a-f51b-4cbd-cdde-21eef5f98174"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "# Because we initialized BertForMaskedLM and concat is with our classifier instead of directly using BertForSequenceClassification\n",
        "# Some weights of the model checkpoint at bert-base-uncased were not used is within the expectation.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,output_dim,dropout_rate):\n",
        "        super(Model,self).__init__()\n",
        "        self.encoder=AutoModelForMaskedLM.from_pretrained(modelname, output_hidden_states=True, return_dict=True)\n",
        "        self.dropout=nn.Dropout(dropout_rate)\n",
        "        # For the \"bert-base-uncased\" model, each hidden state has a dimension of 768.\n",
        "        # the value 3072=4*768 corresponds to the total dimension of the concatenated hidden states from the BERT model.\n",
        "        self.classifier=nn.Linear(3072,output_dim)\n",
        "\n",
        "\n",
        "    def forward(self,input_ids,token_type_ids,attention_mask):\n",
        "        outputs = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        hidden_states = torch.cat(tuple([outputs.hidden_states[i] for i in [-1, -2, -3, -4]]), dim=-1) # [bs, seq_len, hidden_dim*4]\n",
        "        # We are actually extracting the hidden state of the [CLS] token for each sequence in the batch.\n",
        "        # This [CLS] token's hidden state is typically used as a fixed-size representation of the entire sequence.\n",
        "        # This representation has been learned during BERT's pretraining to capture important information for various tasks.\n",
        "        # In the context of classification, you can think of the [CLS] token's hidden state as a summary of the sequence's content,\n",
        "        # which is then fed into the linear classifier to make predictions for the task at hand.\n",
        "        x=self.dropout(hidden_states[:, 0, :])\n",
        "        x=self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = Model(output_dim=3, dropout_rate = 0.5)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_fct = CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "314aa15a0dc642eeac4fe71108e558ff",
            "f3311eaaaa634a25b15b696bd597ced0",
            "17b7e31540be4d2493dd5cc3c0b5db8c",
            "c3e3e46efcb04d6abb0bf8e23161f9ef",
            "f63a9a360181468a991009b14a271a46",
            "99727414bc1146578aa17513e14e697b",
            "1761b91723a845728299f470d05c9f5e",
            "0e730ba0c9d242849d18cb062a78f57b",
            "0d7b1eee53da43caacb1075066cb4204",
            "b7b2679af34f4bd484b6f8b0e43e6449",
            "71f78f69f9834809a0d621aa1ec23bb0"
          ]
        },
        "id": "M1ml663Hes61",
        "outputId": "8b2524b7-b04d-44e3-8dca-f55bf1a16002"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "\n",
        "epochs = 2\n",
        "num_training_steps = epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        "    )\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "        for batch in train_dataloader:\n",
        "            model.train()\n",
        "            # Loop through batches in the training data loader\n",
        "            label_ids = batch['labels']\n",
        "            input_ids = batch['input_ids']\n",
        "            token_type_ids = None\n",
        "            # When using BERT for tasks like single-text classification or sequence labeling, the token_type_ids is an optional parameter, commonly set to None.\n",
        "            attention_mask = batch['attention_mask']\n",
        "            # Perform a forward pass through the model to get logits\n",
        "            logits = model(input_ids, token_type_ids, attention_mask)\n",
        "\n",
        "            # Calculate the loss using the provided loss function\n",
        "            loss = loss_fct(logits, label_ids.view(-1))\n",
        "            # Perform backward pass and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad() # Clear accumulated gradients\n",
        "            progress_bar.update(1) # Update progress bar\n",
        "\n",
        "        # Set the model to evaluation mode for validation\n",
        "        model.eval()\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            with torch.no_grad(): # disable gradient computation\n",
        "                label_ids = batch['labels']\n",
        "                input_ids = batch['input_ids']\n",
        "                token_type_ids = None\n",
        "                attention_mask = batch['attention_mask']\n",
        "                logits = model(input_ids, token_type_ids, attention_mask)\n",
        "                loss = loss_fct(logits, label_ids.view(-1))\n",
        "\n",
        "            # Get predicted labels by selecting the class with the highest probability\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "        acc = metric.compute()\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        print(f'val_loss : {loss}')\n",
        "        print(f\"val_accuracy: {acc['accuracy'] * 100}\")\n",
        "        print(25*'==')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdvc_fOYRx6z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv0FaC3fon4C"
      },
      "outputs": [],
      "source": [
        "# # D\n",
        "# #Their own model\n",
        "# from transformers import DistilBertTokenizer, DistilBertModel\n",
        "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,DataCollatorWithPadding\n",
        "# import numpy as np\n",
        "# import evaluate\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2:\"POSITIVE\"}\n",
        "# label2id = {\"NEGATIVE\": 0, \"NEUTRAL\":1 , \"POSITIVE\": 2}\n",
        "\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        "# )\n",
        "\n",
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "# accuracy = evaluate.load(\"accuracy\")\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"my_awesome_model\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=16,\n",
        "#     per_device_eval_batch_size=16,\n",
        "#     num_train_epochs=2,\n",
        "#     weight_decay=0.01,\n",
        "#     evaluation_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     load_best_model_at_end=True,\n",
        "#     push_to_hub=True,\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=dataset[\"train\"],\n",
        "#     eval_dataset=dataset[\"test\"],\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_wqbOA8yJq5"
      },
      "outputs": [],
      "source": [
        "# classifier=pipeline(\"text-classification\",model=model, tokenizer=tokenizer)\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu4wwQ-E7ehC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEjgfz7O-zhb"
      },
      "source": [
        "# test - currently working on this, run fasttext first to attain vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 133,
      "metadata": {
        "id": "kE3wsVDh-yJo"
      },
      "outputs": [],
      "source": [
        "train_vectors\n",
        "train_labels = dataset['train']['labels']\n",
        "test_vectors\n",
        "test_labels = dataset['test']['labels']\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 143,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVX3e4YYPMAx",
        "outputId": "1a23a24b-7b7a-4f5d-a3c0-18af3c5beb45"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([267, 1, 128])"
            ]
          },
          "execution_count": 143,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_vectors1 = torch.Tensor(train_vectors).reshape(len(train_vectors),1,128)\n",
        "train_vectors1.shape\n",
        "test_vectors1 = torch.Tensor(test_vectors).reshape(len(test_labels),1,128)\n",
        "test_vectors1.shape\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "2MbceMFiO-8i",
        "outputId": "2c2adf99-eecf-4303-e88f-ffeb03f5a76c"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f442ccc4ab8>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest_vectors1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'test_vectors1' is not defined"
          ]
        }
      ],
      "source": [
        "test_vectors1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6U5CA61lMUp0",
        "outputId": "0eec4fe4-186a-490d-af6e-d7ba2e8bdafe"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "torch.Size([267])"
            ]
          },
          "execution_count": 155,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels1 = torch.Tensor(train_labels).reshape(len(train_labels))\n",
        "train_labels1.shape\n",
        "test_labels1 = torch.Tensor(test_labels).reshape(len(test_labels))\n",
        "test_labels1.shape\n",
        "\n",
        "# But in our case, this is a little bit different because I simplify the word embedding process for easy use and understanding before sending the embedding vector to our network:\n",
        "\n",
        "# def get_sentence_vectors(sentences):\n",
        "#     vectors = []\n",
        "#     for sentence in sentences:\n",
        "#         #This line creates a list of word vectors for each word in the sentence that is in the Word2Vec model's vocabulary.\n",
        "#         sentence_vectors = [wv[word] for word in sentence if word in wv]\n",
        "#         if len(sentence_vectors) == 0:\n",
        "#             vectors.append([0] * 50)  # If the sentence doesn't have any words that are in\n",
        "#             # the Word2Vec model's vocabulary, the sentence is represented by a vector of 50 zeros.\n",
        "#         else:\n",
        "#             vectors.append(np.mean(sentence_vectors, axis=0))  # Otherwise, the sentence vector is the average\n",
        "#             # of its word vectors. This vector is then added to the list of sentence vectors.\n",
        "#     return vectors"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuQJ7vn4Nv4W",
        "outputId": "6516d3f2-b4ec-4265-858c-e3f0d7f67d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<built-in method size of Tensor object at 0x7b00b58e67f0>\n",
            "torch.Size([1512, 1, 128])\n",
            "<built-in method size of Tensor object at 0x7b00b58fe930>\n",
            "torch.Size([1, 128])\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors1.size)\n",
        "print(train_vectors1.shape)\n",
        "print(train_vectors1[0].size)\n",
        "print(train_vectors1[0].shape)\n",
        "print(train_vectors1.dtype)\n",
        "print(train_vectors1[0].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 325
        },
        "id": "id267x5oItCf",
        "outputId": "a999e505-6f7e-4a9a-d54f-62089410dfb8"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-156-9f7add2f8ba7>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "train_dataset = torch.utils.data.TensorDataset(train_vectors1, train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_vectors1, test_labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdlSt2r-Kx7_",
        "outputId": "3cdfc922-4552-4773-edf9-76e50763886b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_vectors1.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dKhmkInIfIk",
        "outputId": "71455f20-0306-4d2b-f904-ae8cd96e9103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([128])\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors1[0].shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "pYnPEeN6EPs0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 45,
      "metadata": {
        "id": "IOJEvkzHECGN"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define the first convolutional layer\n",
        "        self.conv1 = nn.Conv1d(1, 32, 1, 1,1, bias=True)\n",
        "        # Define the batch normalization layer for the first conv layer\n",
        "        self.Bn1 = nn.BatchNorm1d(32)\n",
        "        # Define the max pooling layer for the first conv layer\n",
        "        self.pool1=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(1, 32, 1, 1,1, bias=True)\n",
        "        self.Bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool2=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.bi_lstm1 = nn.LSTM(input_size=960, hidden_size=100, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        self.fc1 = nn.Linear(100, 100, bias=True)\n",
        "        self.self_attn_1 = nn.MultiheadAttention(embed_dim=100, num_heads=4)\n",
        "        self.fc2 = nn.Linear(100, 5, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the first convolutional layer, then through the ReLU activation function, then through max pooling\n",
        "        x_layer1 = self.pool1(F.relu(self.Bn1(self.conv1(x))))\n",
        "        x_layer2 = self.pool1(F.relu(self.Bn2(self.conv2(x))))\n",
        "        # Concatenate the outputs of the three layers along the channel dimension\n",
        "        x = torch.cat((x_layer1, x_layer2), 1)\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass input through the LSTM layer\n",
        "        x, _ = self.bi_lstm1(x)\n",
        "        # Pass output of LSTM layer through the first fully connected layer, then through the ReLU activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Reshape the tensor for the self-attention layer\n",
        "        x = x.view(-1, 1, 100)\n",
        "        # Pass tensor through the self-attention layer\n",
        "        x, _ = self.self_attn_1(x.permute(1, 0, 2), x.permute(1, 0, 2), x.permute(1, 0, 2))\n",
        "        # Reshape tensor back to original shape\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.view(-1, 100)\n",
        "        # Pass the output through the final fully connected layer for classification\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 46,
      "metadata": {
        "id": "KiLBgphoEBqq"
      },
      "outputs": [],
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):  # Loop over each batch from the training set\n",
        "        data, target = data.to(device), target.to(device)  # Move the data to the device that is used\n",
        "\n",
        "        target = target-1  # Adjust the target values (Moving 1-5 to 0-4  for easy training)\n",
        "        target = target.long()  # Make sure that target data is long type (necessary for loss function)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous training step\n",
        "        output = model(data)  # Run forward pass (model predictions)\n",
        "\n",
        "        loss = F.cross_entropy(output, target)  # Calculate the loss between the output and target\n",
        "        loss.backward()  # Perform backpropagation (calculate gradients of loss w.r.t. parameters)\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:  # Print log info for specified interval\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():  # Deactivates autograd, reduces memory usage and speeds up computations\n",
        "        for data, target in test_loader:  # Loop over each batch from the testing set\n",
        "            data, target = data.to(device), target.to(device)  # Move the data to the device that is used\n",
        "            target = target-1  # Adjust the target values\n",
        "            output = model(data)  # Run forward pass (model predictions)\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability as the predicted output\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  # Calculate the average loss\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
        "    return correct  # Return the number of correctly classified samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "xreTSnllEW9Q"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  epochs = 10\n",
        "  lr = 1.0\n",
        "  use_cuda=False\n",
        "  gamma = 0.7\n",
        "  log_interval = 10\n",
        "  no_cuda = False\n",
        "  seed = 1\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 116,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "FkNCa8kX_Bno",
        "outputId": "5f41f665-3bba-4d94-c706-bf048b8fe08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight \t torch.Size([32, 1, 1])\n",
            "conv1.bias \t torch.Size([32])\n",
            "Bn1.weight \t torch.Size([32])\n",
            "Bn1.bias \t torch.Size([32])\n",
            "Bn1.running_mean \t torch.Size([32])\n",
            "Bn1.running_var \t torch.Size([32])\n",
            "Bn1.num_batches_tracked \t torch.Size([])\n",
            "conv2.weight \t torch.Size([32, 1, 1])\n",
            "conv2.bias \t torch.Size([32])\n",
            "Bn2.weight \t torch.Size([32])\n",
            "Bn2.bias \t torch.Size([32])\n",
            "Bn2.running_mean \t torch.Size([32])\n",
            "Bn2.running_var \t torch.Size([32])\n",
            "Bn2.num_batches_tracked \t torch.Size([])\n",
            "bi_lstm1.weight_ih_l0 \t torch.Size([400, 960])\n",
            "bi_lstm1.weight_hh_l0 \t torch.Size([400, 100])\n",
            "bi_lstm1.bias_ih_l0 \t torch.Size([400])\n",
            "bi_lstm1.bias_hh_l0 \t torch.Size([400])\n",
            "fc1.weight \t torch.Size([100, 100])\n",
            "fc1.bias \t torch.Size([100])\n",
            "self_attn_1.in_proj_weight \t torch.Size([300, 100])\n",
            "self_attn_1.in_proj_bias \t torch.Size([300])\n",
            "self_attn_1.out_proj.weight \t torch.Size([100, 100])\n",
            "self_attn_1.out_proj.bias \t torch.Size([100])\n",
            "fc2.weight \t torch.Size([5, 100])\n",
            "fc2.bias \t torch.Size([5])\n"
          ]
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-116-f0883962ab17>\u001b[0m in \u001b[0;36m<cell line: 8>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m#Form training and testing dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0moptimizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mAdadelta\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparameters\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mtrain_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_vectors1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mtest_dataset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTensorDataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_vectors1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, *tensors)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataset.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    203\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 204\u001b[0;31m         \u001b[0;32massert\u001b[0m \u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtensor\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Size mismatch between tensors\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtensors\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    206\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'size'"
          ]
        }
      ],
      "source": [
        "\n",
        "torch.manual_seed(args.seed)\n",
        "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "for param_tensor in model.state_dict():\n",
        "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "#Form training and testing dataset\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
        "train_dataset = torch.utils.data.TensorDataset(train_vectors1, train_labels)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_vectors1, test_labels)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "#Model training\n",
        "ACC = 0\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, train_loader, optimizer, epoch)\n",
        "    ACC_ = test(model, device, test_loader)\n",
        "    if ACC_>ACC or ACC_ == ACC:\n",
        "        ACC = ACC_\n",
        "        torch.save(model.state_dict(), \"cnn_lstm_att.pt\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(ACC)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPPDQde6BuTJ"
      },
      "source": [
        "# Yeeted of HANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoEc0GHiBto4"
      },
      "outputs": [],
      "source": [
        "class HAHNetwork():\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.MAX_SENTENCE_LENGTH = 0\n",
        "        self.MAX_SENTENCE_COUNT = 0\n",
        "        self.VOCABULARY_SIZE = 0\n",
        "        self.word_embedding = None\n",
        "        self.model = None\n",
        "        self.word_attention_model = None\n",
        "        self.tokenizer = None\n",
        "        self.class_count = 2\n",
        "\n",
        "    def build_model(self, n_classes=2, embedding_dim=200, embeddings_path=False):\n",
        "\n",
        "        l2_reg = regularizers.l2(0.001)\n",
        "\n",
        "        embedding_weights = np.random.normal(0, 1, (len(self.tokenizer.word_index) + 1, embedding_dim))\n",
        "\n",
        "        if embeddings_path is not None:\n",
        "\n",
        "            if word_embedding_type is 'from_scratch':\n",
        "                # FastText\n",
        "                filename = './fasttext_model.txt'\n",
        "                model =  gensim.models.FastText.load(filename)\n",
        "\n",
        "                embeddings_index = model.wv\n",
        "                embedding_matrix = np.zeros( ( len(self.tokenizer.word_index) + 1, embedding_dim) )\n",
        "                for word, i in self.tokenizer.word_index.items():\n",
        "                    try:\n",
        "                        embedding_vector = embeddings_index[word]\n",
        "                        if embedding_vector is not None:\n",
        "                            embedding_matrix[i] = embedding_vector\n",
        "                    except Exception as e:\n",
        "                        #print(str(e))\n",
        "                        continue\n",
        "\n",
        "\n",
        "            else:\n",
        "                embedding_dim = 300\n",
        "                embedding_matrix = load_subword_embedding_300d(self.tokenizer.word_index)\n",
        "\n",
        "            embedding_weights = embedding_matrix\n",
        "\n",
        "        sentence_in = Input(shape=(self.MAX_SENTENCE_LENGTH,), dtype='int32', name=\"input_1\")\n",
        "\n",
        "        embedding_trainable = True\n",
        "\n",
        "\n",
        "\n",
        "        if word_embedding_type is 'pre_trained':\n",
        "            embedding_trainable = False\n",
        "\n",
        "        embedded_word_seq = Embedding(\n",
        "            self.VOCABULARY_SIZE,\n",
        "            embedding_dim,\n",
        "            weights=[embedding_weights],\n",
        "            input_length=self.MAX_SENTENCE_LENGTH,\n",
        "            trainable=embedding_trainable,\n",
        "            #mask_zero=True,\n",
        "            mask_zero=False,\n",
        "            name='word_embeddings',)(sentence_in)\n",
        "\n",
        "\n",
        "\n",
        "        dropout = Dropout(0.2)(embedded_word_seq)\n",
        "        filter_sizes = [3,4,5]\n",
        "        convs = []\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = Conv1D(filters=64, kernel_size=filter_size, padding='same', activation='relu')(dropout)\n",
        "            pool = MaxPool1D(filter_size)(conv)\n",
        "            convs.append(pool)\n",
        "\n",
        "        concatenate = Concatenate(axis=1)(convs)\n",
        "\n",
        "        if rnn_type is 'GRU':\n",
        "            #word_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True, dropout=0.2))(concatenate)\n",
        "            dropout = Dropout(0.1)(concatenate)\n",
        "            word_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True))(dropout)\n",
        "        else:\n",
        "            word_encoder = Bidirectional(\n",
        "                LSTM(50, return_sequences=True, dropout=0.2))(embedded_word_seq)\n",
        "\n",
        "\n",
        "        dense_transform_word = Dense(\n",
        "            100,\n",
        "            activation='relu',\n",
        "            name='dense_transform_word',\n",
        "            kernel_regularizer=l2_reg)(word_encoder)\n",
        "\n",
        "        # word attention\n",
        "        attention_weighted_sentence = Model(\n",
        "            sentence_in, Attention(name=\"word_attention\")(dense_transform_word))\n",
        "\n",
        "        self.word_attention_model = attention_weighted_sentence\n",
        "\n",
        "        attention_weighted_sentence.summary()\n",
        "\n",
        "        # sentence-attention-weighted document scores\n",
        "\n",
        "        texts_in = Input(shape=(self.MAX_SENTENCE_COUNT, self.MAX_SENTENCE_LENGTH), dtype='int32', name=\"input_2\")\n",
        "\n",
        "        attention_weighted_sentences = TimeDistributed(attention_weighted_sentence)(texts_in)\n",
        "\n",
        "\n",
        "        if rnn_type is 'GRU':\n",
        "            #sentence_encoder = Bidirectional(GRU(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))(attention_weighted_sentences)\n",
        "            dropout = Dropout(0.1)(attention_weighted_sentences)\n",
        "            sentence_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True))(dropout)\n",
        "        else:\n",
        "            sentence_encoder = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))(attention_weighted_sentences)\n",
        "\n",
        "\n",
        "        dense_transform_sentence = Dense(\n",
        "            100,\n",
        "            activation='relu',\n",
        "            name='dense_transform_sentence',\n",
        "            kernel_regularizer=l2_reg)(sentence_encoder)\n",
        "\n",
        "        # sentence attention\n",
        "        attention_weighted_text = Attention(name=\"sentence_attention\")(dense_transform_sentence)\n",
        "\n",
        "\n",
        "        prediction = Dense(n_classes, activation='softmax')(attention_weighted_text)\n",
        "\n",
        "        model = Model(texts_in, prediction)\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        optimizer=Adam(lr=learning_rate, decay=0.0001)\n",
        "\n",
        "        model.compile(\n",
        "                      optimizer=optimizer,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def get_tokenizer_filename(self, saved_model_filename):\n",
        "        return saved_model_filename + '.tokenizer'\n",
        "\n",
        "    def create_reverse_word_index(self):\n",
        "        self.reverse_word_index = {value:key for key,value in self.tokenizer.word_index.items()}\n",
        "\n",
        "    def encode_texts(self, texts):\n",
        "        encoded_texts = np.zeros((len(texts), self.MAX_SENTENCE_COUNT, self.MAX_SENTENCE_LENGTH))\n",
        "        for i, text in enumerate(texts):\n",
        "            encoded_text = np.array(pad_sequences(\n",
        "                self.tokenizer.texts_to_sequences(text),\n",
        "                maxlen=self.MAX_SENTENCE_LENGTH))[:self.MAX_SENTENCE_COUNT]\n",
        "            encoded_texts[i][-len(encoded_text):] = encoded_text\n",
        "        return encoded_texts\n",
        "\n",
        "\n",
        "    def encode_input(self, x, log=False):\n",
        "        x = np.array(x)\n",
        "        if not x.shape:\n",
        "            x = np.expand_dims(x, 0)\n",
        "        texts = np.array([normalize(text) for text in x])\n",
        "        return self.encode_texts(texts)\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "            encoded_x = self.encode_texts(x)\n",
        "            return self.model.predict(encoded_x)\n",
        "\n",
        "\n",
        "    def activation_maps(self, text, websafe=False):\n",
        "        normalized_text = normalize(text)\n",
        "\n",
        "        encoded_text = self.encode_input(text)[0]\n",
        "\n",
        "        # get word activations\n",
        "\n",
        "        hidden_word_encoding_out = Model(\n",
        "            inputs=self.word_attention_model.input,\n",
        "            outputs=self.word_attention_model.get_layer('dense_transform_word').output)\n",
        "\n",
        "\n",
        "        hidden_word_encodings = hidden_word_encoding_out.predict(encoded_text)\n",
        "\n",
        "        word_context = self.word_attention_model.get_layer('word_attention').get_weights()[0]\n",
        "\n",
        "\n",
        "        dot = np.dot(hidden_word_encodings, word_context)\n",
        "\n",
        "        #u_wattention = encoded_text*np.exp(np.squeeze(dot))\n",
        "        u_wattention = encoded_text\n",
        "\n",
        "        if websafe:\n",
        "            u_wattention = u_wattention.astype(float)\n",
        "\n",
        "        nopad_encoded_text = encoded_text[-len(normalized_text):]\n",
        "        nopad_encoded_text = [list(filter(lambda x: x > 0, sentence)) for sentence in nopad_encoded_text]\n",
        "        reconstructed_texts = [[self.reverse_word_index[int(i)]\n",
        "                                for i in sentence] for sentence in nopad_encoded_text]\n",
        "        nopad_wattention = u_wattention[-len(normalized_text):]\n",
        "        nopad_wattention = nopad_wattention/np.expand_dims(np.sum(nopad_wattention, -1), -1)\n",
        "        nopad_wattention = np.array([attention_seq[-len(sentence):]\n",
        "                            for attention_seq, sentence in zip(nopad_wattention, nopad_encoded_text)])\n",
        "        word_activation_maps = []\n",
        "        for i, text in enumerate(reconstructed_texts):\n",
        "            word_activation_maps.append(list(zip(text, nopad_wattention[i])))\n",
        "\n",
        "        hidden_sentence_encoding_out = Model(inputs=self.model.input,\n",
        "                                             outputs=self.model.get_layer('dense_transform_sentence').output)\n",
        "        hidden_sentence_encodings = np.squeeze(\n",
        "            hidden_sentence_encoding_out.predict(np.expand_dims(encoded_text, 0)), 0)\n",
        "        sentence_context = self.model.get_layer('sentence_attention').get_weights()[0]\n",
        "        u_sattention = np.exp(np.squeeze(np.dot(hidden_sentence_encodings, sentence_context), -1))\n",
        "        if websafe:\n",
        "            u_sattention = u_sattention.astype(float)\n",
        "        nopad_sattention = u_sattention[-len(normalized_text):]\n",
        "\n",
        "        nopad_sattention = nopad_sattention/np.expand_dims(np.sum(nopad_sattention, -1), -1)\n",
        "\n",
        "        activation_map = list(zip(word_activation_maps, nopad_sattention))\n",
        "\n",
        "        return activation_map\n",
        "\n",
        "\n",
        "    def load_weights(self, saved_model_dir, saved_model_filename):\n",
        "        with CustomObjectScope({'Attention': Attention}):\n",
        "            print(os.path.join(saved_model_dir, saved_model_filename))\n",
        "            self.model = load_model(os.path.join(saved_model_dir, saved_model_filename))\n",
        "            self.word_attention_model = self.model.get_layer('time_distributed_1').layer\n",
        "            tokenizer_path = os.path.join(\n",
        "                saved_model_dir, self.get_tokenizer_filename(saved_model_filename))\n",
        "            tokenizer_state = pickle.load(open(tokenizer_path, \"rb\" ))\n",
        "            self.tokenizer = tokenizer_state['tokenizer']\n",
        "            self.MAX_SENTENCE_COUNT = tokenizer_state['maxSentenceCount']\n",
        "            self.MAX_SENTENCE_LENGTH = tokenizer_state['maxSentenceLength']\n",
        "            self.VOCABULARY_SIZE = tokenizer_state['vocabularySize']\n",
        "            self.create_reverse_word_index()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02a2dd3734c5481ea6b4c54f33d6121c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b363a4be084db2bfdd98c4fe08e133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5f103144da47e4bf668a2a31c8d6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d7b1eee53da43caacb1075066cb4204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e730ba0c9d242849d18cb062a78f57b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1761b91723a845728299f470d05c9f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17b7e31540be4d2493dd5cc3c0b5db8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e730ba0c9d242849d18cb062a78f57b",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d7b1eee53da43caacb1075066cb4204",
            "value": 250
          }
        },
        "187358e1308a4581884fc2f4fbde9a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4287f832e2594b269b8f6ae48b885bd1",
              "IPY_MODEL_7385490df52c44c18044d35bae7c37e1",
              "IPY_MODEL_d0e7378ee17e4d14beb86040e4e91a94"
            ],
            "layout": "IPY_MODEL_6d9d76219d2644419b1ad08553f6237c"
          }
        },
        "2024bd3b639c48fc8b8815643564717d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd63c4f7f92b42b5afd8bc5858b88a74",
            "placeholder": "​",
            "style": "IPY_MODEL_35f02b3c6dbb4dbb8a6bd04bd181df79",
            "value": "Map: 100%"
          }
        },
        "22afb4a1f09644778bf4bb10c687644b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c162df50a1f4114ae9a108a7d1c30e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe15378930b4a97b98ec96f8e584e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2024bd3b639c48fc8b8815643564717d",
              "IPY_MODEL_af493b1c2c1b40c5ab2db58497fbdd4d",
              "IPY_MODEL_878f2c1cf6b84f9c96be43719570b6e1"
            ],
            "layout": "IPY_MODEL_961ed0414e5a4c62b78b2f10f1263145"
          }
        },
        "314aa15a0dc642eeac4fe71108e558ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3311eaaaa634a25b15b696bd597ced0",
              "IPY_MODEL_17b7e31540be4d2493dd5cc3c0b5db8c",
              "IPY_MODEL_c3e3e46efcb04d6abb0bf8e23161f9ef"
            ],
            "layout": "IPY_MODEL_f63a9a360181468a991009b14a271a46"
          }
        },
        "35f02b3c6dbb4dbb8a6bd04bd181df79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "371e79d8d05e48bd8b59efcfcc010bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c8c385f34447fba4511e04b1d1028a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f49eba8c864c3e893c6b1ba6f04768",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "39a437e801504f4782f049ff65ea71d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af06ad482b84968966f5bc1f6dde9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c068b96d5544c3e80836ec323f00e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b363a4be084db2bfdd98c4fe08e133",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6331897e562547fba3f62d4b009ea5e9",
            "value": 28
          }
        },
        "4287f832e2594b269b8f6ae48b885bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e031dbb97404ba7a27775a511b69ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_9670129efee148f78e2c720f5f89a0c5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "46534bf21d56434bbd640a1f1c0a869b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482368971ad34b2b90d95226231987a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44bb132f8774946a4ef51d8905e9406",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb227ecc4ab4008a5bd4c18eee24b3f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4d001b5f443e47ccabffd062d70695b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515c0a2698e945d7ac81eaba81432480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52632601b5194259b357010a316a87c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_482368971ad34b2b90d95226231987a7",
              "IPY_MODEL_3c068b96d5544c3e80836ec323f00e4c",
              "IPY_MODEL_7cbb4dda6ecd417ca2a228f9e75a1c9c"
            ],
            "layout": "IPY_MODEL_925841aa064d47908721220d5c2dc8a0"
          }
        },
        "59c6673701ea425ea0c7fea35767a5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b5e8e49cad4dea9a005c4a9332227c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9232b398bce42a5b845fc106907a114",
            "value": 570
          }
        },
        "5a31b0da8dad42eea5297c17f28c1ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88bb7dd6ad0c48c19d0e9a1ef46a646e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b5f103144da47e4bf668a2a31c8d6db",
            "value": 440449768
          }
        },
        "5b2168404943494f91df77dca5bcdc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cfbe3cbffe9483caed053cb35b90939": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60df71b9a7a04a83a89f7dbeb4003f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f91d5ef6106e48c99ca2296c91c3c321",
              "IPY_MODEL_9b54d69d732d4f77817e54fca8eba374",
              "IPY_MODEL_a89e5dae524748a5953c311618c94b08"
            ],
            "layout": "IPY_MODEL_b1c0e44b9f69418ea8dfeb4b32a000f8"
          }
        },
        "6331897e562547fba3f62d4b009ea5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d9d76219d2644419b1ad08553f6237c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f78f69f9834809a0d621aa1ec23bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7385490df52c44c18044d35bae7c37e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28d6656e9af4043aa86cafb8dd5a644",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b2168404943494f91df77dca5bcdc6d",
            "value": 466062
          }
        },
        "73c8c385f34447fba4511e04b1d1028a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7998ae84e4344bc88cf96162c8c040de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a874d40f81d48cb845f4d5dd83e7909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbb4dda6ecd417ca2a228f9e75a1c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1491196238948d398317aaa15adf68c",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c14f35fb284e37bbea0f0e876957bb",
            "value": " 28.0/28.0 [00:00&lt;00:00, 453B/s]"
          }
        },
        "83b58655255041338750df563867d4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "878f2c1cf6b84f9c96be43719570b6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af06ad482b84968966f5bc1f6dde9ac",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9e2bc1c9e14a71b1860acf10a72025",
            "value": " 267/267 [00:00&lt;00:00, 735.68 examples/s]"
          }
        },
        "88a1037651ca482f9baf03f24f56d34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88bb7dd6ad0c48c19d0e9a1ef46a646e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c2fedef5264a1e94592256bcf36eff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9e2bc1c9e14a71b1860acf10a72025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc20f969e6647cea734eecad6fc5ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_371e79d8d05e48bd8b59efcfcc010bb2",
              "IPY_MODEL_59c6673701ea425ea0c7fea35767a5be",
              "IPY_MODEL_f1854c5107ef4cd9949e8f54d27a8905"
            ],
            "layout": "IPY_MODEL_5cfbe3cbffe9483caed053cb35b90939"
          }
        },
        "8fb227ecc4ab4008a5bd4c18eee24b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925841aa064d47908721220d5c2dc8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9268c5df10f94577ba3f2a1fab5b0595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "961ed0414e5a4c62b78b2f10f1263145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9670129efee148f78e2c720f5f89a0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cdd6461b3b46a9aab314fabdc70caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d001b5f443e47ccabffd062d70695b4",
            "placeholder": "​",
            "style": "IPY_MODEL_02a2dd3734c5481ea6b4c54f33d6121c",
            "value": " 440M/440M [00:06&lt;00:00, 103MB/s]"
          }
        },
        "99727414bc1146578aa17513e14e697b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b54d69d732d4f77817e54fca8eba374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c95041aaa17485cb4a09ed0c19d5aa2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83b58655255041338750df563867d4f7",
            "value": 231508
          }
        },
        "9c95041aaa17485cb4a09ed0c19d5aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e031dbb97404ba7a27775a511b69ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f49eba8c864c3e893c6b1ba6f04768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a417965cba7e4256b39a584f60c4f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e4f8658078472caeedcff6038e236a",
            "placeholder": "​",
            "style": "IPY_MODEL_2c162df50a1f4114ae9a108a7d1c30e5",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a4c14f35fb284e37bbea0f0e876957bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a89e5dae524748a5953c311618c94b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c2fedef5264a1e94592256bcf36eff",
            "placeholder": "​",
            "style": "IPY_MODEL_46534bf21d56434bbd640a1f1c0a869b",
            "value": " 232k/232k [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "ab76c2cada82457ba9561bffc84576bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af493b1c2c1b40c5ab2db58497fbdd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7998ae84e4344bc88cf96162c8c040de",
            "max": 267,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_515c0a2698e945d7ac81eaba81432480",
            "value": 267
          }
        },
        "b1c0e44b9f69418ea8dfeb4b32a000f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b2679af34f4bd484b6f8b0e43e6449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd63c4f7f92b42b5afd8bc5858b88a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e3e46efcb04d6abb0bf8e23161f9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b2679af34f4bd484b6f8b0e43e6449",
            "placeholder": "​",
            "style": "IPY_MODEL_71f78f69f9834809a0d621aa1ec23bb0",
            "value": " 250/500 [1:15:17&lt;1:14:33, 17.89s/it]"
          }
        },
        "d0e7378ee17e4d14beb86040e4e91a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f966b5e0e2a44868b76afe22ee15a51c",
            "placeholder": "​",
            "style": "IPY_MODEL_88a1037651ca482f9baf03f24f56d34f",
            "value": " 466k/466k [00:00&lt;00:00, 6.74MB/s]"
          }
        },
        "d1491196238948d398317aaa15adf68c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44bb132f8774946a4ef51d8905e9406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9232b398bce42a5b845fc106907a114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da836073426b4f0382c174f733e6b632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a417965cba7e4256b39a584f60c4f039",
              "IPY_MODEL_5a31b0da8dad42eea5297c17f28c1ea9",
              "IPY_MODEL_98cdd6461b3b46a9aab314fabdc70caf"
            ],
            "layout": "IPY_MODEL_ab76c2cada82457ba9561bffc84576bc"
          }
        },
        "f1854c5107ef4cd9949e8f54d27a8905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22afb4a1f09644778bf4bb10c687644b",
            "placeholder": "​",
            "style": "IPY_MODEL_39a437e801504f4782f049ff65ea71d2",
            "value": " 570/570 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "f1e4f8658078472caeedcff6038e236a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28d6656e9af4043aa86cafb8dd5a644": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b5e8e49cad4dea9a005c4a9332227c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3311eaaaa634a25b15b696bd597ced0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99727414bc1146578aa17513e14e697b",
            "placeholder": "​",
            "style": "IPY_MODEL_1761b91723a845728299f470d05c9f5e",
            "value": " 50%"
          }
        },
        "f63a9a360181468a991009b14a271a46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91d5ef6106e48c99ca2296c91c3c321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a874d40f81d48cb845f4d5dd83e7909",
            "placeholder": "​",
            "style": "IPY_MODEL_9268c5df10f94577ba3f2a1fab5b0595",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "f966b5e0e2a44868b76afe22ee15a51c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
