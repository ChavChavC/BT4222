{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EI_IQ81m1PrW",
        "outputId": "f26b8d0b-2584-4f86-e469-ceda84b3cb11"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datasets in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (2.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (1.20.3)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (13.0.0)\n",
            "Requirement already satisfied: dill<0.3.7,>=0.3.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (0.3.6)\n",
            "Requirement already satisfied: pandas in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (4.64.1)\n",
            "Requirement already satisfied: xxhash in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.11.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (2023.4.0)\n",
            "Requirement already satisfied: aiohttp in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (3.8.3)\n",
            "Requirement already satisfied: huggingface-hub<1.0.0,>=0.2.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (0.10.1)\n",
            "Requirement already satisfied: packaging in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (0.18.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets) (5.4.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (22.1.0)\n",
            "Requirement already satisfied: charset-normalizer<3.0,>=2.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (2.0.4)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets) (1.2.0)\n",
            "Requirement already satisfied: filelock in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from huggingface-hub<1.0.0,>=0.2.0->datasets) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from packaging->datasets) (3.0.9)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->datasets) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->datasets) (2022.6)\n",
            "Requirement already satisfied: six>=1.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: torch in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (1.12.1)\n",
            "Requirement already satisfied: typing-extensions in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from torch) (4.4.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: transformers in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (4.20.1)\n",
            "Requirement already satisfied: filelock in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (3.7.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (0.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (1.20.3)\n",
            "Requirement already satisfied: packaging>=20.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (21.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (5.4.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (2022.10.31)\n",
            "Requirement already satisfied: requests in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (2.28.1)\n",
            "Requirement already satisfied: tokenizers!=0.11.3,<0.13,>=0.11.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (0.12.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from transformers) (4.64.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from huggingface-hub<1.0,>=0.1.0->transformers) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from packaging>=20.0->transformers) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests->transformers) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests->transformers) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests->transformers) (2023.5.7)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
            "Requirement already satisfied: evaluate in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (0.4.1)\n",
            "Requirement already satisfied: datasets>=2.0.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (2.10.1)\n",
            "Requirement already satisfied: numpy>=1.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (1.20.3)\n",
            "Requirement already satisfied: dill in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (0.3.6)\n",
            "Requirement already satisfied: pandas in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (1.5.1)\n",
            "Requirement already satisfied: requests>=2.19.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (2.28.1)\n",
            "Requirement already satisfied: tqdm>=4.62.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (4.64.1)\n",
            "Requirement already satisfied: xxhash in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (3.3.0)\n",
            "Requirement already satisfied: multiprocess in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (0.70.14)\n",
            "Requirement already satisfied: fsspec[http]>=2021.05.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (2023.4.0)\n",
            "Requirement already satisfied: huggingface-hub>=0.7.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (0.10.1)\n",
            "Requirement already satisfied: packaging in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (21.3)\n",
            "Requirement already satisfied: responses<0.19 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from evaluate) (0.18.0)\n",
            "Requirement already satisfied: pyarrow>=6.0.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (13.0.0)\n",
            "Requirement already satisfied: aiohttp in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (3.8.3)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from datasets>=2.0.0->evaluate) (5.4.1)\n",
            "Requirement already satisfied: filelock in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (3.7.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from huggingface-hub>=0.7.0->evaluate) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from packaging->evaluate) (3.0.9)\n",
            "Requirement already satisfied: charset-normalizer<3,>=2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2.0.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (3.4)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (1.26.12)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from requests>=2.19.0->evaluate) (2023.5.7)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->evaluate) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from pandas->evaluate) (2022.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (22.1.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.0.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (4.0.2)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.8.1)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.2.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/maximyam/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages (from python-dateutil>=2.8.1->pandas->evaluate) (1.16.0)\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m23.2.1\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m23.3.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install datasets\n",
        "!pip install torch\n",
        "!pip install transformers\n",
        "!pip install evaluate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRa2gDzCmQFr",
        "outputId": "b0658b82-b288-4cd5-8c02-c8fa824b0ba1"
      },
      "outputs": [],
      "source": [
        "# import torch\n",
        "# torch.cuda.current_device()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "df = pd.read_csv('new_data.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>title</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Gildan Activewear Reports Strong Results for t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRILLION ENERGY ANNOUNCES FLOW TEST RESULTS FO...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>CAPREIT Announces October Distribution</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Unigold Inc Delivers Positive Feasibility Stud...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Wallbridge Provides Update on Archer Explorati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               title  labels\n",
              "0  Gildan Activewear Reports Strong Results for t...       2\n",
              "1  TRILLION ENERGY ANNOUNCES FLOW TEST RESULTS FO...       2\n",
              "2             CAPREIT Announces October Distribution       1\n",
              "3  Unigold Inc Delivers Positive Feasibility Stud...       2\n",
              "4  Wallbridge Provides Update on Archer Explorati...       1"
            ]
          },
          "execution_count": 14,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(df, test_size=0.2)\n",
        "#df.shape (13702, 2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [],
      "source": [
        "X_train, X_val, y_train, y_val = train_test_split(train_data[\"title\"], train_data[\"labels\"], test_size=0.2, shuffle=True, random_state=4222)\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "vectorizer = CountVectorizer().fit(X_train)\n",
        "X_train_count = vectorizer.transform(X_train)\n",
        "X_val_count = vectorizer.transform(X_val)\n",
        "transformer = TfidfTransformer().fit(X_train_count)\n",
        "X_train_feature = transformer.transform(X_train_count)\n",
        "X_val_feature = transformer.transform(X_val_count)\n",
        "\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data[\"title\"], train_data[\"labels\"], test_size=0.2, shuffle=True, random_state=4222)\n",
        "ngram_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "ngram_matrix_train = ngram_vectorizer.fit_transform(X_train)\n",
        "ngram_matrix_val = ngram_vectorizer.transform(X_val)\n",
        "ngram_dense_matrix_train = ngram_matrix_train.todense()\n",
        "ngram_dense_matrix_val = ngram_matrix_val.todense()\n",
        "\n",
        "#xtrain - 8768\n",
        "#xval - 2193"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eXGvzpLFfZsG"
      },
      "source": [
        "# Word2Vec\n",
        "Pre trained model does not work well with OOB due to financial jargon"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AZD6tChvjuiY",
        "outputId": "f7a7ac0e-c981-4c5b-8de9-4c992289b794"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "glove.6B.zip        100%[===================>] 822.24M  5.00MB/s    in 2m 39s  \n",
            "\n",
            "2023-11-05 08:20:08 (5.17 MB/s) - ‘glove.6B.zip’ saved [862182613/862182613]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget http://nlp.stanford.edu/data/glove.6B.zip\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rUTN2Ni_j1EZ",
        "outputId": "9c81d599-eed5-409c-dd90-3fa9f6412f98"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Archive:  glove.6B.zip\n",
            "  inflating: glove.6B.50d.txt        \n",
            "  inflating: glove.6B.100d.txt       \n",
            "  inflating: glove.6B.200d.txt       \n",
            "  inflating: glove.6B.300d.txt       \n"
          ]
        }
      ],
      "source": [
        "!unzip glove*.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "id": "QD8UED1hkowN",
        "outputId": "ed8249e6-3cd5-4c6f-c19d-9a78d315c577"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'/content'"
            ]
          },
          "execution_count": 21,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import os\n",
        "os.getcwd()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5OkjYPn_gl0C",
        "outputId": "3cfaabd4-71c4-443c-a8bd-ebb7e14b0850"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.10/dist-packages (4.3.2)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.23.5)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.10/dist-packages (from gensim) (1.11.3)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.10/dist-packages (from gensim) (6.4.0)\n",
            "Requirement already satisfied: nltk in /usr/local/lib/python3.10/dist-packages (3.8.1)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.10/dist-packages (from nltk) (8.1.7)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.10/dist-packages (from nltk) (1.3.2)\n",
            "Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.10/dist-packages (from nltk) (2023.6.3)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from nltk) (4.66.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install gensim\n",
        "!pip install nltk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "eyUOM-4Jh4B-"
      },
      "outputs": [],
      "source": [
        "from keras.preprocessing.text import Tokenizer\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "9p9gH-8kjpoI"
      },
      "outputs": [],
      "source": [
        "embeddings_dict = {}\n",
        "with open('glove.6B.50d.txt','rb') as f:\n",
        "    for line in f:\n",
        "        values = line.split()\n",
        "        word = values[0]\n",
        "        vector = np.asarray(values[1:], \"float32\")\n",
        "        embeddings_dict[word] = vector"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZEqmO-Zk7w5",
        "outputId": "0bd2b5d7-8c85-454b-9f55-5e1783364c63"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([ 0.13175 , -0.25517 , -0.067915,  0.26193 , -0.26155 ,  0.23569 ,\n",
              "        0.13077 , -0.011801,  1.7659  ,  0.20781 ,  0.26198 , -0.16428 ,\n",
              "       -0.84642 ,  0.020094,  0.070176,  0.39778 ,  0.15278 , -0.20213 ,\n",
              "       -1.6184  , -0.54327 , -0.17856 ,  0.53894 ,  0.49868 , -0.10171 ,\n",
              "        0.66265 , -1.7051  ,  0.057193, -0.32405 , -0.66835 ,  0.26654 ,\n",
              "        2.842   ,  0.26844 , -0.59537 , -0.5004  ,  1.5199  ,  0.039641,\n",
              "        1.6659  ,  0.99758 , -0.5597  , -0.70493 , -0.0309  , -0.28302 ,\n",
              "       -0.13564 ,  0.6429  ,  0.41491 ,  1.2362  ,  0.76587 ,  0.97798 ,\n",
              "        0.58507 , -0.30176 ], dtype=float32)"
            ]
          },
          "execution_count": 34,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "embeddings_dict[b'test']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "B2LYXKV3h_DW"
      },
      "outputs": [],
      "source": [
        "sents = ['Hi I am Maxim']\n",
        "MAX_NUM_WORDS = 100\n",
        "MAX_SEQUENCE_LENGTH = 20\n",
        "tokenizer = Tokenizer(num_words=MAX_NUM_WORDS)\n",
        "tokenizer.fit_on_texts(sents)\n",
        "sequences = tokenizer.texts_to_sequences(sents)\n",
        "\n",
        "word_index = tokenizer.word_index\n",
        "data = pad_sequences(sequences, maxlen=MAX_SEQUENCE_LENGTH)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "zIIM9VRoSGEO",
        "outputId": "08f7d5eb-ed15-4374-c787-fffe4a5d8182"
      },
      "outputs": [
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-5270a4bce7f5>\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minitializers\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mConstant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0membeddings_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mEMBEDDING_DIM\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0membeddings_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mb'a'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mnum_words\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mMAX_NUM_WORDS\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_index\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_words\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEMBEDDING_DIM\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'shape'"
          ]
        }
      ],
      "source": [
        "from keras.layers import Embedding\n",
        "from keras.initializers import Constant\n",
        "embeddings_dict={}\n",
        "EMBEDDING_DIM = embeddings_dict.get(b'a').shape[0]\n",
        "num_words = min(MAX_NUM_WORDS, len(word_index)) + 1\n",
        "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
        "for word, i in word_index.items():\n",
        "    if i > MAX_NUM_WORDS:\n",
        "        continue\n",
        "    embedding_vector = embeddings_dict.get(word.encode(\"utf-8\"))\n",
        "    if embedding_vector is not None:\n",
        "        embedding_matrix[i] = embedding_vector"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HwmbntEXl9As"
      },
      "source": [
        "# FastText 2\n",
        "\n",
        "FastText helpss with OOB"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 138,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BcxzvcXEnmSw",
        "outputId": "614047a9-467f-4be4-81b7-3df84fd6eb02"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /Users/maximyam/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "execution_count": 138,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 140,
      "metadata": {
        "id": "49n006npnCbn"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "from nltk.tokenize import word_tokenize\n",
        "from gensim.models import FastText\n",
        "import numpy as np\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "train_data, test_data = train_test_split(df, test_size=0.2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 141,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X_EdV79R9nDk",
        "outputId": "3c643d6f-bfa9-41b9-ab43-8b024be64413"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "vector of the first training sentence: [ 1.07859995e-03  3.61997029e-03 -1.06006516e-02  1.73058058e-03\n",
            " -5.41980863e-02  3.17300335e-02 -1.98729942e-03 -1.05749136e-02\n",
            "  1.78253222e-02 -7.12216049e-02 -6.16450468e-03  1.34471208e-02\n",
            "  5.70243523e-02 -1.68132018e-02 -1.86934844e-02  1.99965481e-03\n",
            "  5.46533354e-02 -1.02992565e-03 -3.53736132e-02 -3.93695831e-02\n",
            " -1.07701672e-02 -5.01843058e-02 -1.91872586e-02  4.93549854e-02\n",
            " -2.46326886e-02  9.75399930e-03 -4.66964506e-02 -1.14517822e-03\n",
            " -2.52654497e-02 -8.49591917e-04 -3.36643495e-02  2.71644406e-02\n",
            " -9.41997860e-03 -2.80474741e-02  4.96958084e-02 -3.12904976e-02\n",
            "  5.24278022e-02 -2.66779419e-02  1.91196855e-02 -2.21440326e-02\n",
            "  1.17069099e-03  3.72060575e-02  3.02792508e-02  5.47939949e-02\n",
            "  1.02781681e-02  2.04283092e-02 -1.36556104e-02  8.78978427e-03\n",
            "  8.00075568e-03  9.10056103e-03  3.47839929e-02  2.22751256e-02\n",
            "  5.17173037e-02  3.42179351e-02 -5.20537645e-02  2.89380327e-02\n",
            "  6.29539266e-02  1.05549749e-04  1.01136804e-01  8.80398788e-03\n",
            "  4.95302454e-02  4.22860030e-03 -2.16390938e-02  4.48307358e-02\n",
            "  6.42435029e-02 -6.65897578e-02  9.36559886e-02  6.47399621e-03\n",
            "  4.31415476e-02 -2.64773332e-02 -1.19869709e-02  2.15750583e-03\n",
            " -2.80492418e-02  1.90271775e-03 -1.51378242e-02 -1.38379157e-01\n",
            " -8.71625990e-02 -3.86452340e-02  6.38651550e-02 -2.93288426e-03\n",
            "  2.11187433e-02  3.37598026e-02 -6.84300438e-02  2.77714152e-02\n",
            "  5.85866813e-03 -5.23812845e-02 -2.43838932e-02 -7.08004311e-02\n",
            " -2.69961301e-02 -1.12601379e-02  2.10059304e-02  9.12026968e-03\n",
            "  5.98833002e-02  6.95154890e-02  3.00355628e-02 -9.77145415e-03\n",
            "  2.35961564e-02  3.96226868e-02  4.56974544e-02 -4.03473862e-02\n",
            "  6.44097105e-02 -2.68273279e-02  1.55961299e-02  2.83211539e-03\n",
            " -3.72648388e-02 -2.84003075e-02 -4.94107716e-02  4.82889032e-03\n",
            "  4.23022732e-02 -7.76498392e-03  3.41376364e-02 -9.33251437e-03\n",
            " -4.82927784e-02 -6.99535199e-03 -3.46276611e-02  1.92270279e-02\n",
            " -1.19539341e-02 -6.49449751e-02 -1.60430912e-02  1.91900283e-02\n",
            "  9.99223739e-02  1.26284389e-02 -4.07705642e-02 -4.31482717e-02\n",
            " -2.27898452e-02  2.07672752e-02  1.06104255e-01  1.62571296e-02]\n"
          ]
        }
      ],
      "source": [
        "model = FastText(sentences=train_data['title'], vector_size =128, window=7, min_count=3, epochs = 5, seed =42, sg =1 )\n",
        "wv = model.wv\n",
        "def get_sentence_vectors(sentences):\n",
        "    vectors = []\n",
        "    for sentence in sentences:\n",
        "        sentence_vectors = [wv[word] for word in sentence if word in wv]\n",
        "        vectors.append((np.mean(sentence_vectors, axis=0)))\n",
        "    return vectors\n",
        "\n",
        "train_vectors = get_sentence_vectors(train_data['title'])\n",
        "print(\"vector of the first training sentence:\", train_vectors[0])\n",
        "test_vectors = get_sentence_vectors(test_data['title'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X6SoFri6q3uk"
      },
      "source": [
        "# BERT Tokenizer 3\n",
        "BERT Tokenizer to deal with diff in text **size**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 144,
          "referenced_widgets": [
            "52632601b5194259b357010a316a87c3",
            "482368971ad34b2b90d95226231987a7",
            "3c068b96d5544c3e80836ec323f00e4c",
            "7cbb4dda6ecd417ca2a228f9e75a1c9c",
            "925841aa064d47908721220d5c2dc8a0",
            "d44bb132f8774946a4ef51d8905e9406",
            "8fb227ecc4ab4008a5bd4c18eee24b3f",
            "03b363a4be084db2bfdd98c4fe08e133",
            "6331897e562547fba3f62d4b009ea5e9",
            "d1491196238948d398317aaa15adf68c",
            "a4c14f35fb284e37bbea0f0e876957bb",
            "60df71b9a7a04a83a89f7dbeb4003f8a",
            "f91d5ef6106e48c99ca2296c91c3c321",
            "9b54d69d732d4f77817e54fca8eba374",
            "a89e5dae524748a5953c311618c94b08",
            "b1c0e44b9f69418ea8dfeb4b32a000f8",
            "7a874d40f81d48cb845f4d5dd83e7909",
            "9268c5df10f94577ba3f2a1fab5b0595",
            "9c95041aaa17485cb4a09ed0c19d5aa2",
            "83b58655255041338750df563867d4f7",
            "88c2fedef5264a1e94592256bcf36eff",
            "46534bf21d56434bbd640a1f1c0a869b",
            "187358e1308a4581884fc2f4fbde9a94",
            "4287f832e2594b269b8f6ae48b885bd1",
            "7385490df52c44c18044d35bae7c37e1",
            "d0e7378ee17e4d14beb86040e4e91a94",
            "6d9d76219d2644419b1ad08553f6237c",
            "9e031dbb97404ba7a27775a511b69ecd",
            "9670129efee148f78e2c720f5f89a0c5",
            "f28d6656e9af4043aa86cafb8dd5a644",
            "5b2168404943494f91df77dca5bcdc6d",
            "f966b5e0e2a44868b76afe22ee15a51c",
            "88a1037651ca482f9baf03f24f56d34f",
            "8dc20f969e6647cea734eecad6fc5ee7",
            "371e79d8d05e48bd8b59efcfcc010bb2",
            "59c6673701ea425ea0c7fea35767a5be",
            "f1854c5107ef4cd9949e8f54d27a8905",
            "5cfbe3cbffe9483caed053cb35b90939",
            "73c8c385f34447fba4511e04b1d1028a",
            "a3f49eba8c864c3e893c6b1ba6f04768",
            "f2b5e8e49cad4dea9a005c4a9332227c",
            "d9232b398bce42a5b845fc106907a114",
            "22afb4a1f09644778bf4bb10c687644b",
            "39a437e801504f4782f049ff65ea71d2"
          ]
        },
        "id": "MBZWq2hirvMf",
        "outputId": "8c57b602-164a-4d99-955f-dc28b0b403c8"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "52632601b5194259b357010a316a87c3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)okenizer_config.json:   0%|          | 0.00/28.0 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "60df71b9a7a04a83a89f7dbeb4003f8a",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)solve/main/vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "187358e1308a4581884fc2f4fbde9a94",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)/main/tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8dc20f969e6647cea734eecad6fc5ee7",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading (…)lve/main/config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from transformers import BertTokenizer\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FT5G8Rb8r2P4",
        "outputId": "0658e784-f707-475b-b852-2f3c69fa3ab3"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n"
          ]
        }
      ],
      "source": [
        "token_lens = []\n",
        "for txt in dataset['train']['summary_detail_with_title']:\n",
        "  tokens = tokenizer.encode(txt, max_length=512)\n",
        "  token_lens.append(len(tokens))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9jTaiBp-s7XI"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4vyJ9WhLstu6"
      },
      "outputs": [],
      "source": [
        "token_lens"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aKe63N4Zr5aV"
      },
      "outputs": [],
      "source": [
        "class GPReviewDataset(Dataset):\n",
        "\n",
        "  def __init__(self, reviews, targets, tokenizer, max_len):\n",
        "    self.reviews = reviews\n",
        "    self.targets = targets\n",
        "    self.tokenizer = tokenizer\n",
        "    self.max_len = max_len\n",
        "\n",
        "  def __len__(self):\n",
        "    return len(self.reviews)\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    review = str(self.reviews[item])\n",
        "    target = self.targets[item]\n",
        "\n",
        "    encoding = self.tokenizer.encode_plus(\n",
        "      review,\n",
        "      add_special_tokens=True,\n",
        "      max_length=self.max_len,\n",
        "      return_token_type_ids=False,\n",
        "      pad_to_max_length=True,\n",
        "      return_attention_mask=True,\n",
        "      return_tensors='pt',\n",
        "    )\n",
        "\n",
        "    return {\n",
        "      'review_text': review,\n",
        "      'input_ids': encoding['input_ids'].flatten(),\n",
        "      'attention_mask': encoding['attention_mask'].flatten(),\n",
        "      'targets': torch.tensor(target, dtype=torch.long)\n",
        "    }"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 268,
          "referenced_widgets": [
            "da836073426b4f0382c174f733e6b632",
            "a417965cba7e4256b39a584f60c4f039",
            "5a31b0da8dad42eea5297c17f28c1ea9",
            "98cdd6461b3b46a9aab314fabdc70caf",
            "ab76c2cada82457ba9561bffc84576bc",
            "f1e4f8658078472caeedcff6038e236a",
            "2c162df50a1f4114ae9a108a7d1c30e5",
            "88bb7dd6ad0c48c19d0e9a1ef46a646e",
            "0b5f103144da47e4bf668a2a31c8d6db",
            "4d001b5f443e47ccabffd062d70695b4",
            "02a2dd3734c5481ea6b4c54f33d6121c"
          ]
        },
        "id": "i_MfAlEal96S",
        "outputId": "29459f55-44a9-4716-82e6-dd4a57c79425"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "da836073426b4f0382c174f733e6b632",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Downloading model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "ename": "AttributeError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-48-7a582dedeaac>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"bert-base-uncased\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# get the embedding vector for the word \"example\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mexample_token_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvert_tokens_to_ids\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"example\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mexample_embedding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0membeddings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mword_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mexample_token_id\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mAttributeError\u001b[0m: 'Tokenizer' object has no attribute 'convert_tokens_to_ids'"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "from transformers import BertModel\n",
        "tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "model = BertModel.from_pretrained(\"bert-base-uncased\")\n",
        "# get the embedding vector for the word \"example\"\n",
        "example_token_id = tokenizer.convert_tokens_to_ids([\"example\"])[0]\n",
        "example_embedding = model.embeddings.word_embeddings(torch.tensor([example_token_id]))\n",
        "example_embedding\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tqRc1C4VmD_O"
      },
      "outputs": [],
      "source": [
        "# Load the BERT tokenizer from the \"bert-base-uncased\" pre-trained model\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "def tokenize_function(examples):\n",
        "# Tokenize the \"text\" column of the examples, adding padding to the maximum length and truncating if necessary\n",
        "        return tokenizer(examples[\"summary_detail_with_title\"], padding=\"max_length\", truncation=True)\n",
        "# Apply the tokenize function to the dataset in batches\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"summary_detail_with_title\"])\n",
        "# Rename the \"label\" column to \"labels\" to match the expected format for training\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# Shuffle the dataset with a fixed seed and select a range of examples\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ly4uiJ9jSGB-",
        "outputId": "922acceb-9202-468d-c43d-f14baee8fbde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        ...,\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0],\n",
              "        [1, 1, 1,  ..., 0, 0, 0]])"
            ]
          },
          "execution_count": 25,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "tokenized_datasets['train']['token_type_ids']\n",
        "tokenized_datasets['train']['attention_mask']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OJ9_GlGZSF_t",
        "outputId": "0e843344-dc2a-441e-80e1-2c3dd68cae32"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['input_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AlG6XdApSF9M",
        "outputId": "e287ec0c-643f-44a4-b338-e4315617b953"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 27,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['token_type_ids'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-Gdjve5SF6p",
        "outputId": "bc2e0389-780c-4dd6-c852-d20747825a13"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "1512"
            ]
          },
          "execution_count": 28,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len(tokenized_datasets['train']['attention_mask'])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wt_6x7vu7iWR"
      },
      "source": [
        "# ROBERTA,BERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "NwGEwgFuSF1Q"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "train_data = pd.DataFrame(dataset[\"train\"])\n",
        "X_train, X_val, y_train, y_val = train_test_split(train_data[\"summary_detail_with_title\"], train_data[\"labels\"], test_size=0.2, shuffle=True, random_state=4222)\n",
        "vectorizer = CountVectorizer().fit(X_train)\n",
        "X_train_count = vectorizer.transform(X_train)\n",
        "X_val_count = vectorizer.transform(X_val)\n",
        "transformer = TfidfTransformer().fit(X_train_count)\n",
        "X_train_feature = transformer.transform(X_train_count)\n",
        "X_val_feature = transformer.transform(X_val_count)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "u7fMydHI8pWC",
        "outputId": "28c21856-8b1f-44e0-f058-14c1bdc58ca7"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<1209x7640 sparse matrix of type '<class 'numpy.float64'>'\n",
              "\twith 51755 stored elements in Compressed Sparse Row format>"
            ]
          },
          "execution_count": 10,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train_feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ElfQ0ci38xCD"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define the first convolutional layer\n",
        "        self.conv1 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        # Define the batch normalization layer for the first conv layer\n",
        "        self.Bn1 = nn.BatchNorm1d(32)\n",
        "        # Define the max pooling layer for the first conv layer\n",
        "        self.pool1=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        self.Bn2 = nn.BatchNorm1d(32)\n",
        "        self.pool2=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        self.conv3 = nn.Conv1d(1, 32, 3, 1,1, bias=True)\n",
        "        self.Bn3 = nn.BatchNorm1d(32)\n",
        "        self.pool3=nn.MaxPool1d(kernel_size=5, stride=5)\n",
        "\n",
        "        # Define LSTM layer with input size of 960 and hidden size of 100\n",
        "        self.bi_lstm1 = nn.LSTM(input_size=960, hidden_size=100, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        # Define the first fully connected layer after LSTM\n",
        "        self.fc1 = nn.Linear(100, 100, bias=True)\n",
        "        # Define self-attention layer\n",
        "        self.self_attn_1 = nn.MultiheadAttention(embed_dim=100, num_heads=4)\n",
        "        # Define the final fully connected layer for classification\n",
        "        self.fc2 = nn.Linear(100, 5, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the first convolutional layer, then through the ReLU activation function, then through max pooling\n",
        "        x_layer1 = self.pool1(F.relu(self.Bn1(self.conv1(x))))\n",
        "        x_layer2 = self.pool1(F.relu(self.Bn2(self.conv2(x))))\n",
        "        x_layer3 = self.pool1(F.relu(self.Bn3(self.conv3(x))))\n",
        "        # Concatenate the outputs of the three layers along the channel dimension\n",
        "        x = torch.cat((x_layer1, x_layer2,x_layer3), 1)\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "\n",
        "        # Pass input through the LSTM layer\n",
        "        x, _ = self.bi_lstm1(x)\n",
        "        # Pass output of LSTM layer through the first fully connected layer, then through the ReLU activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Reshape the tensor for the self-attention layer\n",
        "        x = x.view(-1, 1, 100)\n",
        "        # Pass tensor through the self-attention layer\n",
        "        x, _ = self.self_attn_1(x.permute(1, 0, 2), x.permute(1, 0, 2), x.permute(1, 0, 2))\n",
        "        # Reshape tensor back to original shape\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.view(-1, 100)\n",
        "        # Pass the output through the final fully connected layer for classification\n",
        "        x = self.fc2(x)\n",
        "\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GMGO6oW6DEOz"
      },
      "source": [
        "Roberta"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Sdwnk0J5ocEx"
      },
      "outputs": [],
      "source": [
        "# # ROBERTA FIN BERT model\n",
        "# #Their own model\n",
        "# from transformers import AutoTokenizer, AutoModelForSequenceClassification,pipeline\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\"Jean-Baptiste/roberta-large-financial-news-sentiment-en\")\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"Jean-Baptiste/roberta-large-financial-news-sentiment-en\")\n",
        "\n",
        "# classifier=pipeline(\"text-classification\",model=model, tokenizer=tokenizer)\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iq3Y9auVVbLH"
      },
      "source": [
        "FinBERT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7IlXTNQRVKSr"
      },
      "outputs": [],
      "source": [
        "# Use a pipeline as a high-level helper\n",
        "from transformers import pipeline\n",
        "\n",
        "pipe = pipeline(\"text-classification\", model=\"ProsusAI/finbert\")\n",
        "# Load model directly\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"ProsusAI/finbert\")\n",
        "model = AutoModelForSequenceClassification.from_pretrained(\"ProsusAI/finbert\")\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zlk18uHBwjql"
      },
      "source": [
        "BERT/ Distilbert"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kI2uC53NwpT1"
      },
      "outputs": [],
      "source": [
        "modelname = \"bert-base-uncased\"\n",
        "modelname = \"distilbert-base-uncased\"\n",
        "modelname = \"distilbert-base-uncased\"\n",
        "\n",
        "\n",
        "# modelname = \"distilbert-base-uncased\"\n",
        "# id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2:\"POSITIVE\"}\n",
        "# label2id = {\"NEGATIVE\": 0, \"NEUTRAL\":1 , \"POSITIVE\": 2}\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        "# )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 49,
          "referenced_widgets": [
            "2fe15378930b4a97b98ec96f8e584e45",
            "2024bd3b639c48fc8b8815643564717d",
            "af493b1c2c1b40c5ab2db58497fbdd4d",
            "878f2c1cf6b84f9c96be43719570b6e1",
            "961ed0414e5a4c62b78b2f10f1263145",
            "bd63c4f7f92b42b5afd8bc5858b88a74",
            "35f02b3c6dbb4dbb8a6bd04bd181df79",
            "7998ae84e4344bc88cf96162c8c040de",
            "515c0a2698e945d7ac81eaba81432480",
            "3af06ad482b84968966f5bc1f6dde9ac",
            "8d9e2bc1c9e14a71b1860acf10a72025"
          ]
        },
        "id": "p1ZmUZ-5d3gz",
        "outputId": "1e92ea13-4f7f-4a52-8d41-3fc644b3212f"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2fe15378930b4a97b98ec96f8e584e45",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "Map:   0%|          | 0/267 [00:00<?, ? examples/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Load the BERT tokenizer from the \"bert-base-uncased\" pre-trained model\n",
        "from transformers import AutoTokenizer\n",
        "tokenizer = AutoTokenizer.from_pretrained(modelname)\n",
        "def tokenize_function(examples):\n",
        "# Tokenize the \"text\" column of the examples, adding padding to the maximum length and truncating if necessary\n",
        "        return tokenizer(examples[\"summary_detail_with_title\"], padding=\"max_length\", truncation=True)\n",
        "# Apply the tokenize function to the dataset in batches\n",
        "tokenized_datasets = dataset.map(tokenize_function, batched=True)\n",
        "tokenized_datasets = tokenized_datasets.remove_columns([\"summary_detail_with_title\"])\n",
        "# Rename the \"label\" column to \"labels\" to match the expected format for training\n",
        "tokenized_datasets.set_format(\"torch\")\n",
        "# Shuffle the dataset with a fixed seed and select a range of examples\n",
        "train_dataset = tokenized_datasets[\"train\"].shuffle(seed=42).select(range(1000))\n",
        "eval_dataset = tokenized_datasets[\"test\"].shuffle(seed=42).select(range(100))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Uxno9E1ogst2"
      },
      "outputs": [],
      "source": [
        "train_dataset = train_dataset.remove_columns(['summary_detail', 'title', 'topic',  '__index_level_0__',])\n",
        "eval_dataset = eval_dataset.remove_columns(['summary_detail', 'title', 'topic',  '__index_level_0__',])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uqxFJ-FteZwS"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader, RandomSampler, SequentialSampler,TensorDataset\n",
        "batchsize=4\n",
        "# Create Dataloader\n",
        "train_dataloader = DataLoader(train_dataset, shuffle=True, batch_size=batchsize)\n",
        "eval_dataloader = DataLoader(eval_dataset, batch_size=batchsize)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aCkeM5JFejCj",
        "outputId": "3f5da12a-f51b-4cbd-cdde-21eef5f98174"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertForMaskedLM: ['cls.seq_relationship.bias', 'cls.seq_relationship.weight', 'bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "- This IS expected if you are initializing BertForMaskedLM from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertForMaskedLM from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
          ]
        }
      ],
      "source": [
        "from transformers import AutoModelForMaskedLM\n",
        "# Because we initialized BertForMaskedLM and concat is with our classifier instead of directly using BertForSequenceClassification\n",
        "# Some weights of the model checkpoint at bert-base-uncased were not used is within the expectation.\n",
        "import torch\n",
        "from torch import nn\n",
        "from torch.nn import CrossEntropyLoss\n",
        "from torch.optim import AdamW\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self,output_dim,dropout_rate):\n",
        "        super(Model,self).__init__()\n",
        "        self.encoder=AutoModelForMaskedLM.from_pretrained(modelname, output_hidden_states=True, return_dict=True)\n",
        "        self.dropout=nn.Dropout(dropout_rate)\n",
        "        # For the \"bert-base-uncased\" model, each hidden state has a dimension of 768.\n",
        "        # the value 3072=4*768 corresponds to the total dimension of the concatenated hidden states from the BERT model.\n",
        "        self.classifier=nn.Linear(3072,output_dim)\n",
        "\n",
        "\n",
        "    def forward(self,input_ids,token_type_ids,attention_mask):\n",
        "        outputs = self.encoder(input_ids, token_type_ids=token_type_ids, attention_mask=attention_mask)\n",
        "        hidden_states = torch.cat(tuple([outputs.hidden_states[i] for i in [-1, -2, -3, -4]]), dim=-1) # [bs, seq_len, hidden_dim*4]\n",
        "        # We are actually extracting the hidden state of the [CLS] token for each sequence in the batch.\n",
        "        # This [CLS] token's hidden state is typically used as a fixed-size representation of the entire sequence.\n",
        "        # This representation has been learned during BERT's pretraining to capture important information for various tasks.\n",
        "        # In the context of classification, you can think of the [CLS] token's hidden state as a summary of the sequence's content,\n",
        "        # which is then fed into the linear classifier to make predictions for the task at hand.\n",
        "        x=self.dropout(hidden_states[:, 0, :])\n",
        "        x=self.classifier(x)\n",
        "        return x\n",
        "\n",
        "model = Model(output_dim=3, dropout_rate = 0.5)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "loss_fct = CrossEntropyLoss()\n",
        "optimizer = AdamW(model.parameters(), lr=5e-5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424,
          "referenced_widgets": [
            "314aa15a0dc642eeac4fe71108e558ff",
            "f3311eaaaa634a25b15b696bd597ced0",
            "17b7e31540be4d2493dd5cc3c0b5db8c",
            "c3e3e46efcb04d6abb0bf8e23161f9ef",
            "f63a9a360181468a991009b14a271a46",
            "99727414bc1146578aa17513e14e697b",
            "1761b91723a845728299f470d05c9f5e",
            "0e730ba0c9d242849d18cb062a78f57b",
            "0d7b1eee53da43caacb1075066cb4204",
            "b7b2679af34f4bd484b6f8b0e43e6449",
            "71f78f69f9834809a0d621aa1ec23bb0"
          ]
        },
        "id": "M1ml663Hes61",
        "outputId": "8b2524b7-b04d-44e3-8dca-f55bf1a16002"
      },
      "outputs": [],
      "source": [
        "from transformers import get_scheduler\n",
        "from tqdm.auto import tqdm\n",
        "import evaluate\n",
        "\n",
        "epochs = 2\n",
        "num_training_steps = epochs * len(train_dataloader)\n",
        "lr_scheduler = get_scheduler(\n",
        "name=\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps\n",
        "    )\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "progress_bar = tqdm(range(num_training_steps))\n",
        "\n",
        "\n",
        "for epoch in range(epochs):\n",
        "        for batch in train_dataloader:\n",
        "            model.train()\n",
        "            # Loop through batches in the training data loader\n",
        "            label_ids = batch['labels']\n",
        "            input_ids = batch['input_ids']\n",
        "            token_type_ids = None\n",
        "            # When using BERT for tasks like single-text classification or sequence labeling, the token_type_ids is an optional parameter, commonly set to None.\n",
        "            attention_mask = batch['attention_mask']\n",
        "            # Perform a forward pass through the model to get logits\n",
        "            logits = model(input_ids, token_type_ids, attention_mask)\n",
        "\n",
        "            # Calculate the loss using the provided loss function\n",
        "            loss = loss_fct(logits, label_ids.view(-1))\n",
        "            # Perform backward pass and update model parameters\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            lr_scheduler.step()\n",
        "            optimizer.zero_grad() # Clear accumulated gradients\n",
        "            progress_bar.update(1) # Update progress bar\n",
        "\n",
        "        # Set the model to evaluation mode for validation\n",
        "        model.eval()\n",
        "        for batch in eval_dataloader:\n",
        "            batch = {k: v.to(device) for k, v in batch.items()}\n",
        "            with torch.no_grad(): # disable gradient computation\n",
        "                label_ids = batch['labels']\n",
        "                input_ids = batch['input_ids']\n",
        "                token_type_ids = None\n",
        "                attention_mask = batch['attention_mask']\n",
        "                logits = model(input_ids, token_type_ids, attention_mask)\n",
        "                loss = loss_fct(logits, label_ids.view(-1))\n",
        "\n",
        "            # Get predicted labels by selecting the class with the highest probability\n",
        "            predictions = torch.argmax(logits, dim=-1)\n",
        "            metric.add_batch(predictions=predictions, references=batch[\"labels\"])\n",
        "\n",
        "        acc = metric.compute()\n",
        "        print(f'Epoch {epoch+1}')\n",
        "        print(f'val_loss : {loss}')\n",
        "        print(f\"val_accuracy: {acc['accuracy'] * 100}\")\n",
        "        print(25*'==')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xdvc_fOYRx6z"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dv0FaC3fon4C"
      },
      "outputs": [],
      "source": [
        "# # D\n",
        "# #Their own model\n",
        "# from transformers import DistilBertTokenizer, DistilBertModel\n",
        "# from transformers import AutoModelForSequenceClassification, TrainingArguments, Trainer,DataCollatorWithPadding\n",
        "# import numpy as np\n",
        "# import evaluate\n",
        "\n",
        "# tokenizer = AutoTokenizer.from_pretrained(\"distilbert-base-uncased\")\n",
        "\n",
        "# id2label = {0: \"NEGATIVE\", 1: \"NEUTRAL\", 2:\"POSITIVE\"}\n",
        "# label2id = {\"NEGATIVE\": 0, \"NEUTRAL\":1 , \"POSITIVE\": 2}\n",
        "\n",
        "\n",
        "# model = AutoModelForSequenceClassification.from_pretrained(\n",
        "#     \"distilbert-base-uncased\", num_labels=3, id2label=id2label, label2id=label2id\n",
        "# )\n",
        "\n",
        "# data_collator = DataCollatorWithPadding(tokenizer=tokenizer)\n",
        "# accuracy = evaluate.load(\"accuracy\")\n",
        "# def compute_metrics(eval_pred):\n",
        "#     predictions, labels = eval_pred\n",
        "#     predictions = np.argmax(predictions, axis=1)\n",
        "#     return accuracy.compute(predictions=predictions, references=labels)\n",
        "\n",
        "# training_args = TrainingArguments(\n",
        "#     output_dir=\"my_awesome_model\",\n",
        "#     learning_rate=2e-5,\n",
        "#     per_device_train_batch_size=16,\n",
        "#     per_device_eval_batch_size=16,\n",
        "#     num_train_epochs=2,\n",
        "#     weight_decay=0.01,\n",
        "#     evaluation_strategy=\"epoch\",\n",
        "#     save_strategy=\"epoch\",\n",
        "#     load_best_model_at_end=True,\n",
        "#     push_to_hub=True,\n",
        "# )\n",
        "\n",
        "# trainer = Trainer(\n",
        "#     model=model,\n",
        "#     args=training_args,\n",
        "#     train_dataset=dataset[\"train\"],\n",
        "#     eval_dataset=dataset[\"test\"],\n",
        "#     tokenizer=tokenizer,\n",
        "#     data_collator=DataCollatorWithPadding(tokenizer=tokenizer),\n",
        "#     compute_metrics=compute_metrics,\n",
        "# )\n",
        "\n",
        "# trainer.train()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "x_wqbOA8yJq5"
      },
      "outputs": [],
      "source": [
        "# classifier=pipeline(\"text-classification\",model=model, tokenizer=tokenizer)\n",
        "# output=classifier(dataset['train']['summary_detail_with_title'][0])\n",
        "# print(output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cu4wwQ-E7ehC"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zEjgfz7O-zhb"
      },
      "source": [
        "# test - currently working on this, run fasttext first to attain vecs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {
        "id": "kE3wsVDh-yJo"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(2193, 72170)"
            ]
          },
          "execution_count": 30,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "#train_vectors = X_train_feature \n",
        "train_vectors = ngram_dense_matrix_train\n",
        "train_labels = y_train\n",
        "#test_vectors = X_val_feature \n",
        "test_vectors = ngram_dense_matrix_val\n",
        "test_labels = y_val\n",
        "\n",
        "train_vectors1 = torch.Tensor(train_vectors).reshape(len(train_vectors),1,72170)\n",
        "# train_vectors1.shape\n",
        "test_vectors1 = torch.Tensor(test_vectors).reshape(len(test_vectors),1,72170)\n",
        "# test_vectors1.shape\n",
        "train_labels1 = torch.Tensor(train_labels)\n",
        "test_labels1 = torch.Tensor(test_labels.values)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 52,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bVX3e4YYPMAx",
        "outputId": "1a23a24b-7b7a-4f5d-a3c0-18af3c5beb45"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([10961, 1, 128])\n",
            "torch.Size([10961])\n",
            "torch.Size([2741, 1, 128])\n",
            "torch.Size([2741])\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors1.shape)\n",
        "print(train_labels1.shape)\n",
        "print(test_vectors1.shape)\n",
        "print(test_labels1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 151,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 169
        },
        "id": "2MbceMFiO-8i",
        "outputId": "2c2adf99-eecf-4303-e88f-ffeb03f5a76c"
      },
      "outputs": [],
      "source": [
        "train_labels = train_data['labels']\n",
        "test_labels = test_data['labels']\n",
        "train_labels1 = torch.Tensor(train_labels)\n",
        "test_labels1 = torch.Tensor(test_labels.values)\n",
        "train_vectors1 = torch.Tensor(train_vectors).reshape(len(train_vectors),1,128)\n",
        "test_vectors1 = torch.Tensor(test_vectors).reshape(len(test_vectors),1,128)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 152,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tuQJ7vn4Nv4W",
        "outputId": "6516d3f2-b4ec-4265-858c-e3f0d7f67d63"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<built-in method size of Tensor object at 0x7b00b58e67f0>\n",
            "torch.Size([1512, 1, 128])\n",
            "<built-in method size of Tensor object at 0x7b00b58fe930>\n",
            "torch.Size([1, 128])\n",
            "torch.float32\n",
            "torch.float32\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors1.size)\n",
        "print(train_vectors1.shape)\n",
        "print(train_vectors1[0].size)\n",
        "print(train_vectors1[0].shape)\n",
        "print(train_vectors1.dtype)\n",
        "print(train_vectors1[0].dtype)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 117,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rdlSt2r-Kx7_",
        "outputId": "3cdfc922-4552-4773-edf9-76e50763886b"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "267"
            ]
          },
          "execution_count": 117,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "test_vectors1.size(0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-dKhmkInIfIk",
        "outputId": "71455f20-0306-4d2b-f904-ae8cd96e9103"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "torch.Size([8768, 1, 72170])\n"
          ]
        }
      ],
      "source": [
        "print(train_vectors1.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 62,
      "metadata": {
        "id": "pYnPEeN6EPs0"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torch.optim as optim\n",
        "from torchvision import datasets, transforms\n",
        "from torch.optim.lr_scheduler import StepLR"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(tensor([0., 1., 2.]), tensor([1172, 5607, 1989]))"
            ]
          },
          "execution_count": 118,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "train_labels1.unique(return_counts=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "28868"
            ]
          },
          "execution_count": 85,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 134,
      "metadata": {
        "id": "IOJEvkzHECGN"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        # Define the first convolutional layer\n",
        "        self.conv1 = nn.Conv1d(1, 4, 3, 1,1, bias=True)\n",
        "        # Define the batch normalization layer for the first conv layer\n",
        "        self.Bn1 = nn.BatchNorm1d(4)\n",
        "        # Define the max pooling layer for the first conv layer\n",
        "        self.pool1=nn.MaxPool1d(kernel_size=3, stride=3)\n",
        "\n",
        "        self.conv2 = nn.Conv1d(1, 4, 3, 1,1, bias=True)\n",
        "        self.Bn2 = nn.BatchNorm1d(4)\n",
        "        self.pool2=nn.MaxPool1d(kernel_size=3, stride=3)\n",
        "\n",
        "        self.bi_lstm1 = nn.LSTM(input_size=192448, hidden_size=100, num_layers=1, batch_first=True, bidirectional=False)\n",
        "        self.fc1 = nn.Linear(100, 100, bias=True)\n",
        "        self.self_attn_1 = nn.MultiheadAttention(embed_dim=100, num_heads=4)\n",
        "        self.fc2 = nn.Linear(100, 3, bias=True)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Pass input through the first convolutional layer, then through the ReLU activation function, then through max pooling\n",
        "        x_layer1 = self.pool1(F.relu(self.Bn1(self.conv1(x))))\n",
        "        x_layer2 = self.pool1(F.relu(self.Bn2(self.conv2(x))))\n",
        "        # Concatenate the outputs of the three layers along the channel dimension\n",
        "\n",
        "        x = torch.cat((x_layer1, x_layer2), 1)\n",
        "\n",
        "        # Flatten the tensor for the fully connected layers\n",
        "        x = torch.flatten(x, 1)\n",
        "        # Pass input through the LSTM layer\n",
        "        x, _ = self.bi_lstm1(x)\n",
        "        # Pass output of LSTM layer through the first fully connected layer, then through the ReLU activation function\n",
        "        x = F.relu(self.fc1(x))\n",
        "        # Reshape the tensor for the self-attention layer\n",
        "        x = x.view(-1, 1, 100)\n",
        "        # Pass tensor through the self-attention layer\n",
        "        x, _ = self.self_attn_1(x.permute(1, 0, 2), x.permute(1, 0, 2), x.permute(1, 0, 2))\n",
        "        # Reshape tensor back to original shape\n",
        "        x = x.permute(1, 0, 2)\n",
        "        x = x.view(-1, 100)\n",
        "        # Pass the output through the final fully connected layer for classification\n",
        "        x = self.fc2(x)\n",
        "        return x\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 135,
      "metadata": {
        "id": "KiLBgphoEBqq"
      },
      "outputs": [],
      "source": [
        "def train(args, model, device, train_loader, optimizer, epoch):\n",
        "    model.train()  # Set the model to training mode\n",
        "\n",
        "    for batch_idx, (data, target) in enumerate(train_loader):  # Loop over each batch from the training set\n",
        "        data, target = data.to(device), target.to(device)  # Move the data to the device that is used\n",
        "\n",
        "        target = target  # Adjust the target values (Moving 1-5 to 0-4  for easy training)\n",
        "        target = target.long()  # Make sure that target data is long type (necessary for loss function)\n",
        "\n",
        "        optimizer.zero_grad()  # Clear gradients from the previous training step\n",
        "        output = model(data)  # Run forward pass (model predictions)\n",
        "\n",
        "        loss = F.cross_entropy(output, target)  # Calculate the loss between the output and target\n",
        "        loss.backward()  # Perform backpropagation (calculate gradients of loss w.r.t. parameters)\n",
        "        optimizer.step()  # Update the model parameters\n",
        "\n",
        "        if batch_idx % args.log_interval == 0:  # Print log info for specified interval\n",
        "            print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(epoch, batch_idx * len(data), len(train_loader.dataset),100. * batch_idx / len(train_loader), loss.item()))\n",
        "\n",
        "\n",
        "\n",
        "def test(model, device, test_loader):\n",
        "    model.eval()  # Set the model to evaluation mode\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():  # Deactivates autograd, reduces memory usage and speeds up computations\n",
        "        for data, target in test_loader:  # Loop over each batch from the testing set\n",
        "            data, target = data.to(device), target.to(device)  # Move the data to the device that is used\n",
        "            target = target-1  # Adjust the target values\n",
        "            output = model(data)  # Run forward pass (model predictions)\n",
        "            pred = output.argmax(dim=1, keepdim=True)  # Get the index of the max log-probability as the predicted output\n",
        "            correct += pred.eq(target.view_as(pred)).sum().item()  # Count correct predictions\n",
        "\n",
        "    test_loss /= len(test_loader.dataset)  # Calculate the average loss\n",
        "\n",
        "    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}/{} ({:.0f}%)\\n'.format(test_loss, correct, len(test_loader.dataset),100. * correct / len(test_loader.dataset)))\n",
        "    return correct  # Return the number of correctly classified samples\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 136,
      "metadata": {
        "id": "xreTSnllEW9Q"
      },
      "outputs": [],
      "source": [
        "class Args:\n",
        "  epochs = 10\n",
        "  lr = 1.0\n",
        "  use_cuda=False\n",
        "  gamma = 0.7\n",
        "  log_interval = 10\n",
        "  no_cuda = False\n",
        "  seed = 1\n",
        "\n",
        "args = Args()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 137,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 918
        },
        "id": "FkNCa8kX_Bno",
        "outputId": "5f41f665-3bba-4d94-c706-bf048b8fe08e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "conv1.weight \t torch.Size([4, 1, 3])\n",
            "conv1.bias \t torch.Size([4])\n",
            "Bn1.weight \t torch.Size([4])\n",
            "Bn1.bias \t torch.Size([4])\n",
            "Bn1.running_mean \t torch.Size([4])\n",
            "Bn1.running_var \t torch.Size([4])\n",
            "Bn1.num_batches_tracked \t torch.Size([])\n",
            "conv2.weight \t torch.Size([4, 1, 3])\n",
            "conv2.bias \t torch.Size([4])\n",
            "Bn2.weight \t torch.Size([4])\n",
            "Bn2.bias \t torch.Size([4])\n",
            "Bn2.running_mean \t torch.Size([4])\n",
            "Bn2.running_var \t torch.Size([4])\n",
            "Bn2.num_batches_tracked \t torch.Size([])\n",
            "bi_lstm1.weight_ih_l0 \t torch.Size([400, 192448])\n",
            "bi_lstm1.weight_hh_l0 \t torch.Size([400, 100])\n",
            "bi_lstm1.bias_ih_l0 \t torch.Size([400])\n",
            "bi_lstm1.bias_hh_l0 \t torch.Size([400])\n",
            "fc1.weight \t torch.Size([100, 100])\n",
            "fc1.bias \t torch.Size([100])\n",
            "self_attn_1.in_proj_weight \t torch.Size([300, 100])\n",
            "self_attn_1.in_proj_bias \t torch.Size([300])\n",
            "self_attn_1.out_proj.weight \t torch.Size([100, 100])\n",
            "self_attn_1.out_proj.bias \t torch.Size([100])\n",
            "fc2.weight \t torch.Size([3, 100])\n",
            "fc2.bias \t torch.Size([3])\n",
            "Train Epoch: 1 [0/8768 (0%)]\tLoss: 1.114502\n",
            "Train Epoch: 1 [80/8768 (1%)]\tLoss: 1.182757\n",
            "Train Epoch: 1 [160/8768 (2%)]\tLoss: 1.146704\n",
            "Train Epoch: 1 [240/8768 (3%)]\tLoss: 1.165100\n",
            "Train Epoch: 1 [320/8768 (4%)]\tLoss: 0.598568\n",
            "Train Epoch: 1 [400/8768 (5%)]\tLoss: 0.902771\n",
            "Train Epoch: 1 [480/8768 (5%)]\tLoss: 0.977032\n",
            "Train Epoch: 1 [560/8768 (6%)]\tLoss: 1.057747\n",
            "Train Epoch: 1 [640/8768 (7%)]\tLoss: 0.880586\n",
            "Train Epoch: 1 [720/8768 (8%)]\tLoss: 0.597423\n",
            "Train Epoch: 1 [800/8768 (9%)]\tLoss: 0.832806\n",
            "Train Epoch: 1 [880/8768 (10%)]\tLoss: 1.180685\n",
            "Train Epoch: 1 [960/8768 (11%)]\tLoss: 1.354123\n",
            "Train Epoch: 1 [1040/8768 (12%)]\tLoss: 1.193741\n",
            "Train Epoch: 1 [1120/8768 (13%)]\tLoss: 1.365500\n",
            "Train Epoch: 1 [1200/8768 (14%)]\tLoss: 0.973261\n",
            "Train Epoch: 1 [1280/8768 (15%)]\tLoss: 0.896986\n",
            "Train Epoch: 1 [1360/8768 (16%)]\tLoss: 1.530815\n",
            "Train Epoch: 1 [1440/8768 (16%)]\tLoss: 0.946564\n",
            "Train Epoch: 1 [1520/8768 (17%)]\tLoss: 0.960822\n",
            "Train Epoch: 1 [1600/8768 (18%)]\tLoss: 0.881764\n",
            "Train Epoch: 1 [1680/8768 (19%)]\tLoss: 0.673594\n",
            "Train Epoch: 1 [1760/8768 (20%)]\tLoss: 1.637211\n",
            "Train Epoch: 1 [1840/8768 (21%)]\tLoss: 0.784499\n",
            "Train Epoch: 1 [1920/8768 (22%)]\tLoss: 0.981565\n",
            "Train Epoch: 1 [2000/8768 (23%)]\tLoss: 0.861580\n",
            "Train Epoch: 1 [2080/8768 (24%)]\tLoss: 0.817793\n",
            "Train Epoch: 1 [2160/8768 (25%)]\tLoss: 0.903663\n",
            "Train Epoch: 1 [2240/8768 (26%)]\tLoss: 0.557083\n",
            "Train Epoch: 1 [2320/8768 (26%)]\tLoss: 0.499356\n",
            "Train Epoch: 1 [2400/8768 (27%)]\tLoss: 1.293547\n",
            "Train Epoch: 1 [2480/8768 (28%)]\tLoss: 0.717161\n",
            "Train Epoch: 1 [2560/8768 (29%)]\tLoss: 1.324932\n",
            "Train Epoch: 1 [2640/8768 (30%)]\tLoss: 0.905406\n",
            "Train Epoch: 1 [2720/8768 (31%)]\tLoss: 1.026400\n",
            "Train Epoch: 1 [2800/8768 (32%)]\tLoss: 0.777412\n",
            "Train Epoch: 1 [2880/8768 (33%)]\tLoss: 0.633856\n",
            "Train Epoch: 1 [2960/8768 (34%)]\tLoss: 0.859098\n",
            "Train Epoch: 1 [3040/8768 (35%)]\tLoss: 0.985451\n",
            "Train Epoch: 1 [3120/8768 (36%)]\tLoss: 1.027241\n",
            "Train Epoch: 1 [3200/8768 (36%)]\tLoss: 0.909770\n",
            "Train Epoch: 1 [3280/8768 (37%)]\tLoss: 0.860364\n",
            "Train Epoch: 1 [3360/8768 (38%)]\tLoss: 0.655419\n",
            "Train Epoch: 1 [3440/8768 (39%)]\tLoss: 0.619966\n",
            "Train Epoch: 1 [3520/8768 (40%)]\tLoss: 0.590909\n",
            "Train Epoch: 1 [3600/8768 (41%)]\tLoss: 0.981755\n",
            "Train Epoch: 1 [3680/8768 (42%)]\tLoss: 1.088851\n",
            "Train Epoch: 1 [3760/8768 (43%)]\tLoss: 0.931625\n",
            "Train Epoch: 1 [3840/8768 (44%)]\tLoss: 0.666798\n",
            "Train Epoch: 1 [3920/8768 (45%)]\tLoss: 1.085481\n",
            "Train Epoch: 1 [4000/8768 (46%)]\tLoss: 0.981171\n",
            "Train Epoch: 1 [4080/8768 (47%)]\tLoss: 0.847837\n",
            "Train Epoch: 1 [4160/8768 (47%)]\tLoss: 0.691767\n",
            "Train Epoch: 1 [4240/8768 (48%)]\tLoss: 0.805435\n",
            "Train Epoch: 1 [4320/8768 (49%)]\tLoss: 1.070594\n",
            "Train Epoch: 1 [4400/8768 (50%)]\tLoss: 0.767240\n",
            "Train Epoch: 1 [4480/8768 (51%)]\tLoss: 0.755564\n",
            "Train Epoch: 1 [4560/8768 (52%)]\tLoss: 0.748260\n",
            "Train Epoch: 1 [4640/8768 (53%)]\tLoss: 0.890021\n",
            "Train Epoch: 1 [4720/8768 (54%)]\tLoss: 0.846597\n",
            "Train Epoch: 1 [4800/8768 (55%)]\tLoss: 0.785270\n",
            "Train Epoch: 1 [4880/8768 (56%)]\tLoss: 1.300182\n",
            "Train Epoch: 1 [4960/8768 (57%)]\tLoss: 0.875746\n",
            "Train Epoch: 1 [5040/8768 (57%)]\tLoss: 0.633325\n",
            "Train Epoch: 1 [5120/8768 (58%)]\tLoss: 0.780318\n",
            "Train Epoch: 1 [5200/8768 (59%)]\tLoss: 0.509060\n",
            "Train Epoch: 1 [5280/8768 (60%)]\tLoss: 1.138492\n",
            "Train Epoch: 1 [5360/8768 (61%)]\tLoss: 1.161702\n",
            "Train Epoch: 1 [5440/8768 (62%)]\tLoss: 1.217312\n",
            "Train Epoch: 1 [5520/8768 (63%)]\tLoss: 0.961655\n",
            "Train Epoch: 1 [5600/8768 (64%)]\tLoss: 1.037232\n",
            "Train Epoch: 1 [5680/8768 (65%)]\tLoss: 0.996582\n",
            "Train Epoch: 1 [5760/8768 (66%)]\tLoss: 0.740501\n",
            "Train Epoch: 1 [5840/8768 (67%)]\tLoss: 0.782127\n",
            "Train Epoch: 1 [5920/8768 (68%)]\tLoss: 0.696838\n",
            "Train Epoch: 1 [6000/8768 (68%)]\tLoss: 0.973003\n",
            "Train Epoch: 1 [6080/8768 (69%)]\tLoss: 0.733105\n",
            "Train Epoch: 1 [6160/8768 (70%)]\tLoss: 1.207584\n",
            "Train Epoch: 1 [6240/8768 (71%)]\tLoss: 0.913666\n",
            "Train Epoch: 1 [6320/8768 (72%)]\tLoss: 0.349636\n",
            "Train Epoch: 1 [6400/8768 (73%)]\tLoss: 0.775064\n",
            "Train Epoch: 1 [6480/8768 (74%)]\tLoss: 1.380766\n",
            "Train Epoch: 1 [6560/8768 (75%)]\tLoss: 0.757939\n",
            "Train Epoch: 1 [6640/8768 (76%)]\tLoss: 1.099066\n",
            "Train Epoch: 1 [6720/8768 (77%)]\tLoss: 0.850462\n",
            "Train Epoch: 1 [6800/8768 (78%)]\tLoss: 1.105698\n",
            "Train Epoch: 1 [6880/8768 (78%)]\tLoss: 1.387325\n",
            "Train Epoch: 1 [6960/8768 (79%)]\tLoss: 0.698186\n",
            "Train Epoch: 1 [7040/8768 (80%)]\tLoss: 0.489796\n",
            "Train Epoch: 1 [7120/8768 (81%)]\tLoss: 1.220611\n",
            "Train Epoch: 1 [7200/8768 (82%)]\tLoss: 0.745207\n",
            "Train Epoch: 1 [7280/8768 (83%)]\tLoss: 0.797219\n",
            "Train Epoch: 1 [7360/8768 (84%)]\tLoss: 0.849987\n",
            "Train Epoch: 1 [7440/8768 (85%)]\tLoss: 0.516729\n",
            "Train Epoch: 1 [7520/8768 (86%)]\tLoss: 1.082917\n",
            "Train Epoch: 1 [7600/8768 (87%)]\tLoss: 0.650415\n",
            "Train Epoch: 1 [7680/8768 (88%)]\tLoss: 1.071836\n",
            "Train Epoch: 1 [7760/8768 (89%)]\tLoss: 1.055941\n",
            "Train Epoch: 1 [7840/8768 (89%)]\tLoss: 0.785850\n",
            "Train Epoch: 1 [7920/8768 (90%)]\tLoss: 1.021288\n",
            "Train Epoch: 1 [8000/8768 (91%)]\tLoss: 0.790717\n",
            "Train Epoch: 1 [8080/8768 (92%)]\tLoss: 0.657126\n",
            "Train Epoch: 1 [8160/8768 (93%)]\tLoss: 0.991902\n",
            "Train Epoch: 1 [8240/8768 (94%)]\tLoss: 0.453794\n",
            "Train Epoch: 1 [8320/8768 (95%)]\tLoss: 0.738293\n",
            "Train Epoch: 1 [8400/8768 (96%)]\tLoss: 0.934068\n",
            "Train Epoch: 1 [8480/8768 (97%)]\tLoss: 1.164649\n",
            "Train Epoch: 1 [8560/8768 (98%)]\tLoss: 1.176418\n",
            "Train Epoch: 1 [8640/8768 (99%)]\tLoss: 0.765028\n",
            "Train Epoch: 1 [8720/8768 (99%)]\tLoss: 1.153418\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 333/2193 (15%)\n",
            "\n",
            "Train Epoch: 2 [0/8768 (0%)]\tLoss: 0.780388\n",
            "Train Epoch: 2 [80/8768 (1%)]\tLoss: 0.447384\n",
            "Train Epoch: 2 [160/8768 (2%)]\tLoss: 0.717039\n",
            "Train Epoch: 2 [240/8768 (3%)]\tLoss: 0.372722\n",
            "Train Epoch: 2 [320/8768 (4%)]\tLoss: 0.737864\n",
            "Train Epoch: 2 [400/8768 (5%)]\tLoss: 0.593680\n",
            "Train Epoch: 2 [480/8768 (5%)]\tLoss: 0.419633\n",
            "Train Epoch: 2 [560/8768 (6%)]\tLoss: 1.068089\n",
            "Train Epoch: 2 [640/8768 (7%)]\tLoss: 0.327602\n",
            "Train Epoch: 2 [720/8768 (8%)]\tLoss: 0.353869\n",
            "Train Epoch: 2 [800/8768 (9%)]\tLoss: 0.751879\n",
            "Train Epoch: 2 [880/8768 (10%)]\tLoss: 0.197273\n",
            "Train Epoch: 2 [960/8768 (11%)]\tLoss: 0.531890\n",
            "Train Epoch: 2 [1040/8768 (12%)]\tLoss: 0.495134\n",
            "Train Epoch: 2 [1120/8768 (13%)]\tLoss: 0.365695\n",
            "Train Epoch: 2 [1200/8768 (14%)]\tLoss: 0.599395\n",
            "Train Epoch: 2 [1280/8768 (15%)]\tLoss: 0.728031\n",
            "Train Epoch: 2 [1360/8768 (16%)]\tLoss: 0.907910\n",
            "Train Epoch: 2 [1440/8768 (16%)]\tLoss: 0.442356\n",
            "Train Epoch: 2 [1520/8768 (17%)]\tLoss: 0.874805\n",
            "Train Epoch: 2 [1600/8768 (18%)]\tLoss: 0.222547\n",
            "Train Epoch: 2 [1680/8768 (19%)]\tLoss: 0.644040\n",
            "Train Epoch: 2 [1760/8768 (20%)]\tLoss: 0.846915\n",
            "Train Epoch: 2 [1840/8768 (21%)]\tLoss: 0.512842\n",
            "Train Epoch: 2 [1920/8768 (22%)]\tLoss: 0.689575\n",
            "Train Epoch: 2 [2000/8768 (23%)]\tLoss: 0.446464\n",
            "Train Epoch: 2 [2080/8768 (24%)]\tLoss: 0.202538\n",
            "Train Epoch: 2 [2160/8768 (25%)]\tLoss: 0.398718\n",
            "Train Epoch: 2 [2240/8768 (26%)]\tLoss: 0.395252\n",
            "Train Epoch: 2 [2320/8768 (26%)]\tLoss: 0.627003\n",
            "Train Epoch: 2 [2400/8768 (27%)]\tLoss: 0.776526\n",
            "Train Epoch: 2 [2480/8768 (28%)]\tLoss: 1.053483\n",
            "Train Epoch: 2 [2560/8768 (29%)]\tLoss: 0.732487\n",
            "Train Epoch: 2 [2640/8768 (30%)]\tLoss: 0.392024\n",
            "Train Epoch: 2 [2720/8768 (31%)]\tLoss: 0.562102\n",
            "Train Epoch: 2 [2800/8768 (32%)]\tLoss: 0.644585\n",
            "Train Epoch: 2 [2880/8768 (33%)]\tLoss: 0.522981\n",
            "Train Epoch: 2 [2960/8768 (34%)]\tLoss: 0.329164\n",
            "Train Epoch: 2 [3040/8768 (35%)]\tLoss: 0.253086\n",
            "Train Epoch: 2 [3120/8768 (36%)]\tLoss: 0.812368\n",
            "Train Epoch: 2 [3200/8768 (36%)]\tLoss: 0.058818\n",
            "Train Epoch: 2 [3280/8768 (37%)]\tLoss: 0.495133\n",
            "Train Epoch: 2 [3360/8768 (38%)]\tLoss: 0.494048\n",
            "Train Epoch: 2 [3440/8768 (39%)]\tLoss: 1.647004\n",
            "Train Epoch: 2 [3520/8768 (40%)]\tLoss: 0.628706\n",
            "Train Epoch: 2 [3600/8768 (41%)]\tLoss: 0.355217\n",
            "Train Epoch: 2 [3680/8768 (42%)]\tLoss: 0.732988\n",
            "Train Epoch: 2 [3760/8768 (43%)]\tLoss: 0.340619\n",
            "Train Epoch: 2 [3840/8768 (44%)]\tLoss: 0.895257\n",
            "Train Epoch: 2 [3920/8768 (45%)]\tLoss: 0.531170\n",
            "Train Epoch: 2 [4000/8768 (46%)]\tLoss: 0.306723\n",
            "Train Epoch: 2 [4080/8768 (47%)]\tLoss: 0.393147\n",
            "Train Epoch: 2 [4160/8768 (47%)]\tLoss: 0.743039\n",
            "Train Epoch: 2 [4240/8768 (48%)]\tLoss: 0.761996\n",
            "Train Epoch: 2 [4320/8768 (49%)]\tLoss: 0.052532\n",
            "Train Epoch: 2 [4400/8768 (50%)]\tLoss: 0.539768\n",
            "Train Epoch: 2 [4480/8768 (51%)]\tLoss: 0.326248\n",
            "Train Epoch: 2 [4560/8768 (52%)]\tLoss: 0.611014\n",
            "Train Epoch: 2 [4640/8768 (53%)]\tLoss: 0.716163\n",
            "Train Epoch: 2 [4720/8768 (54%)]\tLoss: 1.093335\n",
            "Train Epoch: 2 [4800/8768 (55%)]\tLoss: 0.712956\n",
            "Train Epoch: 2 [4880/8768 (56%)]\tLoss: 0.528049\n",
            "Train Epoch: 2 [4960/8768 (57%)]\tLoss: 0.537354\n",
            "Train Epoch: 2 [5040/8768 (57%)]\tLoss: 0.852759\n",
            "Train Epoch: 2 [5120/8768 (58%)]\tLoss: 0.536341\n",
            "Train Epoch: 2 [5200/8768 (59%)]\tLoss: 0.717864\n",
            "Train Epoch: 2 [5280/8768 (60%)]\tLoss: 0.529530\n",
            "Train Epoch: 2 [5360/8768 (61%)]\tLoss: 0.410581\n",
            "Train Epoch: 2 [5440/8768 (62%)]\tLoss: 0.497738\n",
            "Train Epoch: 2 [5520/8768 (63%)]\tLoss: 0.604568\n",
            "Train Epoch: 2 [5600/8768 (64%)]\tLoss: 0.491310\n",
            "Train Epoch: 2 [5680/8768 (65%)]\tLoss: 0.461488\n",
            "Train Epoch: 2 [5760/8768 (66%)]\tLoss: 1.403220\n",
            "Train Epoch: 2 [5840/8768 (67%)]\tLoss: 0.323127\n",
            "Train Epoch: 2 [5920/8768 (68%)]\tLoss: 0.955915\n",
            "Train Epoch: 2 [6000/8768 (68%)]\tLoss: 0.381527\n",
            "Train Epoch: 2 [6080/8768 (69%)]\tLoss: 0.285404\n",
            "Train Epoch: 2 [6160/8768 (70%)]\tLoss: 0.479933\n",
            "Train Epoch: 2 [6240/8768 (71%)]\tLoss: 0.400175\n",
            "Train Epoch: 2 [6320/8768 (72%)]\tLoss: 0.677699\n",
            "Train Epoch: 2 [6400/8768 (73%)]\tLoss: 0.646490\n",
            "Train Epoch: 2 [6480/8768 (74%)]\tLoss: 0.814934\n",
            "Train Epoch: 2 [6560/8768 (75%)]\tLoss: 0.487302\n",
            "Train Epoch: 2 [6640/8768 (76%)]\tLoss: 0.340410\n",
            "Train Epoch: 2 [6720/8768 (77%)]\tLoss: 0.410183\n",
            "Train Epoch: 2 [6800/8768 (78%)]\tLoss: 1.019169\n",
            "Train Epoch: 2 [6880/8768 (78%)]\tLoss: 0.626917\n",
            "Train Epoch: 2 [6960/8768 (79%)]\tLoss: 0.795957\n",
            "Train Epoch: 2 [7040/8768 (80%)]\tLoss: 0.252226\n",
            "Train Epoch: 2 [7120/8768 (81%)]\tLoss: 0.906520\n",
            "Train Epoch: 2 [7200/8768 (82%)]\tLoss: 1.272887\n",
            "Train Epoch: 2 [7280/8768 (83%)]\tLoss: 0.360769\n",
            "Train Epoch: 2 [7360/8768 (84%)]\tLoss: 0.424421\n",
            "Train Epoch: 2 [7440/8768 (85%)]\tLoss: 0.491737\n",
            "Train Epoch: 2 [7520/8768 (86%)]\tLoss: 0.609962\n",
            "Train Epoch: 2 [7600/8768 (87%)]\tLoss: 0.354000\n",
            "Train Epoch: 2 [7680/8768 (88%)]\tLoss: 0.335603\n",
            "Train Epoch: 2 [7760/8768 (89%)]\tLoss: 0.954954\n",
            "Train Epoch: 2 [7840/8768 (89%)]\tLoss: 0.457229\n",
            "Train Epoch: 2 [7920/8768 (90%)]\tLoss: 0.552302\n",
            "Train Epoch: 2 [8000/8768 (91%)]\tLoss: 0.685904\n",
            "Train Epoch: 2 [8080/8768 (92%)]\tLoss: 0.432117\n",
            "Train Epoch: 2 [8160/8768 (93%)]\tLoss: 1.072957\n",
            "Train Epoch: 2 [8240/8768 (94%)]\tLoss: 0.574484\n",
            "Train Epoch: 2 [8320/8768 (95%)]\tLoss: 0.228375\n",
            "Train Epoch: 2 [8400/8768 (96%)]\tLoss: 0.704018\n",
            "Train Epoch: 2 [8480/8768 (97%)]\tLoss: 0.814090\n",
            "Train Epoch: 2 [8560/8768 (98%)]\tLoss: 0.594186\n",
            "Train Epoch: 2 [8640/8768 (99%)]\tLoss: 0.385413\n",
            "Train Epoch: 2 [8720/8768 (99%)]\tLoss: 0.971182\n",
            "\n",
            "Test set: Average loss: 0.0000, Accuracy: 261/2193 (12%)\n",
            "\n",
            "Train Epoch: 3 [0/8768 (0%)]\tLoss: 0.940184\n",
            "Train Epoch: 3 [80/8768 (1%)]\tLoss: 0.030959\n",
            "Train Epoch: 3 [160/8768 (2%)]\tLoss: 0.424013\n",
            "Train Epoch: 3 [240/8768 (3%)]\tLoss: 0.321605\n",
            "Train Epoch: 3 [320/8768 (4%)]\tLoss: 0.378600\n",
            "Train Epoch: 3 [400/8768 (5%)]\tLoss: 0.082012\n",
            "Train Epoch: 3 [480/8768 (5%)]\tLoss: 0.605745\n",
            "Train Epoch: 3 [560/8768 (6%)]\tLoss: 0.135378\n",
            "Train Epoch: 3 [640/8768 (7%)]\tLoss: 0.348478\n",
            "Train Epoch: 3 [720/8768 (8%)]\tLoss: 0.329491\n",
            "Train Epoch: 3 [800/8768 (9%)]\tLoss: 0.035079\n",
            "Train Epoch: 3 [880/8768 (10%)]\tLoss: 0.549520\n",
            "Train Epoch: 3 [960/8768 (11%)]\tLoss: 0.234040\n",
            "Train Epoch: 3 [1040/8768 (12%)]\tLoss: 0.560318\n",
            "Train Epoch: 3 [1120/8768 (13%)]\tLoss: 0.190107\n",
            "Train Epoch: 3 [1200/8768 (14%)]\tLoss: 0.205895\n",
            "Train Epoch: 3 [1280/8768 (15%)]\tLoss: 0.248367\n",
            "Train Epoch: 3 [1360/8768 (16%)]\tLoss: 0.202202\n",
            "Train Epoch: 3 [1440/8768 (16%)]\tLoss: 0.935777\n",
            "Train Epoch: 3 [1520/8768 (17%)]\tLoss: 0.820241\n",
            "Train Epoch: 3 [1600/8768 (18%)]\tLoss: 0.050742\n",
            "Train Epoch: 3 [1680/8768 (19%)]\tLoss: 0.054009\n",
            "Train Epoch: 3 [1760/8768 (20%)]\tLoss: 0.156557\n",
            "Train Epoch: 3 [1840/8768 (21%)]\tLoss: 0.051395\n",
            "Train Epoch: 3 [1920/8768 (22%)]\tLoss: 0.058262\n",
            "Train Epoch: 3 [2000/8768 (23%)]\tLoss: 0.494762\n",
            "Train Epoch: 3 [2080/8768 (24%)]\tLoss: 0.298093\n",
            "Train Epoch: 3 [2160/8768 (25%)]\tLoss: 0.157695\n",
            "Train Epoch: 3 [2240/8768 (26%)]\tLoss: 0.643486\n",
            "Train Epoch: 3 [2320/8768 (26%)]\tLoss: 0.076950\n",
            "Train Epoch: 3 [2400/8768 (27%)]\tLoss: 0.423098\n",
            "Train Epoch: 3 [2480/8768 (28%)]\tLoss: 0.367441\n",
            "Train Epoch: 3 [2560/8768 (29%)]\tLoss: 0.118202\n",
            "Train Epoch: 3 [2640/8768 (30%)]\tLoss: 0.180725\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS BZA/y3s1/BT4222/BT4222/testmodels.ipynb Cell 67\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m ACC \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, args\u001b[39m.\u001b[39mepochs \u001b[39m+\u001b[39m \u001b[39m1\u001b[39m):\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     train(args, model, device, train_loader, optimizer, epoch)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     ACC_ \u001b[39m=\u001b[39m test(model, device, test_loader)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m     \u001b[39mif\u001b[39;00m ACC_\u001b[39m>\u001b[39mACC \u001b[39mor\u001b[39;00m ACC_ \u001b[39m==\u001b[39m ACC:\n",
            "\u001b[1;32m/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS BZA/y3s1/BT4222/BT4222/testmodels.ipynb Cell 67\u001b[0m line \u001b[0;36m1\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(output, target)  \u001b[39m# Calculate the loss between the output and target\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m loss\u001b[39m.\u001b[39mbackward()  \u001b[39m# Perform backpropagation (calculate gradients of loss w.r.t. parameters)\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m optimizer\u001b[39m.\u001b[39;49mstep()  \u001b[39m# Update the model parameters\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mif\u001b[39;00m batch_idx \u001b[39m%\u001b[39m args\u001b[39m.\u001b[39mlog_interval \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:  \u001b[39m# Print log info for specified interval\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/maximyam/Library/CloudStorage/OneDrive-NationalUniversityofSingapore/NUS%20BZA/y3s1/BT4222/BT4222/testmodels.ipynb#Y116sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mTrain Epoch: \u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m [\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m (\u001b[39m\u001b[39m{:.0f}\u001b[39;00m\u001b[39m%\u001b[39m\u001b[39m)]\u001b[39m\u001b[39m\\t\u001b[39;00m\u001b[39mLoss: \u001b[39m\u001b[39m{:.6f}\u001b[39;00m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(epoch, batch_idx \u001b[39m*\u001b[39m \u001b[39mlen\u001b[39m(data), \u001b[39mlen\u001b[39m(train_loader\u001b[39m.\u001b[39mdataset),\u001b[39m100.\u001b[39m \u001b[39m*\u001b[39m batch_idx \u001b[39m/\u001b[39m \u001b[39mlen\u001b[39m(train_loader), loss\u001b[39m.\u001b[39mitem()))\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/optim/lr_scheduler.py:65\u001b[0m, in \u001b[0;36m_LRScheduler.__init__.<locals>.with_counter.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m instance\u001b[39m.\u001b[39m_step_count \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m     64\u001b[0m wrapped \u001b[39m=\u001b[39m func\u001b[39m.\u001b[39m\u001b[39m__get__\u001b[39m(instance, \u001b[39mcls\u001b[39m)\n\u001b[0;32m---> 65\u001b[0m \u001b[39mreturn\u001b[39;00m wrapped(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/optim/optimizer.py:113\u001b[0m, in \u001b[0;36mOptimizer._hook_for_profile.<locals>.profile_hook_step.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    111\u001b[0m profile_name \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mOptimizer.step#\u001b[39m\u001b[39m{}\u001b[39;00m\u001b[39m.step\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m.\u001b[39mformat(obj\u001b[39m.\u001b[39m\u001b[39m__class__\u001b[39m\u001b[39m.\u001b[39m\u001b[39m__name__\u001b[39m)\n\u001b[1;32m    112\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mautograd\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mrecord_function(profile_name):\n\u001b[0;32m--> 113\u001b[0m     \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/autograd/grad_mode.py:27\u001b[0m, in \u001b[0;36m_DecoratorContextManager.__call__.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[39m@functools\u001b[39m\u001b[39m.\u001b[39mwraps(func)\n\u001b[1;32m     25\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mdecorate_context\u001b[39m(\u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m     26\u001b[0m     \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mclone():\n\u001b[0;32m---> 27\u001b[0m         \u001b[39mreturn\u001b[39;00m func(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/optim/adadelta.py:122\u001b[0m, in \u001b[0;36mAdadelta.step\u001b[0;34m(self, closure)\u001b[0m\n\u001b[1;32m    118\u001b[0m         acc_deltas\u001b[39m.\u001b[39mappend(state[\u001b[39m'\u001b[39m\u001b[39macc_delta\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m    120\u001b[0m         state[\u001b[39m'\u001b[39m\u001b[39mstep\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m--> 122\u001b[0m     adadelta(params_with_grad,\n\u001b[1;32m    123\u001b[0m              grads,\n\u001b[1;32m    124\u001b[0m              square_avgs,\n\u001b[1;32m    125\u001b[0m              acc_deltas,\n\u001b[1;32m    126\u001b[0m              lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    127\u001b[0m              rho\u001b[39m=\u001b[39;49mrho,\n\u001b[1;32m    128\u001b[0m              eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    129\u001b[0m              weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    130\u001b[0m              foreach\u001b[39m=\u001b[39;49mforeach,\n\u001b[1;32m    131\u001b[0m              maximize\u001b[39m=\u001b[39;49mmaximize)\n\u001b[1;32m    133\u001b[0m \u001b[39mreturn\u001b[39;00m loss\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/optim/adadelta.py:166\u001b[0m, in \u001b[0;36madadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, foreach, lr, rho, eps, weight_decay, maximize)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    164\u001b[0m     func \u001b[39m=\u001b[39m _single_tensor_adadelta\n\u001b[0;32m--> 166\u001b[0m func(params,\n\u001b[1;32m    167\u001b[0m      grads,\n\u001b[1;32m    168\u001b[0m      square_avgs,\n\u001b[1;32m    169\u001b[0m      acc_deltas,\n\u001b[1;32m    170\u001b[0m      lr\u001b[39m=\u001b[39;49mlr,\n\u001b[1;32m    171\u001b[0m      rho\u001b[39m=\u001b[39;49mrho,\n\u001b[1;32m    172\u001b[0m      eps\u001b[39m=\u001b[39;49meps,\n\u001b[1;32m    173\u001b[0m      weight_decay\u001b[39m=\u001b[39;49mweight_decay,\n\u001b[1;32m    174\u001b[0m      maximize\u001b[39m=\u001b[39;49mmaximize)\n",
            "File \u001b[0;32m~/opt/anaconda3/envs/yourenvname/lib/python3.8/site-packages/torch/optim/adadelta.py:201\u001b[0m, in \u001b[0;36m_single_tensor_adadelta\u001b[0;34m(params, grads, square_avgs, acc_deltas, lr, rho, eps, weight_decay, maximize)\u001b[0m\n\u001b[1;32m    199\u001b[0m square_avg\u001b[39m.\u001b[39mmul_(rho)\u001b[39m.\u001b[39maddcmul_(grad, grad, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m rho)\n\u001b[1;32m    200\u001b[0m std \u001b[39m=\u001b[39m square_avg\u001b[39m.\u001b[39madd(eps)\u001b[39m.\u001b[39msqrt_()\n\u001b[0;32m--> 201\u001b[0m delta \u001b[39m=\u001b[39m acc_delta\u001b[39m.\u001b[39;49madd(eps)\u001b[39m.\u001b[39;49msqrt_()\u001b[39m.\u001b[39;49mdiv_(std)\u001b[39m.\u001b[39mmul_(grad)\n\u001b[1;32m    202\u001b[0m acc_delta\u001b[39m.\u001b[39mmul_(rho)\u001b[39m.\u001b[39maddcmul_(delta, delta, value\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m \u001b[39m-\u001b[39m rho)\n\u001b[1;32m    203\u001b[0m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mis_complex(param):\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "torch.manual_seed(args.seed)\n",
        "device = torch.device(\"cuda\" if args.use_cuda else \"cpu\")\n",
        "model = Net().to(device)\n",
        "for param_tensor in model.state_dict():\n",
        "        print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
        "#Form training and testing dataset\n",
        "optimizer = optim.Adadelta(model.parameters(), lr=1)\n",
        "train_dataset = torch.utils.data.TensorDataset(train_vectors1, train_labels1)\n",
        "test_dataset = torch.utils.data.TensorDataset(test_vectors1, test_labels1)\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=8, shuffle=True)\n",
        "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=8, shuffle=False)\n",
        "scheduler = StepLR(optimizer, step_size=1, gamma=args.gamma)\n",
        "\n",
        "#Model training\n",
        "ACC = 0\n",
        "for epoch in range(1, args.epochs + 1):\n",
        "    train(args, model, device, train_loader, optimizer, epoch)\n",
        "    ACC_ = test(model, device, test_loader)\n",
        "    if ACC_>ACC or ACC_ == ACC:\n",
        "        ACC = ACC_\n",
        "        torch.save(model.state_dict(), \"cnn_lstm_att.pt\")\n",
        "\n",
        "    scheduler.step()\n",
        "\n",
        "print(ACC)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 68,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14434.0"
            ]
          },
          "execution_count": 68,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iPPDQde6BuTJ"
      },
      "source": [
        "# Yeeted of HANN model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZoEc0GHiBto4"
      },
      "outputs": [],
      "source": [
        "class HAHNetwork():\n",
        "    def __init__(self):\n",
        "        self.model = None\n",
        "        self.MAX_SENTENCE_LENGTH = 0\n",
        "        self.MAX_SENTENCE_COUNT = 0\n",
        "        self.VOCABULARY_SIZE = 0\n",
        "        self.word_embedding = None\n",
        "        self.model = None\n",
        "        self.word_attention_model = None\n",
        "        self.tokenizer = None\n",
        "        self.class_count = 2\n",
        "\n",
        "    def build_model(self, n_classes=2, embedding_dim=200, embeddings_path=False):\n",
        "\n",
        "        l2_reg = regularizers.l2(0.001)\n",
        "\n",
        "        embedding_weights = np.random.normal(0, 1, (len(self.tokenizer.word_index) + 1, embedding_dim))\n",
        "\n",
        "        if embeddings_path is not None:\n",
        "\n",
        "            if word_embedding_type is 'from_scratch':\n",
        "                # FastText\n",
        "                filename = './fasttext_model.txt'\n",
        "                model =  gensim.models.FastText.load(filename)\n",
        "\n",
        "                embeddings_index = model.wv\n",
        "                embedding_matrix = np.zeros( ( len(self.tokenizer.word_index) + 1, embedding_dim) )\n",
        "                for word, i in self.tokenizer.word_index.items():\n",
        "                    try:\n",
        "                        embedding_vector = embeddings_index[word]\n",
        "                        if embedding_vector is not None:\n",
        "                            embedding_matrix[i] = embedding_vector\n",
        "                    except Exception as e:\n",
        "                        #print(str(e))\n",
        "                        continue\n",
        "\n",
        "\n",
        "            else:\n",
        "                embedding_dim = 300\n",
        "                embedding_matrix = load_subword_embedding_300d(self.tokenizer.word_index)\n",
        "\n",
        "            embedding_weights = embedding_matrix\n",
        "\n",
        "        sentence_in = Input(shape=(self.MAX_SENTENCE_LENGTH,), dtype='int32', name=\"input_1\")\n",
        "\n",
        "        embedding_trainable = True\n",
        "\n",
        "\n",
        "\n",
        "        if word_embedding_type is 'pre_trained':\n",
        "            embedding_trainable = False\n",
        "\n",
        "        embedded_word_seq = Embedding(\n",
        "            self.VOCABULARY_SIZE,\n",
        "            embedding_dim,\n",
        "            weights=[embedding_weights],\n",
        "            input_length=self.MAX_SENTENCE_LENGTH,\n",
        "            trainable=embedding_trainable,\n",
        "            #mask_zero=True,\n",
        "            mask_zero=False,\n",
        "            name='word_embeddings',)(sentence_in)\n",
        "\n",
        "\n",
        "\n",
        "        dropout = Dropout(0.2)(embedded_word_seq)\n",
        "        filter_sizes = [3,4,5]\n",
        "        convs = []\n",
        "        for filter_size in filter_sizes:\n",
        "            conv = Conv1D(filters=64, kernel_size=filter_size, padding='same', activation='relu')(dropout)\n",
        "            pool = MaxPool1D(filter_size)(conv)\n",
        "            convs.append(pool)\n",
        "\n",
        "        concatenate = Concatenate(axis=1)(convs)\n",
        "\n",
        "        if rnn_type is 'GRU':\n",
        "            #word_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True, dropout=0.2))(concatenate)\n",
        "            dropout = Dropout(0.1)(concatenate)\n",
        "            word_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True))(dropout)\n",
        "        else:\n",
        "            word_encoder = Bidirectional(\n",
        "                LSTM(50, return_sequences=True, dropout=0.2))(embedded_word_seq)\n",
        "\n",
        "\n",
        "        dense_transform_word = Dense(\n",
        "            100,\n",
        "            activation='relu',\n",
        "            name='dense_transform_word',\n",
        "            kernel_regularizer=l2_reg)(word_encoder)\n",
        "\n",
        "        # word attention\n",
        "        attention_weighted_sentence = Model(\n",
        "            sentence_in, Attention(name=\"word_attention\")(dense_transform_word))\n",
        "\n",
        "        self.word_attention_model = attention_weighted_sentence\n",
        "\n",
        "        attention_weighted_sentence.summary()\n",
        "\n",
        "        # sentence-attention-weighted document scores\n",
        "\n",
        "        texts_in = Input(shape=(self.MAX_SENTENCE_COUNT, self.MAX_SENTENCE_LENGTH), dtype='int32', name=\"input_2\")\n",
        "\n",
        "        attention_weighted_sentences = TimeDistributed(attention_weighted_sentence)(texts_in)\n",
        "\n",
        "\n",
        "        if rnn_type is 'GRU':\n",
        "            #sentence_encoder = Bidirectional(GRU(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))(attention_weighted_sentences)\n",
        "            dropout = Dropout(0.1)(attention_weighted_sentences)\n",
        "            sentence_encoder = Bidirectional(CuDNNGRU(50, return_sequences=True))(dropout)\n",
        "        else:\n",
        "            sentence_encoder = Bidirectional(LSTM(50, return_sequences=True, dropout=0.1, recurrent_dropout=0.2))(attention_weighted_sentences)\n",
        "\n",
        "\n",
        "        dense_transform_sentence = Dense(\n",
        "            100,\n",
        "            activation='relu',\n",
        "            name='dense_transform_sentence',\n",
        "            kernel_regularizer=l2_reg)(sentence_encoder)\n",
        "\n",
        "        # sentence attention\n",
        "        attention_weighted_text = Attention(name=\"sentence_attention\")(dense_transform_sentence)\n",
        "\n",
        "\n",
        "        prediction = Dense(n_classes, activation='softmax')(attention_weighted_text)\n",
        "\n",
        "        model = Model(texts_in, prediction)\n",
        "        model.summary()\n",
        "\n",
        "\n",
        "        optimizer=Adam(lr=learning_rate, decay=0.0001)\n",
        "\n",
        "        model.compile(\n",
        "                      optimizer=optimizer,\n",
        "                      loss='categorical_crossentropy',\n",
        "                      metrics=['accuracy'])\n",
        "\n",
        "        return model\n",
        "\n",
        "\n",
        "    def get_tokenizer_filename(self, saved_model_filename):\n",
        "        return saved_model_filename + '.tokenizer'\n",
        "\n",
        "    def create_reverse_word_index(self):\n",
        "        self.reverse_word_index = {value:key for key,value in self.tokenizer.word_index.items()}\n",
        "\n",
        "    def encode_texts(self, texts):\n",
        "        encoded_texts = np.zeros((len(texts), self.MAX_SENTENCE_COUNT, self.MAX_SENTENCE_LENGTH))\n",
        "        for i, text in enumerate(texts):\n",
        "            encoded_text = np.array(pad_sequences(\n",
        "                self.tokenizer.texts_to_sequences(text),\n",
        "                maxlen=self.MAX_SENTENCE_LENGTH))[:self.MAX_SENTENCE_COUNT]\n",
        "            encoded_texts[i][-len(encoded_text):] = encoded_text\n",
        "        return encoded_texts\n",
        "\n",
        "\n",
        "    def encode_input(self, x, log=False):\n",
        "        x = np.array(x)\n",
        "        if not x.shape:\n",
        "            x = np.expand_dims(x, 0)\n",
        "        texts = np.array([normalize(text) for text in x])\n",
        "        return self.encode_texts(texts)\n",
        "\n",
        "\n",
        "    def predict(self, x):\n",
        "            encoded_x = self.encode_texts(x)\n",
        "            return self.model.predict(encoded_x)\n",
        "\n",
        "\n",
        "    def activation_maps(self, text, websafe=False):\n",
        "        normalized_text = normalize(text)\n",
        "\n",
        "        encoded_text = self.encode_input(text)[0]\n",
        "\n",
        "        # get word activations\n",
        "\n",
        "        hidden_word_encoding_out = Model(\n",
        "            inputs=self.word_attention_model.input,\n",
        "            outputs=self.word_attention_model.get_layer('dense_transform_word').output)\n",
        "\n",
        "\n",
        "        hidden_word_encodings = hidden_word_encoding_out.predict(encoded_text)\n",
        "\n",
        "        word_context = self.word_attention_model.get_layer('word_attention').get_weights()[0]\n",
        "\n",
        "\n",
        "        dot = np.dot(hidden_word_encodings, word_context)\n",
        "\n",
        "        #u_wattention = encoded_text*np.exp(np.squeeze(dot))\n",
        "        u_wattention = encoded_text\n",
        "\n",
        "        if websafe:\n",
        "            u_wattention = u_wattention.astype(float)\n",
        "\n",
        "        nopad_encoded_text = encoded_text[-len(normalized_text):]\n",
        "        nopad_encoded_text = [list(filter(lambda x: x > 0, sentence)) for sentence in nopad_encoded_text]\n",
        "        reconstructed_texts = [[self.reverse_word_index[int(i)]\n",
        "                                for i in sentence] for sentence in nopad_encoded_text]\n",
        "        nopad_wattention = u_wattention[-len(normalized_text):]\n",
        "        nopad_wattention = nopad_wattention/np.expand_dims(np.sum(nopad_wattention, -1), -1)\n",
        "        nopad_wattention = np.array([attention_seq[-len(sentence):]\n",
        "                            for attention_seq, sentence in zip(nopad_wattention, nopad_encoded_text)])\n",
        "        word_activation_maps = []\n",
        "        for i, text in enumerate(reconstructed_texts):\n",
        "            word_activation_maps.append(list(zip(text, nopad_wattention[i])))\n",
        "\n",
        "        hidden_sentence_encoding_out = Model(inputs=self.model.input,\n",
        "                                             outputs=self.model.get_layer('dense_transform_sentence').output)\n",
        "        hidden_sentence_encodings = np.squeeze(\n",
        "            hidden_sentence_encoding_out.predict(np.expand_dims(encoded_text, 0)), 0)\n",
        "        sentence_context = self.model.get_layer('sentence_attention').get_weights()[0]\n",
        "        u_sattention = np.exp(np.squeeze(np.dot(hidden_sentence_encodings, sentence_context), -1))\n",
        "        if websafe:\n",
        "            u_sattention = u_sattention.astype(float)\n",
        "        nopad_sattention = u_sattention[-len(normalized_text):]\n",
        "\n",
        "        nopad_sattention = nopad_sattention/np.expand_dims(np.sum(nopad_sattention, -1), -1)\n",
        "\n",
        "        activation_map = list(zip(word_activation_maps, nopad_sattention))\n",
        "\n",
        "        return activation_map\n",
        "\n",
        "\n",
        "    def load_weights(self, saved_model_dir, saved_model_filename):\n",
        "        with CustomObjectScope({'Attention': Attention}):\n",
        "            print(os.path.join(saved_model_dir, saved_model_filename))\n",
        "            self.model = load_model(os.path.join(saved_model_dir, saved_model_filename))\n",
        "            self.word_attention_model = self.model.get_layer('time_distributed_1').layer\n",
        "            tokenizer_path = os.path.join(\n",
        "                saved_model_dir, self.get_tokenizer_filename(saved_model_filename))\n",
        "            tokenizer_state = pickle.load(open(tokenizer_path, \"rb\" ))\n",
        "            self.tokenizer = tokenizer_state['tokenizer']\n",
        "            self.MAX_SENTENCE_COUNT = tokenizer_state['maxSentenceCount']\n",
        "            self.MAX_SENTENCE_LENGTH = tokenizer_state['maxSentenceLength']\n",
        "            self.VOCABULARY_SIZE = tokenizer_state['vocabularySize']\n",
        "            self.create_reverse_word_index()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "display-name",
      "language": "python",
      "name": "yourenvname"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "02a2dd3734c5481ea6b4c54f33d6121c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "03b363a4be084db2bfdd98c4fe08e133": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "0b5f103144da47e4bf668a2a31c8d6db": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0d7b1eee53da43caacb1075066cb4204": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "0e730ba0c9d242849d18cb062a78f57b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "1761b91723a845728299f470d05c9f5e": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "17b7e31540be4d2493dd5cc3c0b5db8c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_0e730ba0c9d242849d18cb062a78f57b",
            "max": 500,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0d7b1eee53da43caacb1075066cb4204",
            "value": 250
          }
        },
        "187358e1308a4581884fc2f4fbde9a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_4287f832e2594b269b8f6ae48b885bd1",
              "IPY_MODEL_7385490df52c44c18044d35bae7c37e1",
              "IPY_MODEL_d0e7378ee17e4d14beb86040e4e91a94"
            ],
            "layout": "IPY_MODEL_6d9d76219d2644419b1ad08553f6237c"
          }
        },
        "2024bd3b639c48fc8b8815643564717d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_bd63c4f7f92b42b5afd8bc5858b88a74",
            "placeholder": "​",
            "style": "IPY_MODEL_35f02b3c6dbb4dbb8a6bd04bd181df79",
            "value": "Map: 100%"
          }
        },
        "22afb4a1f09644778bf4bb10c687644b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "2c162df50a1f4114ae9a108a7d1c30e5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "2fe15378930b4a97b98ec96f8e584e45": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_2024bd3b639c48fc8b8815643564717d",
              "IPY_MODEL_af493b1c2c1b40c5ab2db58497fbdd4d",
              "IPY_MODEL_878f2c1cf6b84f9c96be43719570b6e1"
            ],
            "layout": "IPY_MODEL_961ed0414e5a4c62b78b2f10f1263145"
          }
        },
        "314aa15a0dc642eeac4fe71108e558ff": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f3311eaaaa634a25b15b696bd597ced0",
              "IPY_MODEL_17b7e31540be4d2493dd5cc3c0b5db8c",
              "IPY_MODEL_c3e3e46efcb04d6abb0bf8e23161f9ef"
            ],
            "layout": "IPY_MODEL_f63a9a360181468a991009b14a271a46"
          }
        },
        "35f02b3c6dbb4dbb8a6bd04bd181df79": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "371e79d8d05e48bd8b59efcfcc010bb2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_73c8c385f34447fba4511e04b1d1028a",
            "placeholder": "​",
            "style": "IPY_MODEL_a3f49eba8c864c3e893c6b1ba6f04768",
            "value": "Downloading (…)lve/main/config.json: 100%"
          }
        },
        "39a437e801504f4782f049ff65ea71d2": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "3af06ad482b84968966f5bc1f6dde9ac": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "3c068b96d5544c3e80836ec323f00e4c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_03b363a4be084db2bfdd98c4fe08e133",
            "max": 28,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6331897e562547fba3f62d4b009ea5e9",
            "value": 28
          }
        },
        "4287f832e2594b269b8f6ae48b885bd1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9e031dbb97404ba7a27775a511b69ecd",
            "placeholder": "​",
            "style": "IPY_MODEL_9670129efee148f78e2c720f5f89a0c5",
            "value": "Downloading (…)/main/tokenizer.json: 100%"
          }
        },
        "46534bf21d56434bbd640a1f1c0a869b": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "482368971ad34b2b90d95226231987a7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d44bb132f8774946a4ef51d8905e9406",
            "placeholder": "​",
            "style": "IPY_MODEL_8fb227ecc4ab4008a5bd4c18eee24b3f",
            "value": "Downloading (…)okenizer_config.json: 100%"
          }
        },
        "4d001b5f443e47ccabffd062d70695b4": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "515c0a2698e945d7ac81eaba81432480": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "52632601b5194259b357010a316a87c3": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_482368971ad34b2b90d95226231987a7",
              "IPY_MODEL_3c068b96d5544c3e80836ec323f00e4c",
              "IPY_MODEL_7cbb4dda6ecd417ca2a228f9e75a1c9c"
            ],
            "layout": "IPY_MODEL_925841aa064d47908721220d5c2dc8a0"
          }
        },
        "59c6673701ea425ea0c7fea35767a5be": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f2b5e8e49cad4dea9a005c4a9332227c",
            "max": 570,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_d9232b398bce42a5b845fc106907a114",
            "value": 570
          }
        },
        "5a31b0da8dad42eea5297c17f28c1ea9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88bb7dd6ad0c48c19d0e9a1ef46a646e",
            "max": 440449768,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_0b5f103144da47e4bf668a2a31c8d6db",
            "value": 440449768
          }
        },
        "5b2168404943494f91df77dca5bcdc6d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "5cfbe3cbffe9483caed053cb35b90939": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "60df71b9a7a04a83a89f7dbeb4003f8a": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_f91d5ef6106e48c99ca2296c91c3c321",
              "IPY_MODEL_9b54d69d732d4f77817e54fca8eba374",
              "IPY_MODEL_a89e5dae524748a5953c311618c94b08"
            ],
            "layout": "IPY_MODEL_b1c0e44b9f69418ea8dfeb4b32a000f8"
          }
        },
        "6331897e562547fba3f62d4b009ea5e9": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "6d9d76219d2644419b1ad08553f6237c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "71f78f69f9834809a0d621aa1ec23bb0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "7385490df52c44c18044d35bae7c37e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f28d6656e9af4043aa86cafb8dd5a644",
            "max": 466062,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_5b2168404943494f91df77dca5bcdc6d",
            "value": 466062
          }
        },
        "73c8c385f34447fba4511e04b1d1028a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7998ae84e4344bc88cf96162c8c040de": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7a874d40f81d48cb845f4d5dd83e7909": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "7cbb4dda6ecd417ca2a228f9e75a1c9c": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_d1491196238948d398317aaa15adf68c",
            "placeholder": "​",
            "style": "IPY_MODEL_a4c14f35fb284e37bbea0f0e876957bb",
            "value": " 28.0/28.0 [00:00&lt;00:00, 453B/s]"
          }
        },
        "83b58655255041338750df563867d4f7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "878f2c1cf6b84f9c96be43719570b6e1": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_3af06ad482b84968966f5bc1f6dde9ac",
            "placeholder": "​",
            "style": "IPY_MODEL_8d9e2bc1c9e14a71b1860acf10a72025",
            "value": " 267/267 [00:00&lt;00:00, 735.68 examples/s]"
          }
        },
        "88a1037651ca482f9baf03f24f56d34f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "88bb7dd6ad0c48c19d0e9a1ef46a646e": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "88c2fedef5264a1e94592256bcf36eff": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "8d9e2bc1c9e14a71b1860acf10a72025": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "8dc20f969e6647cea734eecad6fc5ee7": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_371e79d8d05e48bd8b59efcfcc010bb2",
              "IPY_MODEL_59c6673701ea425ea0c7fea35767a5be",
              "IPY_MODEL_f1854c5107ef4cd9949e8f54d27a8905"
            ],
            "layout": "IPY_MODEL_5cfbe3cbffe9483caed053cb35b90939"
          }
        },
        "8fb227ecc4ab4008a5bd4c18eee24b3f": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "925841aa064d47908721220d5c2dc8a0": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9268c5df10f94577ba3f2a1fab5b0595": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "961ed0414e5a4c62b78b2f10f1263145": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9670129efee148f78e2c720f5f89a0c5": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "98cdd6461b3b46a9aab314fabdc70caf": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_4d001b5f443e47ccabffd062d70695b4",
            "placeholder": "​",
            "style": "IPY_MODEL_02a2dd3734c5481ea6b4c54f33d6121c",
            "value": " 440M/440M [00:06&lt;00:00, 103MB/s]"
          }
        },
        "99727414bc1146578aa17513e14e697b": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9b54d69d732d4f77817e54fca8eba374": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_9c95041aaa17485cb4a09ed0c19d5aa2",
            "max": 231508,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_83b58655255041338750df563867d4f7",
            "value": 231508
          }
        },
        "9c95041aaa17485cb4a09ed0c19d5aa2": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9e031dbb97404ba7a27775a511b69ecd": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "a3f49eba8c864c3e893c6b1ba6f04768": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a417965cba7e4256b39a584f60c4f039": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f1e4f8658078472caeedcff6038e236a",
            "placeholder": "​",
            "style": "IPY_MODEL_2c162df50a1f4114ae9a108a7d1c30e5",
            "value": "Downloading model.safetensors: 100%"
          }
        },
        "a4c14f35fb284e37bbea0f0e876957bb": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "a89e5dae524748a5953c311618c94b08": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_88c2fedef5264a1e94592256bcf36eff",
            "placeholder": "​",
            "style": "IPY_MODEL_46534bf21d56434bbd640a1f1c0a869b",
            "value": " 232k/232k [00:00&lt;00:00, 2.30MB/s]"
          }
        },
        "ab76c2cada82457ba9561bffc84576bc": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "af493b1c2c1b40c5ab2db58497fbdd4d": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "FloatProgressModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7998ae84e4344bc88cf96162c8c040de",
            "max": 267,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_515c0a2698e945d7ac81eaba81432480",
            "value": 267
          }
        },
        "b1c0e44b9f69418ea8dfeb4b32a000f8": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "b7b2679af34f4bd484b6f8b0e43e6449": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "bd63c4f7f92b42b5afd8bc5858b88a74": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "c3e3e46efcb04d6abb0bf8e23161f9ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_b7b2679af34f4bd484b6f8b0e43e6449",
            "placeholder": "​",
            "style": "IPY_MODEL_71f78f69f9834809a0d621aa1ec23bb0",
            "value": " 250/500 [1:15:17&lt;1:14:33, 17.89s/it]"
          }
        },
        "d0e7378ee17e4d14beb86040e4e91a94": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_f966b5e0e2a44868b76afe22ee15a51c",
            "placeholder": "​",
            "style": "IPY_MODEL_88a1037651ca482f9baf03f24f56d34f",
            "value": " 466k/466k [00:00&lt;00:00, 6.74MB/s]"
          }
        },
        "d1491196238948d398317aaa15adf68c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d44bb132f8774946a4ef51d8905e9406": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "d9232b398bce42a5b845fc106907a114": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "ProgressStyleModel",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "da836073426b4f0382c174f733e6b632": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HBoxModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_a417965cba7e4256b39a584f60c4f039",
              "IPY_MODEL_5a31b0da8dad42eea5297c17f28c1ea9",
              "IPY_MODEL_98cdd6461b3b46a9aab314fabdc70caf"
            ],
            "layout": "IPY_MODEL_ab76c2cada82457ba9561bffc84576bc"
          }
        },
        "f1854c5107ef4cd9949e8f54d27a8905": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_22afb4a1f09644778bf4bb10c687644b",
            "placeholder": "​",
            "style": "IPY_MODEL_39a437e801504f4782f049ff65ea71d2",
            "value": " 570/570 [00:00&lt;00:00, 13.5kB/s]"
          }
        },
        "f1e4f8658078472caeedcff6038e236a": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f28d6656e9af4043aa86cafb8dd5a644": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f2b5e8e49cad4dea9a005c4a9332227c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f3311eaaaa634a25b15b696bd597ced0": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_99727414bc1146578aa17513e14e697b",
            "placeholder": "​",
            "style": "IPY_MODEL_1761b91723a845728299f470d05c9f5e",
            "value": " 50%"
          }
        },
        "f63a9a360181468a991009b14a271a46": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "f91d5ef6106e48c99ca2296c91c3c321": {
          "model_module": "@jupyter-widgets/controls",
          "model_module_version": "1.5.0",
          "model_name": "HTMLModel",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_7a874d40f81d48cb845f4d5dd83e7909",
            "placeholder": "​",
            "style": "IPY_MODEL_9268c5df10f94577ba3f2a1fab5b0595",
            "value": "Downloading (…)solve/main/vocab.txt: 100%"
          }
        },
        "f966b5e0e2a44868b76afe22ee15a51c": {
          "model_module": "@jupyter-widgets/base",
          "model_module_version": "1.2.0",
          "model_name": "LayoutModel",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
