{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/ChavChavC/BT4222/blob/main/Simple_ML_Models.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "t6-rYyCfA2pj"
      },
      "source": [
        "Models covered:\n",
        "\n",
        "* Multinomial Naive Bayes\n",
        "* SVM\n",
        "* Logistic Regression\n",
        "* Random Forest\n",
        "* K-Neighbors Classifier\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LK1mZ-PdGVvy"
      },
      "outputs": [],
      "source": [
        "!pip install datasets optuna"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_uGkA1NKKmG7"
      },
      "source": [
        "# Data cleaning and pre-processing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading in clean data"
      ],
      "metadata": {
        "id": "rBd0GXKr6JWq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GN1SAOTHdh6U",
        "outputId": "33ab185f-1dc0-4027-c30b-b331c5376f84"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 225
        },
        "id": "4evp8niubegW",
        "outputId": "dfb06da6-531e-4093-bf42-e846e017130e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13702\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  labels\n",
              "0           0  Gildan Activewear Reports Strong Results for t...       2\n",
              "1           1  TRILLION ENERGY ANNOUNCES FLOW TEST RESULTS FO...       2\n",
              "2           2             CAPREIT Announces October Distribution       1\n",
              "3           3  Unigold Inc Delivers Positive Feasibility Stud...       2\n",
              "4           4  Wallbridge Provides Update on Archer Explorati...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-a9fec94e-1d96-40e9-9f00-a8f21f7fc5ec\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>Gildan Activewear Reports Strong Results for t...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TRILLION ENERGY ANNOUNCES FLOW TEST RESULTS FO...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>CAPREIT Announces October Distribution</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>Unigold Inc Delivers Positive Feasibility Stud...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>Wallbridge Provides Update on Archer Explorati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-a9fec94e-1d96-40e9-9f00-a8f21f7fc5ec')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-a9fec94e-1d96-40e9-9f00-a8f21f7fc5ec button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-a9fec94e-1d96-40e9-9f00-a8f21f7fc5ec');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-1bd8718a-9789-4d72-ad1d-49ec0beb66e0\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-1bd8718a-9789-4d72-ad1d-49ec0beb66e0')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-1bd8718a-9789-4d72-ad1d-49ec0beb66e0 button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import pandas as pd\n",
        "\n",
        "data = pd.read_csv(\"/content/gdrive/My Drive/BT4222/new_data.csv\")\n",
        "data = data[~data[\"title\"].isnull()]\n",
        "\n",
        "print(len(data))\n",
        "data.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Lemmatization"
      ],
      "metadata": {
        "id": "skWSnpcl6NE8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import nltk\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "from nltk.tokenize import word_tokenize\n",
        "nltk.download('punkt')\n",
        "nltk.download('wordnet')"
      ],
      "metadata": {
        "id": "sFT94jpQdO2M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lemmatizer = WordNetLemmatizer()\n",
        "\n",
        "def lemmatize_sentence(text):\n",
        "    # Tokenize the sentence into words\n",
        "    words = word_tokenize(text)\n",
        "    lemmatized_words = [lemmatizer.lemmatize(word.lower()) for word in words]\n",
        "    lemmatized_sentence = ' '.join(lemmatized_words)\n",
        "    return lemmatized_sentence\n",
        "\n",
        "def lemmatize_dataset(sentences):\n",
        "    lemmatized = []\n",
        "    for sentence in sentences:\n",
        "        lemmatized.append(lemmatize_sentence(sentence))\n",
        "    return lemmatized\n",
        "\n",
        "data[\"title\"] = pd.Series(lemmatize_dataset(data[\"title\"]))\n",
        "\n",
        "data.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "opuejVrJdeXI",
        "outputId": "ab3e7b69-3db8-4984-ee41-3af64e46d456"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0                                              title  labels\n",
              "0           0  gildan activewear report strong result for the...       2\n",
              "1           1  trillion energy announces flow test result for...       2\n",
              "2           2             capreit announces october distribution       1\n",
              "3           3  unigold inc delivers positive feasibility stud...       2\n",
              "4           4  wallbridge provides update on archer explorati...       1"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-92492a24-b1d4-4037-848a-49cb5c2c8a74\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>title</th>\n",
              "      <th>labels</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>gildan activewear report strong result for the...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>trillion energy announces flow test result for...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>capreit announces october distribution</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>unigold inc delivers positive feasibility stud...</td>\n",
              "      <td>2</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>wallbridge provides update on archer explorati...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-92492a24-b1d4-4037-848a-49cb5c2c8a74')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-92492a24-b1d4-4037-848a-49cb5c2c8a74 button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-92492a24-b1d4-4037-848a-49cb5c2c8a74');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "<div id=\"df-78543a5e-52f6-4abb-ac46-53d194eefbfc\">\n",
              "  <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-78543a5e-52f6-4abb-ac46-53d194eefbfc')\"\n",
              "            title=\"Suggest charts\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "  </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "  <script>\n",
              "    async function quickchart(key) {\n",
              "      const quickchartButtonEl =\n",
              "        document.querySelector('#' + key + ' button');\n",
              "      quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "      quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "      try {\n",
              "        const charts = await google.colab.kernel.invokeFunction(\n",
              "            'suggestCharts', [key], {});\n",
              "      } catch (error) {\n",
              "        console.error('Error during call to suggestCharts:', error);\n",
              "      }\n",
              "      quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "      quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "    }\n",
              "    (() => {\n",
              "      let quickchartButtonEl =\n",
              "        document.querySelector('#df-78543a5e-52f6-4abb-ac46-53d194eefbfc button');\n",
              "      quickchartButtonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "    })();\n",
              "  </script>\n",
              "</div>\n",
              "    </div>\n",
              "  </div>\n"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creating train-validation-test split"
      ],
      "metadata": {
        "id": "8TvO27lj6Pzp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iO_y1ibRebV-"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "data = data[~data[\"title\"].isnull()]\n",
        "\n",
        "# create train : val : test split of 6 : 2 : 2\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    data[\"title\"], data[\"labels\"], test_size=0.2, shuffle=True, random_state=4222)\n",
        "X_train, X_val, y_train, y_val = train_test_split(\n",
        "    X_train, y_train, test_size=0.25, shuffle=True, random_state=4222)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GWQCbHS-cPgY"
      },
      "source": [
        "# Feature engineering"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mtBCox2Zbuk_"
      },
      "outputs": [],
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfTransformer\n",
        "from sklearn.feature_selection import SelectKBest, chi2\n",
        "import numpy as np\n",
        "\n",
        "# TFIDF for unigrams and bigrams\n",
        "ngram_vectorizer = TfidfVectorizer(ngram_range=(1, 2))\n",
        "ngram_matrix_train = ngram_vectorizer.fit_transform(X_train)\n",
        "ngram_matrix_val = ngram_vectorizer.transform(X_val)\n",
        "ngram_dense_matrix_train = ngram_matrix_train.todense()\n",
        "ngram_dense_matrix_val = ngram_matrix_val.todense()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D8uUCJdaNGFZ"
      },
      "outputs": [],
      "source": [
        "# TFIDF for unigrams only\n",
        "vectorizer = CountVectorizer().fit(X_train)\n",
        "X_train_count = vectorizer.transform(X_train)\n",
        "X_val_count = vectorizer.transform(X_val)\n",
        "\n",
        "transformer = TfidfTransformer().fit(X_train_count)\n",
        "X_train_feature = transformer.transform(X_train_count)\n",
        "X_val_feature = transformer.transform(X_val_count)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JH_e0eM3KuVt"
      },
      "source": [
        "# Testing out different sklearn classifiers"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xW9lxQMxcf1m"
      },
      "source": [
        "The main idea here is that we are using `optuna` library to help us finetune some of the hyperparameters for each of the models we have chosen. It will experiment with a range of hyperparameter values, as specified, and choose the set of hyperparameters that result in the greatest validation accuracy."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Hyperparameter fine-tuning for all classifiers, using TFIDF unigram data only"
      ],
      "metadata": {
        "id": "vgT9R-HD75nQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzMjRzt3N-Uu"
      },
      "outputs": [],
      "source": [
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.svm import LinearSVC\n",
        "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "import optuna\n",
        "optuna.logging.set_verbosity(optuna.logging.ERROR)\n",
        "\n",
        "\n",
        "def train_model(X_train, X_val, y_train, y_val, model):\n",
        "    \"\"\"Used to train the model and return predictions on validation data\"\"\"\n",
        "\n",
        "    model.fit(X_train, y_train)\n",
        "    y_pred = model.predict(X_val)\n",
        "\n",
        "    return y_pred\n",
        "\n",
        "# the following functions are used as objective functions for optuna to perform\n",
        "# hyperparameter fine-tuning\n",
        "# the return value will be maximised in the optimisation algorithm\n",
        "\n",
        "def objective_MNB(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 0.01, 1.0),\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, MultinomialNB(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "def objective_SVM(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        # \"loss\": trial.suggest_categorical(\"loss\", [\"hinge\", \"squared_hinge\"]),\n",
        "        \"C\": trial.suggest_float(\"C\", 0.1, 1.0),  # regularisation parameter\n",
        "        \"intercept_scaling\": trial.suggest_float(\"intercept_scaling\", 1.0, 10.0),  # allows intercept to have different regularisation behaviour from other features\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 5000, 10000),\n",
        "        \"dual\": False\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, LinearSVC(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "def objective_LR(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        \"C\": trial.suggest_float(\"C\", 0.01, 1.0),  # regularisation parameter\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 5000, 10000)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, LogisticRegression(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "def objective_RF(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 300),\n",
        "        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 100),\n",
        "        \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 30),\n",
        "        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
        "        \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 5, 1000),\n",
        "        # \"ccp_alpha\": trial.suggest_float(\"ccp_alpha\", 0.0, 10.0)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, RandomForestClassifier(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "\n",
        "def objective_KN(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 100),\n",
        "        \"leaf_size\": trial.suggest_int(\"leaf_size\", 1, 100)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, KNeighborsClassifier(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wirgRMKSI9Zl",
        "outputId": "bd3716ea-3096-4dc5-9f70-4bae2e4b53b9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
            "Default params acc: 0.6995253742241694\n",
            "Best params: {'alpha': 0.15223417247258386}\n",
            "Best params acc: 0.7619569185834246\n",
            "\n",
            "Classifier: <class 'sklearn.svm._classes.LinearSVC'>\n",
            "Default params acc: 0.7900693683826214\n",
            "Best params: {'C': 0.7397751893387812, 'intercept_scaling': 2.9888751603831105, 'max_iter': 9347}\n",
            "Best params acc: 0.7962760131434831\n",
            "\n",
            "Classifier: <class 'sklearn.linear_model._logistic.LogisticRegression'>\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/sklearn/linear_model/_logistic.py:458: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Default params acc: 0.7721796276013143\n",
            "Best params: {'C': 0.9907313081009161, 'max_iter': 9982}\n",
            "Best params acc: 0.7721796276013143\n",
            "\n",
            "Classifier: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "Default params acc: 0.7860533041255933\n",
            "Best params: {'n_estimators': 83, 'max_depth': 98, 'min_samples_split': 18, 'min_samples_leaf': 1, 'max_leaf_nodes': 821}\n",
            "Best params acc: 0.7488134355604235\n",
            "\n",
            "Classifier: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
            "Default params acc: 0.7440671778021175\n",
            "Best params: {'n_neighbors': 11, 'leaf_size': 1}\n",
            "Best params acc: 0.7612267250821467\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# this cell basically carries out model training multiple times with different hyperpameters\n",
        "# then chooses then ones that give the best validation accuracy\n",
        "\n",
        "objectives = [\n",
        "    [objective_MNB, MultinomialNB],\n",
        "    [objective_SVM, LinearSVC],\n",
        "    [objective_LR, LogisticRegression],\n",
        "    [objective_RF, RandomForestClassifier],\n",
        "    [objective_KN, KNeighborsClassifier]\n",
        "]\n",
        "\n",
        "best_params_dct = {}\n",
        "\n",
        "for objective, model in objectives:\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_feature, X_val_feature, y_train, y_val), n_trials=30)\n",
        "    params = study.best_params\n",
        "    best_params_dct[str(model)] = params\n",
        "\n",
        "    print(\"Classifier:\", model)\n",
        "    y_preds = train_model(X_train_feature, X_val_feature, y_train, y_val, model())\n",
        "    print(\"Default params acc:\", accuracy_score(y_val, y_preds))\n",
        "    print(\"Best params:\", params)\n",
        "    y_preds_2 = train_model(X_train_feature, X_val_feature, y_train, y_val, model(**params))\n",
        "    print(\"Best params acc:\", accuracy_score(y_val, y_preds_2))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Since there is risk of failure to convergence for LogisticRegression and LinearSVC, we try using SGDClassifier instead\n"
      ],
      "metadata": {
        "id": "eVh-ReZacjBQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1GEbiv9AMC5P",
        "outputId": "d693a72d-fec8-4210-cd4d-f6d935bfc6f8"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: SVM\n",
            "Default params acc: 0.7984665936473165\n",
            "Best params: {'alpha': 0.00010132788989789356, 'max_iter': 7079, 'penalty': 'elasticnet', 'warm_start': True, 'learning_rate': 'adaptive', 'eta0': 0.4325638808470886}\n",
            "Best params acc: 0.796641109894122\n",
            "\n",
            "Classifier: LR\n",
            "Default params acc: 0.764877692588536\n",
            "Best params: {'alpha': 0.00010561665784748327, 'max_iter': 1681, 'penalty': 'l1', 'warm_start': False, 'learning_rate': 'adaptive', 'eta0': 0.40050212305690175}\n",
            "Best params acc: 0.7882438846294268\n",
            "\n",
            "Classifier: Any\n",
            "Default params acc: 0.796641109894122\n",
            "Best params: {'loss': 'perceptron', 'alpha': 0.007482187295449014, 'max_iter': 7109, 'penalty': 'l2', 'warm_start': True, 'learning_rate': 'adaptive', 'eta0': 0.9426725754999974}\n",
            "Best params acc: 0.7517342095655348\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# the hyperparameters for the SGDClassifier are finetuned in a similar way as above\n",
        "\n",
        "def objective_SGD(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        \"loss\": trial.suggest_categorical(\"loss\", [\"modified_huber\", \"squared_hinge\", \"perceptron\"]),\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1),  # regularisation parameter\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 10000),\n",
        "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
        "        \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
        "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"optimal\", \"adaptive\"]),\n",
        "        \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, SGDClassifier(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "def objective_SVM_SGD(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        # \"loss\": trial.suggest_categorical(\"loss\", [\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\"]),\n",
        "        \"loss\": \"hinge\",\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1),  # regularisation parameter\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 10000),\n",
        "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
        "        \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
        "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"optimal\", \"adaptive\"]),\n",
        "        \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, SGDClassifier(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "def objective_LR_SGD(trial, X_train, X_val, y_train, y_val):\n",
        "    params = {\n",
        "        # \"loss\": trial.suggest_categorical(\"loss\", [\"hinge\", \"log_loss\", \"modified_huber\", \"squared_hinge\", \"perceptron\"]),\n",
        "        \"loss\": \"log_loss\",\n",
        "        \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1),  # regularisation parameter\n",
        "        \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 10000),\n",
        "        \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
        "        \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
        "        \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"optimal\", \"adaptive\"]),\n",
        "        \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0)\n",
        "    }\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, SGDClassifier(**params))\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "SGD_objectives = [\n",
        "    [objective_SVM_SGD, \"SVM\"],\n",
        "    [objective_LR_SGD, \"LR\"],\n",
        "    [objective_SGD, \"Any\"],\n",
        "]\n",
        "\n",
        "best_params_dct_1 = {}\n",
        "\n",
        "for objective, model in SGD_objectives:\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_feature, X_val_feature, y_train, y_val), n_trials=200)\n",
        "    params = study.best_params\n",
        "    best_params_dct_1[model] = params\n",
        "\n",
        "    print(\"Classifier:\", model)\n",
        "    if model == \"LR\":\n",
        "        y_preds = train_model(X_train_feature, X_val_feature, y_train, y_val, SGDClassifier(loss=\"log_loss\"))\n",
        "    else:\n",
        "        y_preds = train_model(X_train_feature, X_val_feature, y_train, y_val, SGDClassifier())\n",
        "    print(\"Default params acc:\", accuracy_score(y_val, y_preds))\n",
        "    print(\"Best params:\", params)\n",
        "    y_preds_2 = train_model(X_train_feature, X_val_feature, y_train, y_val, SGDClassifier(**params))\n",
        "    print(\"Best params acc:\", accuracy_score(y_val, y_preds_2))\n",
        "    print()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Hence, from here, we will proceed with using SGDClassifier for both logistic regression and SVM classifiers."
      ],
      "metadata": {
        "id": "ilvm2Zdq8Mqs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Hyperparameter fine-tuning for all classifiers using TFIDF with unigrams and bigrams\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "L7L1-qJB8sRL"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KfHlJPT-kQlc"
      },
      "outputs": [],
      "source": [
        "X_train_all_ngrams = np.array(ngram_dense_matrix_train)\n",
        "X_val_all_ngrams = np.array(ngram_dense_matrix_val)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(X_train_feature.shape)\n",
        "print(X_train_all_ngrams.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjhCWF2af2e2",
        "outputId": "d6eddb83-3a30-4ba0-c03c-34c829cf028a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(8216, 13199)\n",
            "(8216, 65895)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Can try using optuna to choose the best k"
      ],
      "metadata": {
        "id": "cRvZSp8jhyOp"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0oEJ4C6qxrY"
      },
      "outputs": [],
      "source": [
        "classifiers = [\n",
        "    MultinomialNB,\n",
        "    SGDClassifier,\n",
        "    RandomForestClassifier,\n",
        "    KNeighborsClassifier\n",
        "]\n",
        "\n",
        "def objective_k(trial, X_train, X_val, y_train, y_val, clf):\n",
        "\n",
        "    selector = SelectKBest(chi2, k=trial.suggest_int(\"k\", 500, 5000))\n",
        "    X_train = selector.fit_transform(X_train, y_train)\n",
        "    X_val = selector.transform(X_val)\n",
        "\n",
        "    y_pred = train_model(X_train, X_val, y_train, y_val, clf())\n",
        "\n",
        "    return accuracy_score(y_val, y_pred)\n",
        "\n",
        "best_params_dct_2 = {}\n",
        "\n",
        "for model in classifiers:\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective_k(\n",
        "        trial, X_train_all_ngrams, X_val_all_ngrams, y_train, y_val, model),\n",
        "                   n_trials=30)\n",
        "    params = study.best_params\n",
        "    best_params_dct_2[str(model)] = params\n",
        "\n",
        "    print(\"Classifier:\", model)\n",
        "    y_preds = train_model(X_train_all_ngrams, X_val_all_ngrams, y_train, y_val, model())\n",
        "    print(\"All ngrams acc:\", accuracy_score(y_val, y_preds))\n",
        "    print(\"Best params:\", params)\n",
        "    k = params[\"k\"]\n",
        "    selector = SelectKBest(chi2, k=k)\n",
        "    X_train_selected = selector.fit_transform(X_train_all_ngrams, y_train)\n",
        "    X_val_selected = selector.transform(X_val_all_ngrams)\n",
        "    y_preds_2 = train_model(X_train_selected, X_val_selected, y_train, y_val, model())\n",
        "    print(\"Selected params acc:\", accuracy_score(y_val, y_preds_2))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Hyperpameter fine-tuning using only 10,000 features for training, selected using SelectKBest\n"
      ],
      "metadata": {
        "id": "kniQ_6vJ87ib"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "selector = SelectKBest(chi2, k=10000)\n",
        "X_train_selected = selector.fit_transform(X_train_all_ngrams, y_train)\n",
        "X_val_selected = selector.transform(X_val_all_ngrams)"
      ],
      "metadata": {
        "id": "wX-edLG0Qr5B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eg4wTKeph39j",
        "outputId": "b35163b4-34d6-4cd1-a7dd-ce32ea27f48a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classifier: <class 'sklearn.naive_bayes.MultinomialNB'>\n",
            "Default params acc: 0.6856516976998904\n",
            "Best params: {'alpha': 0.017985757775145533}\n",
            "Best params acc: 0.7776560788608982\n",
            "\n",
            "Classifier: <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
            "Default params acc: 0.7940854326396495\n",
            "Best params: {'alpha': 0.000501578634830783, 'max_iter': 5851, 'penalty': 'elasticnet', 'warm_start': False, 'learning_rate': 'adaptive', 'eta0': 0.06828026948459881}\n",
            "Best params acc: 0.6973347937203359\n",
            "\n",
            "Classifier: <class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\n",
            "Default params acc: 0.7820372398685652\n",
            "Best params: {'alpha': 0.00029271480817876655, 'max_iter': 5766, 'penalty': 'l2', 'warm_start': True, 'learning_rate': 'optimal', 'eta0': 0.3074761528089284}\n",
            "Best params acc: 0.7458926615553122\n",
            "\n",
            "Classifier: <class 'sklearn.ensemble._forest.RandomForestClassifier'>\n",
            "Default params acc: 0.7663380795910917\n",
            "Best params: {'n_estimators': 171, 'max_depth': 100, 'min_samples_split': 27, 'min_samples_leaf': 1, 'max_leaf_nodes': 740}\n",
            "Best params acc: 0.7575757575757576\n",
            "\n",
            "Classifier: <class 'sklearn.neighbors._classification.KNeighborsClassifier'>\n",
            "Default params acc: 0.696604600219058\n",
            "Best params: {'n_neighbors': 1, 'leaf_size': 38}\n",
            "Best params acc: 0.7283680175246441\n",
            "\n"
          ]
        }
      ],
      "source": [
        "# the hyperparameters for the classifiers are finetuned to train well to a subset\n",
        "# of all the TFIDF of unigrams and bigrams\n",
        "\n",
        "objectives = [\n",
        "    [objective_MNB, MultinomialNB],\n",
        "    [objective_SVM_SGD, SGDClassifier],\n",
        "    [objective_LR_SGD, SGDClassifier],\n",
        "    [objective_RF, RandomForestClassifier],\n",
        "    [objective_KN, KNeighborsClassifier]\n",
        "]\n",
        "\n",
        "best_params_dct_3 = {}\n",
        "\n",
        "for objective, model in objectives:\n",
        "    # k = best_params_dct_2[str(model)][\"k\"]\n",
        "    # selector = SelectKBest(chi2, k=k)\n",
        "    # X_train_selected = selector.fit_transform(X_train_all_ngrams, y_train)\n",
        "    # X_val_selected = selector.transform(X_val_all_ngrams)\n",
        "\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective(trial, X_train_selected, X_val_selected, y_train, y_val), n_trials=30)\n",
        "    params = study.best_params\n",
        "    best_params_dct_3[str(model)] = params\n",
        "\n",
        "    print(\"Classifier:\", model)\n",
        "    y_preds = train_model(X_train_selected, X_val_selected, y_train, y_val, model())\n",
        "    print(\"Default params acc:\", accuracy_score(y_val, y_preds))\n",
        "    print(\"Best params:\", params)\n",
        "    y_preds_2 = train_model(X_train_selected, X_val_selected, y_train, y_val, model(**params))\n",
        "    print(\"Best params acc:\", accuracy_score(y_val, y_preds_2))\n",
        "    print()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Re-initialise `best_params_dct_3` in case of runtime disconnection"
      ],
      "metadata": {
        "id": "ATy4pH5f9XSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "best_params_dct_3 = {\n",
        "    \"<class 'sklearn.naive_bayes.MultinomialNB'>\": {'alpha': 0.017985757775145533},\n",
        "    \"<class 'sklearn.linear_model._stochastic_gradient.SGDClassifier'>\": {'alpha': 0.00029271480817876655,\n",
        "                                                                          'max_iter': 5766,\n",
        "                                                                          'penalty': 'l2',\n",
        "                                                                          'warm_start': True,\n",
        "                                                                          'learning_rate': 'optimal',\n",
        "                                                                          'eta0': 0.3074761528089284},\n",
        "    \"<class 'sklearn.ensemble._forest.RandomForestClassifier'>\": {'n_estimators': 171,\n",
        "                                                                  'max_depth': 100,\n",
        "                                                                  'min_samples_split': 27,\n",
        "                                                                  'min_samples_leaf': 1,\n",
        "                                                                  'max_leaf_nodes': 740},\n",
        "    \"<class 'sklearn.neighbors._classification.KNeighborsClassifier'>\": {'n_neighbors': 1,\n",
        "                                                                         'leaf_size': 38}\n",
        "}"
      ],
      "metadata": {
        "id": "afgwEYMmOV6x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Benchmark accuracies for all classifiers trained using all TFIDF unigrams and bigrams\n"
      ],
      "metadata": {
        "id": "SqnZY4O3-HFs"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The hyperparameters obtained from fine-tuning above (using only the top 10,000 features) are used below, for models where an improvement in validation accuracy was observed. Else, the default model hyperparameters are used."
      ],
      "metadata": {
        "id": "7CxetzAz-QJM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "finetuned_clfs = [\n",
        "    MultinomialNB(**best_params_dct_3[str(MultinomialNB)]),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier(**best_params_dct_3[str(KNeighborsClassifier)])\n",
        "]\n",
        "\n",
        "for clf in finetuned_clfs:\n",
        "    y_preds = train_model(X_train_all_ngrams, X_val_all_ngrams, y_train, y_val, clf)\n",
        "    print(clf)\n",
        "    print(\"val acc:\", accuracy_score(y_val, y_preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMPhXQ4FE52K",
        "outputId": "259f9db7-211d-4f97-d977-bbe3e2a879a9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7926250456370938\n",
            "\n",
            "SGDClassifier()\n",
            "val acc: 0.8185469149324571\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "val acc: 0.7656078860898138\n",
            "\n",
            "RandomForestClassifier()\n",
            "val acc: 0.7772909821102593\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.7144943410003651\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIhwJlhThFqg"
      },
      "source": [
        "## Test out different model aggregation algorithms"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "aCCqK5ERhTUp"
      },
      "source": [
        "Brainstorming for ideas:\n",
        "\n",
        "1. Use all classifiers that predict using probabilities, then classify based on highest average probability across all classifiers\n",
        "2. Have 2 different classifiers, the first one classifies everything, then whatever it classifies wrongly or un-confidently (based on a certain probability threshold value) gets passed on to the second classifier. The second classifier is only fitted on these \"difficult\" cases, to try to classify them correctly.\n",
        "    - can try integrating feature selection from model as well\n",
        "3. Use all classifiers that predict using probabilities, then use a second model to output the final class based on the concatenated probabilities (stacking)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0UKnkOGg_P3R"
      },
      "source": [
        "### Idea 1: Weighted Average"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The average of the predictions from various classifiers is taken to be the final prediction. The predictions are weighted based on the prediction confidence. For SVM without prediction probabilities available, a customisable `prob` value is assigned to the class it predicts to, and `0` otherwise."
      ],
      "metadata": {
        "id": "KsG3rVHI-1pB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import OneHotEncoder\n",
        "\n",
        "def weighted_avg_preds(clfs, X_val, y_val, prob=0.9):\n",
        "    preds_probs = []\n",
        "    for clf in clfs:\n",
        "        if hasattr(clf, \"predict_proba\"):  # all classifiers except SVM\n",
        "            preds_probs.append(clf.predict_proba(X_val))\n",
        "        else:  # SVM\n",
        "            enc = OneHotEncoder()\n",
        "            enc.fit(np.expand_dims(np.array(y_val), axis=1))\n",
        "            preds_probs.append(enc.transform(np.expand_dims(clf.predict(X_val), axis=1)).toarray() * prob)\n",
        "    summed_preds_probs = preds_probs[0]\n",
        "    for pred in preds_probs[1:]:\n",
        "        summed_preds_probs += pred\n",
        "\n",
        "    preds = np.argmax(summed_preds_probs, axis=1)\n",
        "    return accuracy_score(y_val, preds)"
      ],
      "metadata": {
        "id": "fRJJlHU7grlA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggregation of all models trained on previously selected (10,000) features"
      ],
      "metadata": {
        "id": "JAtbKR5w_XBN"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b7ifJlSf9vH1",
        "outputId": "c585eafd-63be-4aaa-d703-6d34b7d13b66"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.7802117561153705"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "clfs = []\n",
        "for clf in second:\n",
        "    clf.fit(X_train_selected, y_train)\n",
        "    clfs.append(clf)\n",
        "\n",
        "weighted_avg_preds(clfs, X_val_selected, y_val)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Aggregation of top 3 performing models (SVM, Logistic Regression, Multinomial NB) trained on all features"
      ],
      "metadata": {
        "id": "8-5bWD0__gcl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = SGDClassifier(\"log_loss\")\n",
        "clf2 = SGDClassifier()\n",
        "clf3 = MultinomialNB(alpha=0.017985757775145533)\n",
        "\n",
        "clf1.fit(X_train_all_ngrams, y_train)\n",
        "clf2.fit(X_train_all_ngrams, y_train)\n",
        "clf3.fit(X_train_all_ngrams, y_train)\n",
        "\n",
        "clfs = [clf1, clf2, clf3]"
      ],
      "metadata": {
        "id": "ghfwJI-_thg4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for clf in clfs:\n",
        "    print(accuracy_score(clf.predict(X_val_all_ngrams), y_val))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ydto3OXswQ6x",
        "outputId": "70eedb5b-c472-4829-fb79-57c59a2a6411"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7714494341000365\n",
            "0.8181818181818182\n",
            "0.7926250456370938\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "weighted_avg_preds(clfs, X_val_all_ngrams, y_val, prob=0.7)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5kIuyywwuAIH",
        "outputId": "10fb8182-ecaf-426e-a015-0a1b38505ea1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8159912376779846"
            ]
          },
          "metadata": {},
          "execution_count": 137
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IfWDpSSU_NTW"
      },
      "source": [
        "### Idea 2: Classifier Pairs\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The basic idea here is that Classifier 1 will be trained on all data points. Tthose points classified wrongly, or under a certain confidence threshold will be used to train Classifier 2. The predictions from Classifier 2 will replace those made by Classifier 1.\n",
        "\n",
        "During evaluation, similar to above, Classifier 1 will be used to obtain the prediction probabilities for all data points, and those below a certain threshold will be classified by Classifier 2 instead."
      ],
      "metadata": {
        "id": "oSojqGJzAGl4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "One point to note for this algorithm is that since SVM classifier does not have prediction probabilities, it will be omitted from the choice of Classifier 1."
      ],
      "metadata": {
        "id": "ENZCOPpHA1TO"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6bZdXKGnqu4A"
      },
      "outputs": [],
      "source": [
        "def get_repred_ind(clf, X, y=None, threshold=0.7):\n",
        "    \"\"\"Obtains the indices of data points to be classified by Classifier 2\"\"\"\n",
        "\n",
        "    pred_probs = clf.predict_proba(X)\n",
        "    if y is not None:\n",
        "        threshold_col = np.expand_dims(np.array([threshold]*pred_probs.shape[0]), axis=1)\n",
        "        pred_probs_threshed = np.append(pred_probs, threshold_col, axis=1)\n",
        "        repredict_ind = np.where(np.argmax(pred_probs_threshed, axis=1) != y)[0]\n",
        "    else:\n",
        "        repredict_ind = np.where(np.max(pred_probs, axis=1) < threshold)[0]\n",
        "    return repredict_ind\n",
        "\n",
        "def train_ensem_model(clf1, clf2, X_train, y_train, threshold=0.7):\n",
        "    \"\"\"Trains both Classifier 1 and 2\"\"\"\n",
        "\n",
        "    clf1.fit(X_train, y_train)\n",
        "    repredict_ind = get_repred_ind(clf1, X_train, y_train, threshold)\n",
        "    if len(repredict_ind) == 0:\n",
        "        print(\"second classifier trained on all data\")\n",
        "        clf2.fit(X_train, y_train)\n",
        "    else:\n",
        "        clf2.fit(X_train[repredict_ind], np.array(y_train)[repredict_ind])\n",
        "    return clf1, clf2\n",
        "\n",
        "def eval_ensem_model(clf1, clf2, X_val, y_val, threshold=0.7):\n",
        "    \"\"\"Used to make predictions on validation data, using both Classifier 1 and 2\"\"\"\n",
        "\n",
        "    pred_probs = clf1.predict_proba(X_val)\n",
        "    repredict_ind = get_repred_ind(clf1, X_val, threshold)\n",
        "    if len(repredict_ind) > 0:\n",
        "        repredict_preds = clf2.predict(X_val[repredict_ind])\n",
        "        preds = clf1.predict(X_val)\n",
        "        preds[repredict_ind] = repredict_preds\n",
        "    else:\n",
        "        print(\"second classifier not used for evaluation\")\n",
        "        preds = clf1.predict(X_val)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    return preds, acc\n"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### All possible combinations of classifier pairs are tested, using previously selected (10,000) features"
      ],
      "metadata": {
        "id": "3UKl7Q3lBCvH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "first = [\n",
        "    MultinomialNB(**best_params_dct_3[str(MultinomialNB)]),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier(**best_params_dct_3[str(KNeighborsClassifier)])\n",
        "]\n",
        "second = [\n",
        "    MultinomialNB(**best_params_dct_3[str(MultinomialNB)]),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier(**best_params_dct_3[str(KNeighborsClassifier)])\n",
        "]"
      ],
      "metadata": {
        "id": "XVFqx9HFOVMK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3IGtj-2axpbG",
        "outputId": "3587610d-b51d-4bf0-9682-2e8cad35d5a2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7776560788608982\n",
            "\n",
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: SGDClassifier()\n",
            "val acc: 0.7944505293902884\n",
            "\n",
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: SGDClassifier(loss='log_loss')\n",
            "val acc: 0.7824023366192041\n",
            "\n",
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: RandomForestClassifier()\n",
            "val acc: 0.7867834976268712\n",
            "\n",
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.764512595837897\n",
            "\n",
            "clf1: SGDClassifier(loss='log_loss')\n",
            "clf2: MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7772909821102593\n",
            "\n",
            "clf1: SGDClassifier(loss='log_loss')\n",
            "clf2: SGDClassifier()\n",
            "val acc: 0.7940854326396495\n",
            "\n",
            "clf1: SGDClassifier(loss='log_loss')\n",
            "clf2: SGDClassifier(loss='log_loss')\n",
            "val acc: 0.7579408543263965\n",
            "\n",
            "clf1: SGDClassifier(loss='log_loss')\n",
            "clf2: RandomForestClassifier()\n",
            "val acc: 0.7637824023366192\n",
            "\n",
            "clf1: SGDClassifier(loss='log_loss')\n",
            "clf2: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.7429718875502008\n",
            "\n",
            "clf1: RandomForestClassifier()\n",
            "clf2: MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7864184008762322\n",
            "\n",
            "clf1: RandomForestClassifier()\n",
            "clf2: SGDClassifier()\n",
            "val acc: 0.7791164658634538\n",
            "\n",
            "clf1: RandomForestClassifier()\n",
            "clf2: SGDClassifier(loss='log_loss')\n",
            "val acc: 0.7594012413289521\n",
            "\n",
            "clf1: RandomForestClassifier()\n",
            "clf2: RandomForestClassifier()\n",
            "val acc: 0.7667031763417306\n",
            "\n",
            "clf1: RandomForestClassifier()\n",
            "clf2: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.7426067907995619\n",
            "\n",
            "clf1: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "clf2: MultinomialNB(alpha=0.017985757775145533)\n",
            "second classifier not used for evaluation\n",
            "val acc: 0.7283680175246441\n",
            "\n",
            "clf1: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "clf2: SGDClassifier()\n",
            "second classifier not used for evaluation\n",
            "val acc: 0.7283680175246441\n",
            "\n",
            "clf1: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "clf2: SGDClassifier(loss='log_loss')\n",
            "second classifier not used for evaluation\n",
            "val acc: 0.7283680175246441\n",
            "\n",
            "clf1: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "clf2: RandomForestClassifier()\n",
            "second classifier not used for evaluation\n",
            "val acc: 0.7283680175246441\n",
            "\n",
            "clf1: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "clf2: KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "second classifier not used for evaluation\n",
            "val acc: 0.7283680175246441\n",
            "\n"
          ]
        }
      ],
      "source": [
        "classifier_pairs = []\n",
        "for clf1 in first:\n",
        "    for clf2 in second:\n",
        "        classifier_pairs.append([clf1, clf2])\n",
        "\n",
        "max_val_acc = 0\n",
        "best_clf1 = None\n",
        "best_clf2 = None\n",
        "for clf1, clf2 in classifier_pairs:\n",
        "    clf1, clf2 = train_ensem_model(clf1, clf2, X_train_selected, y_train)\n",
        "    print(\"clf1:\", clf1)\n",
        "    print(\"clf2:\", clf2)\n",
        "    preds, acc = eval_ensem_model(clf1, clf2, X_val_selected, y_val)\n",
        "    print(\"val acc:\", acc)\n",
        "    print()\n",
        "    if acc > max_val_acc:\n",
        "        max_val_acc = acc\n",
        "        best_clf1 = clf1\n",
        "        best_clf2 = clf2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4l97XZLS0ufQ",
        "outputId": "266ae681-fe4a-4f93-b99e-bee18ce61644"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best ensemble model:\n",
            "clf1: MultinomialNB(alpha=0.017985757775145533)\n",
            "clf2: SGDClassifier()\n",
            "val acc: 0.7944505293902884\n"
          ]
        }
      ],
      "source": [
        "print(\"Best ensemble model:\")\n",
        "print(\"clf1:\", best_clf1)\n",
        "print(\"clf2:\", best_clf2)\n",
        "print(\"val acc:\", max_val_acc)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The top 2 classifier pairs are Multinomial NB + SVM and Logistic Regression + SVM.\n",
        "\n",
        "The focus of subsequent efforts to improve model performance using this aggregation technique will work with these 2 pairs only."
      ],
      "metadata": {
        "id": "6vMu1fnPBx8K"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Experimenting with different threshold values"
      ],
      "metadata": {
        "id": "G0Q53klJTVE1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here, we experiment with different threshold values in range [0.6, 0.9] to find the best validation accuracy."
      ],
      "metadata": {
        "id": "BFVLHJtsB4gJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = MultinomialNB(alpha=0.017985757775145533)\n",
        "clf2 = SGDClassifier()\n",
        "\n",
        "clf1, clf2 = train_ensem_model(clf1, clf2, X_train_selected, y_train, threshold=0.8)\n",
        "preds, acc = eval_ensem_model(clf1, clf2, X_val_selected, y_val, threshold=0.7)"
      ],
      "metadata": {
        "id": "cVQ64laATcXn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using the previous selected (10,000) features as training data, the best threshold values for training and evaluation are 0.85 and 0.7 respectively.\n",
        "\n",
        "This gives rise to a 0.80066 accuracy."
      ],
      "metadata": {
        "id": "hvPunOLBCHBc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = MultinomialNB(alpha=0.017985757775145533)\n",
        "clf2 = SGDClassifier()\n",
        "\n",
        "clf1, clf2 = train_ensem_model(clf1, clf2, X_train_all_ngrams, y_train, threshold=0.85)\n",
        "preds, acc = eval_ensem_model(clf1, clf2, X_val_all_ngrams, y_val, threshold=0.75)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MpD3z8iGUEGF",
        "outputId": "06f4c7a7-1ae9-44ca-e553-40310cd63e16"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8174516246805403"
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Using all the n-gram data for training, the best threshold values for training and evaluation are 0.85 and 0.75 respectively.\n",
        "\n",
        "This gives rise to a 0.81745 accuracy."
      ],
      "metadata": {
        "id": "5fpBTW41CzSl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1 = SGDClassifier(\"log_loss\")\n",
        "clf2 = SGDClassifier()\n",
        "\n",
        "clf1, clf2 = train_ensem_model(clf1, clf2, X_train_all_ngrams, y_train, threshold=0.85)\n",
        "preds, acc = eval_ensem_model(clf1, clf2, X_val_all_ngrams, y_val, threshold=0.75)\n",
        "acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DPaHzRxcfbLx",
        "outputId": "9cfe6060-45af-4f62-bbec-2a7cebc1db17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8170865279299014"
            ]
          },
          "metadata": {},
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Similar results can be observed for the 2nd best classifier pair above."
      ],
      "metadata": {
        "id": "cO4hHRAYDQmt"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Trial and error results"
      ],
      "metadata": {
        "id": "gQJ3LCRtCZoq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "threshold values for train, eval: classification accuracy using selected, all ngrams\n",
        "\n",
        "0.6, 0.6: 0.7849580138736765, 0.805403431909456\n",
        "\n",
        "0.7, 0.6: 0.7882438846294268, 0.8108798831690398\n",
        "\n",
        "0.7, 0.7: 0.7933552391383717, 0.8116100766703176\n",
        "\n",
        "0.8, 0.7: 0.7988316903979554, 0.8167214311792625\n",
        "\n",
        "0.85, 0.7: 0.80065717415115, 0.8163563344286235\n",
        "\n",
        "0.85, 0.75: 0.7995618838992333, 0.8174516246805403"
      ],
      "metadata": {
        "id": "r4iSeeHEWKpe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trying out weighted average for evaluation"
      ],
      "metadata": {
        "id": "ZdbzzUULCd7N"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Instead of using the threshold algorithm during evaluation, weighted average is used instead.\n",
        "\n",
        "The models are still trained using the threshold algorithm though."
      ],
      "metadata": {
        "id": "59Kp4qkpDumU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "clf1a = MultinomialNB(alpha=0.017985757775145533)\n",
        "clf2a = SGDClassifier()\n",
        "\n",
        "clf1a, clf2a = train_ensem_model(clf1a, clf2a, X_train_all_ngrams, y_train)\n",
        "\n",
        "clf1b = SGDClassifier(loss=\"log_loss\")\n",
        "clf2b = SGDClassifier()\n",
        "\n",
        "clf1b, clf2b = train_ensem_model(clf1b, clf2b, X_train_all_ngrams, y_train)"
      ],
      "metadata": {
        "id": "94bj-ERdkkwM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs_a = [clf1a, clf2a]\n",
        "\n",
        "clfs_b = [clf1b, clf2b]\n",
        "\n",
        "print(weighted_avg_preds(clfs_a, X_val_all_ngrams, y_val, prob=0.85))\n",
        "print(weighted_avg_preds(clfs_b, X_val_all_ngrams, y_val, prob=0.85))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IaFkAQ4NkmnF",
        "outputId": "3f4c56c1-7b6a-48a4-f06a-833321e74b50"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.8170865279299014\n",
            "0.8159912376779846\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "By experimenting with different values for the `prob` value used to weight the predictions made by SVM, the best `prob` for classifier pair a and b are 0.85 and 0.9 respectively, resulting in accuracies 0.81709 and 0.81599 respectively."
      ],
      "metadata": {
        "id": "SgbjT0_FECV-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Trial and error results"
      ],
      "metadata": {
        "id": "nd57ANa4D9A_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "training, pred threshold: weighted acc\n",
        "\n",
        "0.6, 0.9: 0.8152610441767069, 0.8178167214311792\n",
        "\n",
        "0.8, 0.85: 0.818912011683096, 0.8127053669222344\n",
        "\n",
        "0.85, 0.85: 0.818912011683096, 0.8127053669222344\n",
        "\n",
        "0.9, 0.9: 0.8170865279299014, 0.8159912376779846"
      ],
      "metadata": {
        "id": "IOpOKOnlnOSP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Trying out using feature selection for Classifier 2 inputs"
      ],
      "metadata": {
        "id": "r1iig3dwysG3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The idea here is that the data points identified for Classifier 2 remains the same, but instead of using all the features to train Classifier 2, we use a selector to select the most important 10,000 features first, and train Classifier 2 only on those features.\n",
        "\n",
        "Similarly, during evaluation, feature selection precedes prediction by Classifier 2.\n",
        "\n",
        "Classifier 1 is not affected."
      ],
      "metadata": {
        "id": "Dtp5RNk7Esnx"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Testing different selector functions"
      ],
      "metadata": {
        "id": "LyYn6x6vEoKX"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_selection import SelectFromModel"
      ],
      "metadata": {
        "id": "uVqkyoaWyr4S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "selector1 = SelectFromModel(estimator=SGDClassifier(), max_features=10000, threshold=-np.inf).fit(X_train_all_ngrams, y_train)\n",
        "X_train_selected_2 = selector1.transform(X_train_all_ngrams)\n",
        "X_val_selected_2 = selector1.transform(X_val_all_ngrams)"
      ],
      "metadata": {
        "id": "gk7yN2Kfe7At"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for clf in second:\n",
        "    y_preds = train_model(X_train_selected_2, X_val_selected_2, y_train, y_val, clf)\n",
        "    print(clf)\n",
        "    print(\"val acc:\", accuracy_score(y_val, y_preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sQL1t6up0lhH",
        "outputId": "a838353f-48c7-498d-ab08-3824ea6321c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7849580138736765\n",
            "\n",
            "SGDClassifier()\n",
            "val acc: 0.80065717415115\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "val acc: 0.768893756845564\n",
            "\n",
            "RandomForestClassifier()\n",
            "val acc: 0.7791164658634538\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.7458926615553122\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "selector2 = SelectFromModel(estimator=SGDClassifier(\"log_loss\"), max_features=10000, threshold=-np.inf).fit(X_train_all_ngrams, y_train)\n",
        "X_train_selected_3 = selector2.transform(X_train_all_ngrams)\n",
        "X_val_selected_3 = selector2.transform(X_val_all_ngrams)\n",
        "for clf in second:\n",
        "    y_preds = train_model(X_train_selected_3, X_val_selected_3, y_train, y_val, clf)\n",
        "    print(clf)\n",
        "    print(\"val acc:\", accuracy_score(y_val, y_preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ljtE3Q81ctp",
        "outputId": "c942a43b-8540-420e-8ad6-d638ccdc86b2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB(alpha=0.017985757775145533)\n",
            "val acc: 0.7864184008762322\n",
            "\n",
            "SGDClassifier()\n",
            "val acc: 0.796641109894122\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "val acc: 0.7579408543263965\n",
            "\n",
            "RandomForestClassifier()\n",
            "val acc: 0.7805768528660095\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "val acc: 0.7437020810514786\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best selector function is SelectFromModel, using SVM as the model."
      ],
      "metadata": {
        "id": "E6ddfy0bFBfk"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Carrying out the model training with inbuilt feature selection"
      ],
      "metadata": {
        "id": "I7l_dRpPFHAj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_repred_ind(clf, X, y=None, threshold=0.85):\n",
        "    \"\"\"Obtains the indices of data points to be classified by Classifier 2\"\"\"\n",
        "\n",
        "    pred_probs = clf.predict_proba(X)\n",
        "    if y is not None:\n",
        "        threshold_col = np.expand_dims(np.array([threshold]*pred_probs.shape[0]), axis=1)\n",
        "        pred_probs_threshed = np.append(pred_probs, threshold_col, axis=1)\n",
        "        repredict_ind = np.where(np.argmax(pred_probs_threshed, axis=1) != y)[0]\n",
        "    else:\n",
        "        repredict_ind = np.where(np.max(pred_probs, axis=1) < threshold)[0]\n",
        "    return repredict_ind\n",
        "\n",
        "def train_ensem_model(clf1, clf2, X_train, y_train, threshold=0.85):\n",
        "    \"\"\"Trains both Classifier 1 and 2\"\"\"\n",
        "\n",
        "    clf1.fit(X_train, y_train)\n",
        "    repredict_ind = get_repred_ind(clf1, X_train, y_train, threshold)\n",
        "    if len(repredict_ind) == 0:\n",
        "        print(\"second classifier trained on all data\")\n",
        "        clf2.fit(selector1.transform(X_train), np.array(y_train))  # selector used\n",
        "    else:\n",
        "        clf2.fit(selector1.transform(X_train[repredict_ind]), np.array(y_train)[repredict_ind])  # selector used\n",
        "    return clf1, clf2\n",
        "\n",
        "def eval_ensem_model(clf1, clf2, X_val, y_val, threshold=0.7):\n",
        "    \"\"\"Used to make predictions on validation data, using both Classifier 1 and 2\"\"\"\n",
        "\n",
        "    pred_probs = clf1.predict_proba(X_val)\n",
        "    repredict_ind = get_repred_ind(clf1, X_val)\n",
        "    if len(repredict_ind) > 0:\n",
        "        repredict_preds = clf2.predict(selector1.transform(X_val[repredict_ind]))  # selector used before prediction\n",
        "        preds = clf1.predict(X_val)\n",
        "        preds[repredict_ind] = repredict_preds\n",
        "    else:\n",
        "        print(\"second classifier not used for evaluation\")\n",
        "        preds = clf1.predict(X_val)\n",
        "    acc = accuracy_score(y_val, preds)\n",
        "    return preds, acc"
      ],
      "metadata": {
        "id": "KekNCRyy8LR4"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# testing out the performance of the top 2 classifier pairs\n",
        "\n",
        "clf1a = MultinomialNB(alpha=0.017985757775145533)\n",
        "clf2a = SGDClassifier()\n",
        "\n",
        "clf1a, clf2a = train_ensem_model(clf1a, clf2a, X_train_all_ngrams, y_train, threshold=0.85)\n",
        "preds_a, acc_a = eval_ensem_model(clf1a, clf2a, X_val_all_ngrams, y_val, threshold=0.85)\n",
        "print(acc_a)\n",
        "\n",
        "clf1b = SGDClassifier(loss=\"log_loss\")\n",
        "clf2b = SGDClassifier()\n",
        "\n",
        "clf1b, clf2b = train_ensem_model(clf1b, clf2b, X_train_all_ngrams, y_train, threshold=0.85)\n",
        "preds_b, acc_b = eval_ensem_model(clf1b, clf2b, X_val_all_ngrams, y_val, threshold=0.85)\n",
        "print(acc_b)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WSaQ0-NR88g6",
        "outputId": "15d7933a-607f-40cf-a467-768e0be6b3ee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7652427893391749\n",
            "0.8032128514056225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_avg_pred_ensem(clfs, X_val, y_val, selector, prob=0.9):\n",
        "    \"\"\"Used to get average prediction, weighted by confidence of each classifier\"\"\"\n",
        "\n",
        "    preds_probs = []\n",
        "    clf1, clf2 = clfs\n",
        "    preds_probs.append(clf1.predict_proba(X_val))\n",
        "    X_val_2 = selector.transform(X_val)\n",
        "    if hasattr(clf2, \"predict_proba\"):\n",
        "        preds_probs.append(clf2.predict_proba(X_val_2))\n",
        "    else:\n",
        "        enc = OneHotEncoder()\n",
        "        enc.fit(np.expand_dims(np.array(y_val), axis=1))\n",
        "        preds_probs.append(enc.transform(np.expand_dims(clf2.predict(X_val_2), axis=1)).toarray() * prob)\n",
        "    summed_preds_probs = preds_probs[0] + preds_probs[1]\n",
        "\n",
        "    preds = np.argmax(summed_preds_probs, axis=1)\n",
        "    return accuracy_score(y_val, preds)"
      ],
      "metadata": {
        "id": "DDC18YFSD2y7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clfs_a = [clf1a, clf2a]\n",
        "clfs_b = [clf1b, clf2b]\n",
        "\n",
        "print(weighted_avg_pred_ensem(clfs_a, X_val_all_ngrams, y_val, selector1, prob=0.9))\n",
        "print(weighted_avg_pred_ensem(clfs_b, X_val_all_ngrams, y_val, selector1, prob=0.9))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t65GjGurDe7h",
        "outputId": "183d4234-eea2-4575-f076-d6fb44d0d60f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0.7433369843008397\n",
            "0.8032128514056225\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Both the threshold evaluation and weighted average evaluation methods are tested, but both do not seem to improve the results of the classifier pair algorithm much."
      ],
      "metadata": {
        "id": "Ukj8szhbFQ_3"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BUsZI3CdBjCb"
      },
      "source": [
        "### Idea 3: Stacking"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Each base learner is trained using the optimal hyperparameters obtained in previous parts. All the prediction confidences are used as inputs into the meta-learner to aggregate and output the final classification.\n",
        "\n",
        "Similar to above, the confidence value for SVM predictions is set manually."
      ],
      "metadata": {
        "id": "72M09iLWF1l1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_proba(clfs, X, y, prob=0.9):\n",
        "    \"\"\"Get concatenated prediction probabilities for all classes from all classifiers\"\"\"\n",
        "\n",
        "    preds_probs = []\n",
        "    for clf in clfs:\n",
        "        if hasattr(clf, \"predict_proba\"):\n",
        "            preds_probs.append(clf.predict_proba(X))\n",
        "        else:\n",
        "            enc = OneHotEncoder()\n",
        "            enc.fit(np.expand_dims(np.array(y), axis=1))\n",
        "            preds_probs.append(enc.transform(np.expand_dims(clf.predict(X), axis=1)).toarray() * prob)\n",
        "    collated = np.concatenate(preds_probs, axis=1)\n",
        "    return collated"
      ],
      "metadata": {
        "id": "mjhfQiUhVdf3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use all classifiers on all features in aggregation"
      ],
      "metadata": {
        "id": "uYX1N2XdGrWo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "trained_all_ngrams = [\n",
        "    MultinomialNB(**best_params_dct_3[str(MultinomialNB)]),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier(**best_params_dct_3[str(KNeighborsClassifier)])\n",
        "]\n",
        "\n",
        "for clf in trained_all_ngrams:\n",
        "    clf.fit(X_train_all_ngrams, y_train)"
      ],
      "metadata": {
        "id": "vu_1LM6iGunV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "finals = [\n",
        "    MultinomialNB(),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier()\n",
        "]\n",
        "\n",
        "train_probs = get_proba(trained_all_ngrams, X_train_all_ngrams, y_train, prob=1.7)\n",
        "val_probs = get_proba(trained_all_ngrams, X_val_all_ngrams, y_train, prob=1.7)\n",
        "\n",
        "for final in finals:\n",
        "    final.fit(train_probs, y_train)\n",
        "    preds = final.predict(val_probs)\n",
        "    print(clf)  # typo: shld be print(final)\n",
        "    print(accuracy_score(y_val, preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_lZF8sbEFseM",
        "outputId": "a9c60dd4-a8d1-4d74-a025-f30ce0369167"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "0.8174516246805403\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "0.7155896312522818\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "0.7721796276013143\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "0.7758305951077036\n",
            "\n",
            "KNeighborsClassifier(leaf_size=38, n_neighbors=1)\n",
            "0.7152245345016429\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use top 4 classifiers on all features in aggregation"
      ],
      "metadata": {
        "id": "G61BvpMsS-NE"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use all models except knn\n",
        "\n",
        "finals = [\n",
        "    MultinomialNB(),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier()\n",
        "]\n",
        "\n",
        "train_probs = get_proba(trained_all_ngrams[:4], X_train_all_ngrams, y_train, prob=1.3)\n",
        "val_probs = get_proba(trained_all_ngrams[:4], X_val_all_ngrams, y_train, prob=1.3)\n",
        "\n",
        "for final in finals:\n",
        "    final.fit(train_probs, y_train)\n",
        "    preds = final.predict(val_probs)\n",
        "    print(final)\n",
        "    print(accuracy_score(y_val, preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vax5-P0hQo7A",
        "outputId": "2d295cc8-397f-4e8c-8bab-66fe42e159de"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "0.8185469149324571\n",
            "\n",
            "SGDClassifier()\n",
            "0.8218327856882074\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "0.8181818181818182\n",
            "\n",
            "RandomForestClassifier()\n",
            "0.7838627236217598\n",
            "\n",
            "KNeighborsClassifier()\n",
            "0.8039430449069004\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### Trial and error results"
      ],
      "metadata": {
        "id": "NM8SGri4TLXY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "0.9\n",
        "\n",
        "MultinomialNB()\n",
        "0.8174516246805403\n",
        "\n",
        "SGDClassifier()\n",
        "0.809784592917123\n",
        "\n",
        "SGDClassifier(loss='log_loss')\n",
        "0.8203723986856517\n",
        "\n",
        "RandomForestClassifier()\n",
        "0.7893391748813435\n",
        "\n",
        "KNeighborsClassifier()\n",
        "0.8039430449069004\n",
        "\n",
        "\n",
        "1.4\n",
        "\n",
        "MultinomialNB()\n",
        "0.8185469149324571\n",
        "\n",
        "SGDClassifier()\n",
        "0.8218327856882074\n",
        "\n",
        "SGDClassifier(loss='log_loss')\n",
        "0.8185469149324571\n",
        "\n",
        "RandomForestClassifier()\n",
        "0.7926250456370938\n",
        "\n",
        "KNeighborsClassifier()\n",
        "0.8039430449069004\n",
        "\n",
        "1.7\n",
        "\n",
        "MultinomialNB()\n",
        "0.8185469149324571\n",
        "\n",
        "SGDClassifier()\n",
        "0.8141657539247901\n",
        "\n",
        "SGDClassifier(loss='log_loss')\n",
        "0.8185469149324571\n",
        "\n",
        "RandomForestClassifier()\n",
        "0.7907995618838992\n",
        "\n",
        "KNeighborsClassifier()\n",
        "0.8039430449069004"
      ],
      "metadata": {
        "id": "LaBCcIL9UbV1"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use top 3 classifiers on all features in aggregation"
      ],
      "metadata": {
        "id": "Shn2DSZuTQDd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# use all models except rf and knn\n",
        "\n",
        "finals = [\n",
        "    MultinomialNB(),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier()\n",
        "]\n",
        "\n",
        "train_probs = get_proba(trained_all_ngrams[:3], X_train_all_ngrams, y_train, prob=1.2)\n",
        "val_probs = get_proba(trained_all_ngrams[:3], X_val_all_ngrams, y_train, prob=1.2)\n",
        "\n",
        "for final in finals:\n",
        "    final.fit(train_probs, y_train)\n",
        "    preds = final.predict(val_probs)\n",
        "    print(final)\n",
        "    print(accuracy_score(y_val, preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LnWdY_tQR5LP",
        "outputId": "3404a391-4a8d-4db3-ea3d-3eeeaf861315"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "0.8185469149324571\n",
            "\n",
            "SGDClassifier()\n",
            "0.7981014968966776\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "0.8108798831690398\n",
            "\n",
            "RandomForestClassifier()\n",
            "0.7838627236217598\n",
            "\n",
            "KNeighborsClassifier()\n",
            "0.7944505293902884\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Use top 4 classifiers on selected features in aggregation"
      ],
      "metadata": {
        "id": "Cm3nyIosTqIy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# using seleted features only\n",
        "\n",
        "trained_selected = [\n",
        "    MultinomialNB(**best_params_dct_3[str(MultinomialNB)]),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier(**best_params_dct_3[str(KNeighborsClassifier)])\n",
        "]\n",
        "\n",
        "for clf in trained_selected:\n",
        "    clf.fit(X_train_selected_2, y_train)"
      ],
      "metadata": {
        "id": "FTqDn2MSWvqO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use all models except knn\n",
        "\n",
        "finals = [\n",
        "    MultinomialNB(),\n",
        "    SGDClassifier(loss=\"hinge\"),\n",
        "    SGDClassifier(loss=\"log_loss\"),\n",
        "    RandomForestClassifier(),\n",
        "    KNeighborsClassifier()\n",
        "]\n",
        "\n",
        "train_probs = get_proba(trained_selected[:4], X_train_selected_2, y_train, prob=1.3)\n",
        "val_probs = get_proba(trained_selected[:4], X_val_selected_2, y_train, prob=1.3)\n",
        "\n",
        "for final in finals:\n",
        "    final.fit(train_probs, y_train)\n",
        "    preds = final.predict(val_probs)\n",
        "    print(final)\n",
        "    print(accuracy_score(y_val, preds))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq3rX8jTXCfE",
        "outputId": "816a7a9e-57c2-4f33-dd60-ffad97d244a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MultinomialNB()\n",
            "0.80065717415115\n",
            "\n",
            "SGDClassifier()\n",
            "0.7316538882803943\n",
            "\n",
            "SGDClassifier(loss='log_loss')\n",
            "0.8046732384081782\n",
            "\n",
            "RandomForestClassifier()\n",
            "0.7864184008762322\n",
            "\n",
            "KNeighborsClassifier()\n",
            "0.8061336254107339\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "All the trials above consistently show that the accuracy score is highest when only the top 4 classifiers are used as the base-models, and all features are used for training. Our final model shall thus follow this."
      ],
      "metadata": {
        "id": "ixXS6Op9T-2a"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Fine-tuning the hyperparameters of the meta-learner"
      ],
      "metadata": {
        "id": "O0RfoinLYr6Y"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def objective_meta(trial, X_train, X_val, y_train, y_val, clf, clf_name):\n",
        "    \"\"\"Objective function to be used to optimize the hyperparameters of meta-learner\"\"\"\n",
        "\n",
        "    if clf_name == \"MNB\":\n",
        "        params = {\n",
        "            \"alpha\": trial.suggest_float(\"alpha\", 0.001, 1.0),\n",
        "        }\n",
        "    elif clf_name == \"SVM\":\n",
        "        params = {\n",
        "            \"loss\": \"hinge\",\n",
        "            \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1),  # regularisation parameter\n",
        "            \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 10000),\n",
        "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
        "            # \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
        "            # \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"optimal\", \"adaptive\"]),\n",
        "            # \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0)\n",
        "        }\n",
        "    elif clf_name == \"LR\":\n",
        "        params = {\n",
        "            \"loss\": \"log_loss\",\n",
        "            \"alpha\": trial.suggest_float(\"alpha\", 0.0001, 0.1),  # regularisation parameter\n",
        "            \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 10000),\n",
        "            \"penalty\": trial.suggest_categorical(\"penalty\", [\"l1\", \"l2\", \"elasticnet\"]),\n",
        "            # \"warm_start\": trial.suggest_categorical(\"warm_start\", [True, False]),\n",
        "            # \"learning_rate\": trial.suggest_categorical(\"learning_rate\", [\"optimal\", \"adaptive\"]),\n",
        "            # \"eta0\": trial.suggest_float(\"eta0\", 0.0, 1.0)\n",
        "        }\n",
        "    elif clf_name == \"RF\":\n",
        "        params = {\n",
        "            \"n_estimators\": trial.suggest_int(\"n_estimators\", 5, 300),\n",
        "            \"max_depth\": trial.suggest_int(\"max_depth\", 5, 100),\n",
        "            \"min_samples_split\": trial.suggest_int(\"min_samples_split\", 2, 30),\n",
        "            \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 1, 10),\n",
        "            \"max_leaf_nodes\": trial.suggest_int(\"max_leaf_nodes\", 5, 1000),\n",
        "        }\n",
        "    elif clf_name == \"KN\":\n",
        "            params = {\n",
        "            \"n_neighbors\": trial.suggest_int(\"n_neighbors\", 1, 100),\n",
        "            \"leaf_size\": trial.suggest_int(\"leaf_size\", 1, 100)\n",
        "        }\n",
        "\n",
        "    model = clf(**params)\n",
        "    model.fit(X_train, y_train)\n",
        "    preds = model.predict(X_val)\n",
        "\n",
        "    return accuracy_score(y_val, preds)"
      ],
      "metadata": {
        "id": "tz3q3vkTYrhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_probs = get_proba(trained_all_ngrams[:4], X_train_all_ngrams, y_train, prob=1.3)\n",
        "val_probs = get_proba(trained_all_ngrams[:4], X_val_all_ngrams, y_train, prob=5)"
      ],
      "metadata": {
        "id": "ps5kcr6hdIfQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clf_clfname = [\n",
        "    [MultinomialNB, \"MNB\"],\n",
        "    [SGDClassifier, \"SVM\"],\n",
        "    [SGDClassifier, \"LR\"],\n",
        "    [RandomForestClassifier, \"RF\"],\n",
        "    [KNeighborsClassifier, \"KN\"]\n",
        "]\n",
        "\n",
        "for clf, clf_name in clf_clfname:\n",
        "    study = optuna.create_study(direction='maximize')\n",
        "    study.optimize(lambda trial: objective_meta(trial, train_probs, val_probs, y_train, y_val, clf, clf_name), n_trials=100)\n",
        "    params = study.best_params\n",
        "\n",
        "    print(\"Meta-learner:\", clf_name)\n",
        "    if clf_name == \"LR\":\n",
        "        model = clf(loss=\"log_loss\")\n",
        "    else:\n",
        "        model = clf()\n",
        "    model.fit(train_probs, y_train)\n",
        "    y_preds = model.predict(val_probs)\n",
        "    print(\"Default params acc:\", accuracy_score(y_val, y_preds))\n",
        "    print(\"Best params:\", params)\n",
        "    model = clf(**params)\n",
        "    model.fit(train_probs, y_train)\n",
        "    y_preds_2 = model.predict(val_probs)\n",
        "    print(\"Best params acc:\", accuracy_score(y_val, y_preds_2))\n",
        "    print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "33KzYi4RbTcy",
        "outputId": "311edb7e-b479-4050-b6a0-b384afd246aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Meta-learner: MNB\n",
            "Default params acc: 0.8185469149324571\n",
            "Best params: {'alpha': 0.5750016598974882}\n",
            "Best params acc: 0.8185469149324571\n",
            "\n",
            "Meta-learner: SVM\n",
            "Default params acc: 0.8130704636728733\n",
            "Best params: {'alpha': 0.0003982622356968902, 'max_iter': 6869, 'penalty': 'elasticnet'}\n",
            "Best params acc: 0.8254837531945965\n",
            "\n",
            "Meta-learner: LR\n",
            "Default params acc: 0.8181818181818182\n",
            "Best params: {'alpha': 0.08216126312129639, 'max_iter': 2738, 'penalty': 'elasticnet'}\n",
            "Best params acc: 0.8185469149324571\n",
            "\n",
            "Meta-learner: RF\n",
            "Default params acc: 0.7893391748813435\n",
            "Best params: {'n_estimators': 10, 'max_depth': 64, 'min_samples_split': 13, 'min_samples_leaf': 9, 'max_leaf_nodes': 379}\n",
            "Best params acc: 0.796641109894122\n",
            "\n",
            "Meta-learner: KN\n",
            "Default params acc: 0.8039430449069004\n",
            "Best params: {'n_neighbors': 79, 'leaf_size': 68}\n",
            "Best params acc: 0.8207374954362906\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The best performing stacking model consists of Multinomial NB, SVM, Logistic Regression and Random Forest base-learners, with SVM meta-learner. After fine-tuning, the validation accuracy is 0.82548."
      ],
      "metadata": {
        "id": "VKjAQU-BUqjx"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "cRvZSp8jhyOp",
        "ATy4pH5f9XSA",
        "gQJ3LCRtCZoq",
        "nd57ANa4D9A_",
        "NM8SGri4TLXY"
      ],
      "authorship_tag": "ABX9TyOYIZP2FHr8qZU7BdizyMY9",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}